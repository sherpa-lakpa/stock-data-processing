[2023-05-28 03:22:36,868] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: stock_spark_airflow.feature_engineering.stock_feature_processing manual__2023-05-28T03:10:39.403102+00:00 [failed]>
[2023-05-28 03:22:36,869] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: stock_spark_airflow.feature_engineering.stock_feature_processing manual__2023-05-28T03:10:39.403102+00:00 [failed]>
[2023-05-28 03:22:36,870] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-05-28 03:22:36,870] {taskinstance.py:1357} INFO - Starting attempt 2 of 1
[2023-05-28 03:22:36,871] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-05-28 03:22:36,880] {taskinstance.py:1377} INFO - Executing <Task(SparkSubmitOperator): feature_engineering.stock_feature_processing> on 2023-05-28 03:10:39.403102+00:00
[2023-05-28 03:22:36,885] {standard_task_runner.py:52} INFO - Started process 13504 to run task
[2023-05-28 03:22:36,889] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'stock_spark_***', 'feature_engineering.stock_feature_processing', 'manual__2023-05-28T03:10:39.403102+00:00', '--job-id', '321', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/stock_spark_ml.py', '--cfg-path', '/tmp/tmpyl8dj94f', '--error-file', '/tmp/tmp8xmtkuq2']
[2023-05-28 03:22:36,890] {standard_task_runner.py:80} INFO - Job 321: Subtask feature_engineering.stock_feature_processing
[2023-05-28 03:22:36,941] {task_command.py:369} INFO - Running <TaskInstance: stock_spark_airflow.feature_engineering.stock_feature_processing manual__2023-05-28T03:10:39.403102+00:00 [running]> on host c1224b457a2d
[2023-05-28 03:22:36,997] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=stock_spark_***
AIRFLOW_CTX_TASK_ID=feature_engineering.stock_feature_processing
AIRFLOW_CTX_EXECUTION_DATE=2023-05-28T03:10:39.403102+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-05-28T03:10:39.403102+00:00
[2023-05-28 03:22:37,009] {base.py:68} INFO - Using connection ID 'spark_local' for task execution.
[2023-05-28 03:22:37,010] {spark_submit.py:339} INFO - Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark /usr/local/spark/app/feature_engineering_processing.py stocks
[2023-05-28 03:22:37,098] {spark_submit.py:490} INFO - /home/***/.local/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2023-05-28 03:22:39,226] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkContext: Running Spark version 3.4.0
[2023-05-28 03:22:39,273] {spark_submit.py:490} INFO - 23/05/28 03:22:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-05-28 03:22:39,336] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceUtils: ==============================================================
[2023-05-28 03:22:39,337] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-05-28 03:22:39,339] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceUtils: ==============================================================
[2023-05-28 03:22:39,340] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkContext: Submitted application: random_reg
[2023-05-28 03:22:39,357] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-05-28 03:22:39,364] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceProfile: Limiting resource is cpu
[2023-05-28 03:22:39,365] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-05-28 03:22:39,409] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SecurityManager: Changing view acls to: default
[2023-05-28 03:22:39,409] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SecurityManager: Changing modify acls to: default
[2023-05-28 03:22:39,410] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SecurityManager: Changing view acls groups to:
[2023-05-28 03:22:39,411] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SecurityManager: Changing modify acls groups to:
[2023-05-28 03:22:39,411] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: default; groups with view permissions: EMPTY; users with modify permissions: default; groups with modify permissions: EMPTY
[2023-05-28 03:22:39,674] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO Utils: Successfully started service 'sparkDriver' on port 42767.
[2023-05-28 03:22:39,710] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkEnv: Registering MapOutputTracker
[2023-05-28 03:22:39,737] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkEnv: Registering BlockManagerMaster
[2023-05-28 03:22:39,759] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-05-28 03:22:39,760] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-05-28 03:22:39,762] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-05-28 03:22:39,782] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d090f73-1597-483e-98fd-b9134e77c6ba
[2023-05-28 03:22:39,795] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-05-28 03:22:39,805] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-05-28 03:22:39,898] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2023-05-28 03:22:39,943] {spark_submit.py:490} INFO - 23/05/28 03:22:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-05-28 03:22:40,012] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO Executor: Starting executor ID driver on host c1224b457a2d
[2023-05-28 03:22:40,016] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-05-28 03:22:40,028] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37283.
[2023-05-28 03:22:40,029] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO NettyBlockTransferService: Server created on c1224b457a2d:37283
[2023-05-28 03:22:40,030] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-05-28 03:22:40,035] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, c1224b457a2d, 37283, None)
[2023-05-28 03:22:40,038] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO BlockManagerMasterEndpoint: Registering block manager c1224b457a2d:37283 with 434.4 MiB RAM, BlockManagerId(driver, c1224b457a2d, 37283, None)
[2023-05-28 03:22:40,039] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, c1224b457a2d, 37283, None)
[2023-05-28 03:22:40,040] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, c1224b457a2d, 37283, None)
[2023-05-28 03:22:40,180] {spark_submit.py:490} INFO - /home/***/.local/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.
[2023-05-28 03:22:40,181] {spark_submit.py:490} INFO - warnings.warn("Python 3.7 support is deprecated in Spark 3.4.", FutureWarning)
[2023-05-28 03:22:40,325] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-05-28 03:22:40,329] {spark_submit.py:490} INFO - 23/05/28 03:22:40 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2023-05-28 03:22:41,094] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO HadoopFSUtils: Listing leaf files and directories in parallel under 199 paths. The first several paths are: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00000-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00001-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00002-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00003-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00004-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00005-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00006-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00007-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00008-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00009-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet.
[2023-05-28 03:22:41,310] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2023-05-28 03:22:41,319] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Got job 0 (load at NativeMethodAccessorImpl.java:0) with 199 output partitions
[2023-05-28 03:22:41,319] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Final stage: ResultStage 0 (load at NativeMethodAccessorImpl.java:0)
[2023-05-28 03:22:41,320] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Parents of final stage: List()
[2023-05-28 03:22:41,320] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Missing parents: List()
[2023-05-28 03:22:41,324] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-28 03:22:41,403] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 102.8 KiB, free 434.3 MiB)
[2023-05-28 03:22:41,429] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.3 MiB)
[2023-05-28 03:22:41,431] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on c1224b457a2d:37283 (size: 36.9 KiB, free: 434.4 MiB)
[2023-05-28 03:22:41,435] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
[2023-05-28 03:22:41,445] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO DAGScheduler: Submitting 199 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2023-05-28 03:22:41,446] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSchedulerImpl: Adding task set 0.0 with 199 tasks resource profile 0
[2023-05-28 03:22:41,488] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (c1224b457a2d, executor driver, partition 0, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,493] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (c1224b457a2d, executor driver, partition 1, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,493] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (c1224b457a2d, executor driver, partition 2, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,494] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (c1224b457a2d, executor driver, partition 3, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,512] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
[2023-05-28 03:22:41,512] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
[2023-05-28 03:22:41,514] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2023-05-28 03:22:41,515] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2023-05-28 03:22:41,621] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2014 bytes result sent to driver
[2023-05-28 03:22:41,621] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2014 bytes result sent to driver
[2023-05-28 03:22:41,623] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2014 bytes result sent to driver
[2023-05-28 03:22:41,624] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2014 bytes result sent to driver
[2023-05-28 03:22:41,634] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (c1224b457a2d, executor driver, partition 4, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,635] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
[2023-05-28 03:22:41,638] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (c1224b457a2d, executor driver, partition 5, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,639] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
[2023-05-28 03:22:41,639] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (c1224b457a2d, executor driver, partition 6, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,640] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
[2023-05-28 03:22:41,641] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (c1224b457a2d, executor driver, partition 7, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,642] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
[2023-05-28 03:22:41,649] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2014 bytes result sent to driver
[2023-05-28 03:22:41,663] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1971 bytes result sent to driver
[2023-05-28 03:22:41,664] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2014 bytes result sent to driver
[2023-05-28 03:22:41,665] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 157 ms on c1224b457a2d (executor driver) (1/199)
[2023-05-28 03:22:41,665] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1971 bytes result sent to driver
[2023-05-28 03:22:41,671] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (c1224b457a2d, executor driver, partition 8, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,673] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (c1224b457a2d, executor driver, partition 9, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,674] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10) (c1224b457a2d, executor driver, partition 10, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,674] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)
[2023-05-28 03:22:41,674] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11) (c1224b457a2d, executor driver, partition 11, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,675] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 178 ms on c1224b457a2d (executor driver) (2/199)
[2023-05-28 03:22:41,675] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 179 ms on c1224b457a2d (executor driver) (3/199)
[2023-05-28 03:22:41,675] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 33 ms on c1224b457a2d (executor driver) (4/199)
[2023-05-28 03:22:41,676] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 199 ms on c1224b457a2d (executor driver) (5/199)
[2023-05-28 03:22:41,676] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
[2023-05-28 03:22:41,676] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 33 ms on c1224b457a2d (executor driver) (6/199)
[2023-05-28 03:22:41,677] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 32 ms on c1224b457a2d (executor driver) (7/199)
[2023-05-28 03:22:41,677] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 40 ms on c1224b457a2d (executor driver) (8/199)
[2023-05-28 03:22:41,677] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
[2023-05-28 03:22:41,685] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
[2023-05-28 03:22:41,688] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 2014 bytes result sent to driver
[2023-05-28 03:22:41,691] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1971 bytes result sent to driver
[2023-05-28 03:22:41,692] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12) (c1224b457a2d, executor driver, partition 12, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,692] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 22 ms on c1224b457a2d (executor driver) (9/199)
[2023-05-28 03:22:41,697] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1971 bytes result sent to driver
[2023-05-28 03:22:41,697] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1928 bytes result sent to driver
[2023-05-28 03:22:41,698] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13) (c1224b457a2d, executor driver, partition 13, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,699] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14) (c1224b457a2d, executor driver, partition 14, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,699] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 14.0 in stage 0.0 (TID 14)
[2023-05-28 03:22:41,700] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15) (c1224b457a2d, executor driver, partition 15, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,700] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 30 ms on c1224b457a2d (executor driver) (10/199)
[2023-05-28 03:22:41,701] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
[2023-05-28 03:22:41,701] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 31 ms on c1224b457a2d (executor driver) (11/199)
[2023-05-28 03:22:41,701] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 12.0 in stage 0.0 (TID 12)
[2023-05-28 03:22:41,702] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
[2023-05-28 03:22:41,703] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 32 ms on c1224b457a2d (executor driver) (12/199)
[2023-05-28 03:22:41,708] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1928 bytes result sent to driver
[2023-05-28 03:22:41,712] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 14.0 in stage 0.0 (TID 14). 1971 bytes result sent to driver
[2023-05-28 03:22:41,713] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16) (c1224b457a2d, executor driver, partition 16, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,714] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 12.0 in stage 0.0 (TID 12). 1928 bytes result sent to driver
[2023-05-28 03:22:41,714] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 14 ms on c1224b457a2d (executor driver) (13/199)
[2023-05-28 03:22:41,715] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
[2023-05-28 03:22:41,716] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17) (c1224b457a2d, executor driver, partition 17, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,716] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
[2023-05-28 03:22:41,717] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 17 ms on c1224b457a2d (executor driver) (14/199)
[2023-05-28 03:22:41,717] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18) (c1224b457a2d, executor driver, partition 18, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,718] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 26 ms on c1224b457a2d (executor driver) (15/199)
[2023-05-28 03:22:41,739] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 18.0 in stage 0.0 (TID 18)
[2023-05-28 03:22:41,740] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 2014 bytes result sent to driver
[2023-05-28 03:22:41,741] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19) (c1224b457a2d, executor driver, partition 19, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,742] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 28 ms on c1224b457a2d (executor driver) (16/199)
[2023-05-28 03:22:41,742] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
[2023-05-28 03:22:41,745] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 2057 bytes result sent to driver
[2023-05-28 03:22:41,747] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 2057 bytes result sent to driver
[2023-05-28 03:22:41,748] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20) (c1224b457a2d, executor driver, partition 20, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,749] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21) (c1224b457a2d, executor driver, partition 21, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,749] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
[2023-05-28 03:22:41,749] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 35 ms on c1224b457a2d (executor driver) (17/199)
[2023-05-28 03:22:41,750] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 49 ms on c1224b457a2d (executor driver) (18/199)
[2023-05-28 03:22:41,750] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
[2023-05-28 03:22:41,751] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1928 bytes result sent to driver
[2023-05-28 03:22:41,752] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22) (c1224b457a2d, executor driver, partition 22, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,753] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 12 ms on c1224b457a2d (executor driver) (19/199)
[2023-05-28 03:22:41,755] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 18.0 in stage 0.0 (TID 18). 2014 bytes result sent to driver
[2023-05-28 03:22:41,759] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
[2023-05-28 03:22:41,760] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 2014 bytes result sent to driver
[2023-05-28 03:22:41,762] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 1928 bytes result sent to driver
[2023-05-28 03:22:41,762] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23) (c1224b457a2d, executor driver, partition 23, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,763] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24) (c1224b457a2d, executor driver, partition 24, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,764] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25) (c1224b457a2d, executor driver, partition 25, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,764] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 45 ms on c1224b457a2d (executor driver) (20/199)
[2023-05-28 03:22:41,764] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 25.0 in stage 0.0 (TID 25)
[2023-05-28 03:22:41,765] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 24.0 in stage 0.0 (TID 24)
[2023-05-28 03:22:41,765] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 16 ms on c1224b457a2d (executor driver) (21/199)
[2023-05-28 03:22:41,765] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 17 ms on c1224b457a2d (executor driver) (22/199)
[2023-05-28 03:22:41,766] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
[2023-05-28 03:22:41,767] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 22.0 in stage 0.0 (TID 22). 2014 bytes result sent to driver
[2023-05-28 03:22:41,768] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26) (c1224b457a2d, executor driver, partition 26, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,769] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
[2023-05-28 03:22:41,769] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 17 ms on c1224b457a2d (executor driver) (23/199)
[2023-05-28 03:22:41,772] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 24.0 in stage 0.0 (TID 24). 2014 bytes result sent to driver
[2023-05-28 03:22:41,772] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27) (c1224b457a2d, executor driver, partition 27, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,773] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 12 ms on c1224b457a2d (executor driver) (24/199)
[2023-05-28 03:22:41,773] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 27.0 in stage 0.0 (TID 27)
[2023-05-28 03:22:41,777] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1928 bytes result sent to driver
[2023-05-28 03:22:41,778] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 25.0 in stage 0.0 (TID 25). 1971 bytes result sent to driver
[2023-05-28 03:22:41,778] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28) (c1224b457a2d, executor driver, partition 28, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,779] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 19 ms on c1224b457a2d (executor driver) (25/199)
[2023-05-28 03:22:41,780] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29) (c1224b457a2d, executor driver, partition 29, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,781] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 27.0 in stage 0.0 (TID 27). 1971 bytes result sent to driver
[2023-05-28 03:22:41,781] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 19 ms on c1224b457a2d (executor driver) (26/199)
[2023-05-28 03:22:41,781] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
[2023-05-28 03:22:41,782] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
[2023-05-28 03:22:41,782] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 1971 bytes result sent to driver
[2023-05-28 03:22:41,783] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30) (c1224b457a2d, executor driver, partition 30, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,783] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31) (c1224b457a2d, executor driver, partition 31, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,784] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 11 ms on c1224b457a2d (executor driver) (27/199)
[2023-05-28 03:22:41,784] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
[2023-05-28 03:22:41,785] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 15 ms on c1224b457a2d (executor driver) (28/199)
[2023-05-28 03:22:41,785] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 30.0 in stage 0.0 (TID 30)
[2023-05-28 03:22:41,801] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1928 bytes result sent to driver
[2023-05-28 03:22:41,802] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32) (c1224b457a2d, executor driver, partition 32, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,804] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 32.0 in stage 0.0 (TID 32)
[2023-05-28 03:22:41,805] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 20 ms on c1224b457a2d (executor driver) (29/199)
[2023-05-28 03:22:41,805] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 1971 bytes result sent to driver
[2023-05-28 03:22:41,806] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1971 bytes result sent to driver
[2023-05-28 03:22:41,806] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 30.0 in stage 0.0 (TID 30). 1971 bytes result sent to driver
[2023-05-28 03:22:41,807] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33) (c1224b457a2d, executor driver, partition 33, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,807] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 33.0 in stage 0.0 (TID 33)
[2023-05-28 03:22:41,810] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 26 ms on c1224b457a2d (executor driver) (30/199)
[2023-05-28 03:22:41,812] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34) (c1224b457a2d, executor driver, partition 34, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,812] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 34.0 in stage 0.0 (TID 34)
[2023-05-28 03:22:41,813] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 26 ms on c1224b457a2d (executor driver) (31/199)
[2023-05-28 03:22:41,813] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35) (c1224b457a2d, executor driver, partition 35, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,814] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 28 ms on c1224b457a2d (executor driver) (32/199)
[2023-05-28 03:22:41,814] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 35.0 in stage 0.0 (TID 35)
[2023-05-28 03:22:41,814] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 33.0 in stage 0.0 (TID 33). 1928 bytes result sent to driver
[2023-05-28 03:22:41,815] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36) (c1224b457a2d, executor driver, partition 36, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,815] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 9 ms on c1224b457a2d (executor driver) (33/199)
[2023-05-28 03:22:41,816] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 32.0 in stage 0.0 (TID 32). 1971 bytes result sent to driver
[2023-05-28 03:22:41,816] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 35.0 in stage 0.0 (TID 35). 1971 bytes result sent to driver
[2023-05-28 03:22:41,817] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 36.0 in stage 0.0 (TID 36)
[2023-05-28 03:22:41,817] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37) (c1224b457a2d, executor driver, partition 37, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,818] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 34.0 in stage 0.0 (TID 34). 1971 bytes result sent to driver
[2023-05-28 03:22:41,819] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 15 ms on c1224b457a2d (executor driver) (34/199)
[2023-05-28 03:22:41,819] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 37.0 in stage 0.0 (TID 37)
[2023-05-28 03:22:41,820] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38) (c1224b457a2d, executor driver, partition 38, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,824] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 15 ms on c1224b457a2d (executor driver) (35/199)
[2023-05-28 03:22:41,824] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 38.0 in stage 0.0 (TID 38)
[2023-05-28 03:22:41,825] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 37.0 in stage 0.0 (TID 37). 1928 bytes result sent to driver
[2023-05-28 03:22:41,825] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39) (c1224b457a2d, executor driver, partition 39, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,826] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 7 ms on c1224b457a2d (executor driver) (36/199)
[2023-05-28 03:22:41,826] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 39.0 in stage 0.0 (TID 39)
[2023-05-28 03:22:41,834] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 36.0 in stage 0.0 (TID 36). 2057 bytes result sent to driver
[2023-05-28 03:22:41,849] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40) (c1224b457a2d, executor driver, partition 40, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,853] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)
[2023-05-28 03:22:41,853] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41) (c1224b457a2d, executor driver, partition 41, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,854] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 41 ms on c1224b457a2d (executor driver) (37/199)
[2023-05-28 03:22:41,854] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 38 ms on c1224b457a2d (executor driver) (38/199)
[2023-05-28 03:22:41,855] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 41.0 in stage 0.0 (TID 41)
[2023-05-28 03:22:41,858] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 39.0 in stage 0.0 (TID 39). 2014 bytes result sent to driver
[2023-05-28 03:22:41,859] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42) (c1224b457a2d, executor driver, partition 42, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,859] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 42.0 in stage 0.0 (TID 42)
[2023-05-28 03:22:41,860] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 38 ms on c1224b457a2d (executor driver) (39/199)
[2023-05-28 03:22:41,861] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 38.0 in stage 0.0 (TID 38). 1971 bytes result sent to driver
[2023-05-28 03:22:41,862] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 41.0 in stage 0.0 (TID 41). 1971 bytes result sent to driver
[2023-05-28 03:22:41,863] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43) (c1224b457a2d, executor driver, partition 43, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,864] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 43 ms on c1224b457a2d (executor driver) (40/199)
[2023-05-28 03:22:41,865] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44) (c1224b457a2d, executor driver, partition 44, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,865] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 14 ms on c1224b457a2d (executor driver) (41/199)
[2023-05-28 03:22:41,868] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 42.0 in stage 0.0 (TID 42). 1971 bytes result sent to driver
[2023-05-28 03:22:41,869] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45) (c1224b457a2d, executor driver, partition 45, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,870] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 11 ms on c1224b457a2d (executor driver) (42/199)
[2023-05-28 03:22:41,881] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 43.0 in stage 0.0 (TID 43)
[2023-05-28 03:22:41,883] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 44.0 in stage 0.0 (TID 44)
[2023-05-28 03:22:41,883] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 40.0 in stage 0.0 (TID 40). 2014 bytes result sent to driver
[2023-05-28 03:22:41,884] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 45.0 in stage 0.0 (TID 45)
[2023-05-28 03:22:41,884] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46) (c1224b457a2d, executor driver, partition 46, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,885] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 37 ms on c1224b457a2d (executor driver) (43/199)
[2023-05-28 03:22:41,886] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 46.0 in stage 0.0 (TID 46)
[2023-05-28 03:22:41,894] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 45.0 in stage 0.0 (TID 45). 1971 bytes result sent to driver
[2023-05-28 03:22:41,894] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 43.0 in stage 0.0 (TID 43). 1971 bytes result sent to driver
[2023-05-28 03:22:41,895] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47) (c1224b457a2d, executor driver, partition 47, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,895] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 47.0 in stage 0.0 (TID 47)
[2023-05-28 03:22:41,896] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 25 ms on c1224b457a2d (executor driver) (44/199)
[2023-05-28 03:22:41,897] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48) (c1224b457a2d, executor driver, partition 48, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,897] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 48.0 in stage 0.0 (TID 48)
[2023-05-28 03:22:41,898] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 36 ms on c1224b457a2d (executor driver) (45/199)
[2023-05-28 03:22:41,900] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 47.0 in stage 0.0 (TID 47). 1971 bytes result sent to driver
[2023-05-28 03:22:41,901] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49) (c1224b457a2d, executor driver, partition 49, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,902] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 7 ms on c1224b457a2d (executor driver) (46/199)
[2023-05-28 03:22:41,902] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 49.0 in stage 0.0 (TID 49)
[2023-05-28 03:22:41,904] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 44.0 in stage 0.0 (TID 44). 1928 bytes result sent to driver
[2023-05-28 03:22:41,905] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50) (c1224b457a2d, executor driver, partition 50, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,906] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 42 ms on c1224b457a2d (executor driver) (47/199)
[2023-05-28 03:22:41,906] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 50.0 in stage 0.0 (TID 50)
[2023-05-28 03:22:41,907] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 46.0 in stage 0.0 (TID 46). 1971 bytes result sent to driver
[2023-05-28 03:22:41,908] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51) (c1224b457a2d, executor driver, partition 51, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,908] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 24 ms on c1224b457a2d (executor driver) (48/199)
[2023-05-28 03:22:41,909] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 50.0 in stage 0.0 (TID 50). 1928 bytes result sent to driver
[2023-05-28 03:22:41,910] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52) (c1224b457a2d, executor driver, partition 52, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,910] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 52.0 in stage 0.0 (TID 52)
[2023-05-28 03:22:41,911] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 6 ms on c1224b457a2d (executor driver) (49/199)
[2023-05-28 03:22:41,911] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 51.0 in stage 0.0 (TID 51)
[2023-05-28 03:22:41,915] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 48.0 in stage 0.0 (TID 48). 1928 bytes result sent to driver
[2023-05-28 03:22:41,916] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 51.0 in stage 0.0 (TID 51). 1928 bytes result sent to driver
[2023-05-28 03:22:41,917] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 49.0 in stage 0.0 (TID 49). 1971 bytes result sent to driver
[2023-05-28 03:22:41,917] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53) (c1224b457a2d, executor driver, partition 53, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,919] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 53.0 in stage 0.0 (TID 53)
[2023-05-28 03:22:41,920] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 20 ms on c1224b457a2d (executor driver) (50/199)
[2023-05-28 03:22:41,920] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 52.0 in stage 0.0 (TID 52). 1928 bytes result sent to driver
[2023-05-28 03:22:41,921] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54) (c1224b457a2d, executor driver, partition 54, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,921] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 11 ms on c1224b457a2d (executor driver) (51/199)
[2023-05-28 03:22:41,922] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 54.0 in stage 0.0 (TID 54)
[2023-05-28 03:22:41,925] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 54.0 in stage 0.0 (TID 54). 1971 bytes result sent to driver
[2023-05-28 03:22:41,927] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55) (c1224b457a2d, executor driver, partition 55, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,928] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 54.0 in stage 0.0 (TID 54) in 8 ms on c1224b457a2d (executor driver) (52/199)
[2023-05-28 03:22:41,929] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 55.0 in stage 0.0 (TID 55)
[2023-05-28 03:22:41,931] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56) (c1224b457a2d, executor driver, partition 56, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,932] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 56.0 in stage 0.0 (TID 56)
[2023-05-28 03:22:41,937] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57) (c1224b457a2d, executor driver, partition 57, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,938] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 53.0 in stage 0.0 (TID 53). 1928 bytes result sent to driver
[2023-05-28 03:22:41,938] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58) (c1224b457a2d, executor driver, partition 58, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,939] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 28 ms on c1224b457a2d (executor driver) (53/199)
[2023-05-28 03:22:41,939] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 56.0 in stage 0.0 (TID 56). 1971 bytes result sent to driver
[2023-05-28 03:22:41,940] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 53.0 in stage 0.0 (TID 53) in 23 ms on c1224b457a2d (executor driver) (54/199)
[2023-05-28 03:22:41,940] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 39 ms on c1224b457a2d (executor driver) (55/199)
[2023-05-28 03:22:41,941] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 56.0 in stage 0.0 (TID 56) in 8 ms on c1224b457a2d (executor driver) (56/199)
[2023-05-28 03:22:41,941] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 58.0 in stage 0.0 (TID 58)
[2023-05-28 03:22:41,942] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59) (c1224b457a2d, executor driver, partition 59, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,942] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 57.0 in stage 0.0 (TID 57)
[2023-05-28 03:22:41,942] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 59.0 in stage 0.0 (TID 59)
[2023-05-28 03:22:41,952] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 57.0 in stage 0.0 (TID 57). 2014 bytes result sent to driver
[2023-05-28 03:22:41,954] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60) (c1224b457a2d, executor driver, partition 60, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,955] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 57.0 in stage 0.0 (TID 57) in 22 ms on c1224b457a2d (executor driver) (57/199)
[2023-05-28 03:22:41,960] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 60.0 in stage 0.0 (TID 60)
[2023-05-28 03:22:41,961] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 59.0 in stage 0.0 (TID 59). 1971 bytes result sent to driver
[2023-05-28 03:22:41,962] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61) (c1224b457a2d, executor driver, partition 61, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,963] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 59.0 in stage 0.0 (TID 59) in 22 ms on c1224b457a2d (executor driver) (58/199)
[2023-05-28 03:22:41,964] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 61.0 in stage 0.0 (TID 61)
[2023-05-28 03:22:41,967] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 58.0 in stage 0.0 (TID 58). 2014 bytes result sent to driver
[2023-05-28 03:22:41,968] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62) (c1224b457a2d, executor driver, partition 62, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,969] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 58.0 in stage 0.0 (TID 58) in 31 ms on c1224b457a2d (executor driver) (59/199)
[2023-05-28 03:22:41,969] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 62.0 in stage 0.0 (TID 62)
[2023-05-28 03:22:41,972] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 62.0 in stage 0.0 (TID 62). 1928 bytes result sent to driver
[2023-05-28 03:22:41,973] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63) (c1224b457a2d, executor driver, partition 63, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,974] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 61.0 in stage 0.0 (TID 61). 1971 bytes result sent to driver
[2023-05-28 03:22:41,974] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 55.0 in stage 0.0 (TID 55). 2014 bytes result sent to driver
[2023-05-28 03:22:41,975] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 63.0 in stage 0.0 (TID 63)
[2023-05-28 03:22:41,975] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64) (c1224b457a2d, executor driver, partition 64, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,976] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 61.0 in stage 0.0 (TID 61) in 12 ms on c1224b457a2d (executor driver) (60/199)
[2023-05-28 03:22:41,976] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 62.0 in stage 0.0 (TID 62) in 6 ms on c1224b457a2d (executor driver) (61/199)
[2023-05-28 03:22:41,976] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 64.0 in stage 0.0 (TID 64)
[2023-05-28 03:22:41,977] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65) (c1224b457a2d, executor driver, partition 65, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:41,977] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Finished task 55.0 in stage 0.0 (TID 55) in 50 ms on c1224b457a2d (executor driver) (62/199)
[2023-05-28 03:22:41,978] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 65.0 in stage 0.0 (TID 65)
[2023-05-28 03:22:41,978] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 60.0 in stage 0.0 (TID 60). 1971 bytes result sent to driver
[2023-05-28 03:22:41,979] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 63.0 in stage 0.0 (TID 63). 1928 bytes result sent to driver
[2023-05-28 03:22:41,981] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 64.0 in stage 0.0 (TID 64). 1928 bytes result sent to driver
[2023-05-28 03:22:41,983] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Finished task 65.0 in stage 0.0 (TID 65). 1971 bytes result sent to driver
[2023-05-28 03:22:41,999] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66) (c1224b457a2d, executor driver, partition 66, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,000] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67) (c1224b457a2d, executor driver, partition 67, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,001] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68) (c1224b457a2d, executor driver, partition 68, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,001] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO Executor: Running task 68.0 in stage 0.0 (TID 68)
[2023-05-28 03:22:42,002] {spark_submit.py:490} INFO - 23/05/28 03:22:41 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69) (c1224b457a2d, executor driver, partition 69, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,002] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 66.0 in stage 0.0 (TID 66)
[2023-05-28 03:22:42,003] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 68.0 in stage 0.0 (TID 68). 1928 bytes result sent to driver
[2023-05-28 03:22:42,004] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 69.0 in stage 0.0 (TID 69)
[2023-05-28 03:22:42,004] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 65.0 in stage 0.0 (TID 65) in 29 ms on c1224b457a2d (executor driver) (63/199)
[2023-05-28 03:22:42,008] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70) (c1224b457a2d, executor driver, partition 70, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,009] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 70.0 in stage 0.0 (TID 70)
[2023-05-28 03:22:42,009] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 66.0 in stage 0.0 (TID 66). 1928 bytes result sent to driver
[2023-05-28 03:22:42,010] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 67.0 in stage 0.0 (TID 67)
[2023-05-28 03:22:42,010] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71) (c1224b457a2d, executor driver, partition 71, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,011] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 71.0 in stage 0.0 (TID 71)
[2023-05-28 03:22:42,015] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 64.0 in stage 0.0 (TID 64) in 33 ms on c1224b457a2d (executor driver) (64/199)
[2023-05-28 03:22:42,016] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 66.0 in stage 0.0 (TID 66) in 20 ms on c1224b457a2d (executor driver) (65/199)
[2023-05-28 03:22:42,016] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 68.0 in stage 0.0 (TID 68) in 8 ms on c1224b457a2d (executor driver) (66/199)
[2023-05-28 03:22:42,017] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 69.0 in stage 0.0 (TID 69). 1928 bytes result sent to driver
[2023-05-28 03:22:42,017] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 70.0 in stage 0.0 (TID 70). 1971 bytes result sent to driver
[2023-05-28 03:22:42,017] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 63.0 in stage 0.0 (TID 63) in 35 ms on c1224b457a2d (executor driver) (67/199)
[2023-05-28 03:22:42,018] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 60.0 in stage 0.0 (TID 60) in 57 ms on c1224b457a2d (executor driver) (68/199)
[2023-05-28 03:22:42,018] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72) (c1224b457a2d, executor driver, partition 72, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,018] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 72.0 in stage 0.0 (TID 72)
[2023-05-28 03:22:42,019] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73) (c1224b457a2d, executor driver, partition 73, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,019] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 70.0 in stage 0.0 (TID 70) in 8 ms on c1224b457a2d (executor driver) (69/199)
[2023-05-28 03:22:42,020] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 73.0 in stage 0.0 (TID 73)
[2023-05-28 03:22:42,020] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 71.0 in stage 0.0 (TID 71). 1928 bytes result sent to driver
[2023-05-28 03:22:42,021] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74) (c1224b457a2d, executor driver, partition 74, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,021] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 69.0 in stage 0.0 (TID 69) in 16 ms on c1224b457a2d (executor driver) (70/199)
[2023-05-28 03:22:42,022] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 74.0 in stage 0.0 (TID 74)
[2023-05-28 03:22:42,022] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 71.0 in stage 0.0 (TID 71) in 11 ms on c1224b457a2d (executor driver) (71/199)
[2023-05-28 03:22:42,023] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 67.0 in stage 0.0 (TID 67). 1971 bytes result sent to driver
[2023-05-28 03:22:42,023] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 72.0 in stage 0.0 (TID 72). 1971 bytes result sent to driver
[2023-05-28 03:22:42,024] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 73.0 in stage 0.0 (TID 73). 1928 bytes result sent to driver
[2023-05-28 03:22:42,024] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75) (c1224b457a2d, executor driver, partition 75, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,025] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 73.0 in stage 0.0 (TID 73) in 9 ms on c1224b457a2d (executor driver) (72/199)
[2023-05-28 03:22:42,025] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 75.0 in stage 0.0 (TID 75)
[2023-05-28 03:22:42,025] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76) (c1224b457a2d, executor driver, partition 76, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,026] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 76.0 in stage 0.0 (TID 76)
[2023-05-28 03:22:42,026] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 72.0 in stage 0.0 (TID 72) in 11 ms on c1224b457a2d (executor driver) (73/199)
[2023-05-28 03:22:42,026] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77) (c1224b457a2d, executor driver, partition 77, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,027] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 77.0 in stage 0.0 (TID 77)
[2023-05-28 03:22:42,027] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 67.0 in stage 0.0 (TID 67) in 24 ms on c1224b457a2d (executor driver) (74/199)
[2023-05-28 03:22:42,028] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 74.0 in stage 0.0 (TID 74). 1928 bytes result sent to driver
[2023-05-28 03:22:42,029] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78) (c1224b457a2d, executor driver, partition 78, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,030] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 74.0 in stage 0.0 (TID 74) in 14 ms on c1224b457a2d (executor driver) (75/199)
[2023-05-28 03:22:42,030] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 78.0 in stage 0.0 (TID 78)
[2023-05-28 03:22:42,032] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 77.0 in stage 0.0 (TID 77). 1928 bytes result sent to driver
[2023-05-28 03:22:42,032] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79) (c1224b457a2d, executor driver, partition 79, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,033] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 77.0 in stage 0.0 (TID 77) in 10 ms on c1224b457a2d (executor driver) (76/199)
[2023-05-28 03:22:42,033] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 79.0 in stage 0.0 (TID 79)
[2023-05-28 03:22:42,034] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 75.0 in stage 0.0 (TID 75). 1928 bytes result sent to driver
[2023-05-28 03:22:42,039] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 78.0 in stage 0.0 (TID 78). 1928 bytes result sent to driver
[2023-05-28 03:22:42,039] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80) (c1224b457a2d, executor driver, partition 80, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,040] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 81.0 in stage 0.0 (TID 81) (c1224b457a2d, executor driver, partition 81, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,040] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 78.0 in stage 0.0 (TID 78) in 10 ms on c1224b457a2d (executor driver) (77/199)
[2023-05-28 03:22:42,040] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 75.0 in stage 0.0 (TID 75) in 19 ms on c1224b457a2d (executor driver) (78/199)
[2023-05-28 03:22:42,041] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 81.0 in stage 0.0 (TID 81)
[2023-05-28 03:22:42,041] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 76.0 in stage 0.0 (TID 76). 1928 bytes result sent to driver
[2023-05-28 03:22:42,042] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 80.0 in stage 0.0 (TID 80)
[2023-05-28 03:22:42,042] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 82.0 in stage 0.0 (TID 82) (c1224b457a2d, executor driver, partition 82, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,042] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 76.0 in stage 0.0 (TID 76) in 20 ms on c1224b457a2d (executor driver) (79/199)
[2023-05-28 03:22:42,044] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 82.0 in stage 0.0 (TID 82)
[2023-05-28 03:22:42,060] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 82.0 in stage 0.0 (TID 82). 1971 bytes result sent to driver
[2023-05-28 03:22:42,062] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 81.0 in stage 0.0 (TID 81). 2014 bytes result sent to driver
[2023-05-28 03:22:42,062] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 79.0 in stage 0.0 (TID 79). 2014 bytes result sent to driver
[2023-05-28 03:22:42,063] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 83.0 in stage 0.0 (TID 83) (c1224b457a2d, executor driver, partition 83, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,063] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 83.0 in stage 0.0 (TID 83)
[2023-05-28 03:22:42,064] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 84.0 in stage 0.0 (TID 84) (c1224b457a2d, executor driver, partition 84, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,064] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 79.0 in stage 0.0 (TID 79) in 31 ms on c1224b457a2d (executor driver) (80/199)
[2023-05-28 03:22:42,064] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 84.0 in stage 0.0 (TID 84)
[2023-05-28 03:22:42,065] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 81.0 in stage 0.0 (TID 81) in 26 ms on c1224b457a2d (executor driver) (81/199)
[2023-05-28 03:22:42,068] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 84.0 in stage 0.0 (TID 84). 1928 bytes result sent to driver
[2023-05-28 03:22:42,070] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 80.0 in stage 0.0 (TID 80). 2014 bytes result sent to driver
[2023-05-28 03:22:42,072] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 85.0 in stage 0.0 (TID 85) (c1224b457a2d, executor driver, partition 85, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,073] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 86.0 in stage 0.0 (TID 86) (c1224b457a2d, executor driver, partition 86, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,074] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 87.0 in stage 0.0 (TID 87) (c1224b457a2d, executor driver, partition 87, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,074] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 82.0 in stage 0.0 (TID 82) in 32 ms on c1224b457a2d (executor driver) (82/199)
[2023-05-28 03:22:42,074] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 80.0 in stage 0.0 (TID 80) in 34 ms on c1224b457a2d (executor driver) (83/199)
[2023-05-28 03:22:42,075] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 87.0 in stage 0.0 (TID 87)
[2023-05-28 03:22:42,075] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 86.0 in stage 0.0 (TID 86)
[2023-05-28 03:22:42,075] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 84.0 in stage 0.0 (TID 84) in 10 ms on c1224b457a2d (executor driver) (84/199)
[2023-05-28 03:22:42,076] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 83.0 in stage 0.0 (TID 83). 1971 bytes result sent to driver
[2023-05-28 03:22:42,078] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 88.0 in stage 0.0 (TID 88) (c1224b457a2d, executor driver, partition 88, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,078] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 88.0 in stage 0.0 (TID 88)
[2023-05-28 03:22:42,079] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 83.0 in stage 0.0 (TID 83) in 15 ms on c1224b457a2d (executor driver) (85/199)
[2023-05-28 03:22:42,080] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 86.0 in stage 0.0 (TID 86). 1928 bytes result sent to driver
[2023-05-28 03:22:42,081] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 89.0 in stage 0.0 (TID 89) (c1224b457a2d, executor driver, partition 89, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,082] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 85.0 in stage 0.0 (TID 85)
[2023-05-28 03:22:42,083] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 89.0 in stage 0.0 (TID 89)
[2023-05-28 03:22:42,083] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 86.0 in stage 0.0 (TID 86) in 8 ms on c1224b457a2d (executor driver) (86/199)
[2023-05-28 03:22:42,084] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 87.0 in stage 0.0 (TID 87). 1928 bytes result sent to driver
[2023-05-28 03:22:42,084] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 90.0 in stage 0.0 (TID 90) (c1224b457a2d, executor driver, partition 90, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,085] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 87.0 in stage 0.0 (TID 87) in 9 ms on c1224b457a2d (executor driver) (87/199)
[2023-05-28 03:22:42,085] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 89.0 in stage 0.0 (TID 89). 1928 bytes result sent to driver
[2023-05-28 03:22:42,086] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 91.0 in stage 0.0 (TID 91) (c1224b457a2d, executor driver, partition 91, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,086] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 91.0 in stage 0.0 (TID 91)
[2023-05-28 03:22:42,087] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 89.0 in stage 0.0 (TID 89) in 6 ms on c1224b457a2d (executor driver) (88/199)
[2023-05-28 03:22:42,088] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 85.0 in stage 0.0 (TID 85). 1928 bytes result sent to driver
[2023-05-28 03:22:42,091] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 92.0 in stage 0.0 (TID 92) (c1224b457a2d, executor driver, partition 92, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,092] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 88.0 in stage 0.0 (TID 88). 1971 bytes result sent to driver
[2023-05-28 03:22:42,093] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 91.0 in stage 0.0 (TID 91). 1928 bytes result sent to driver
[2023-05-28 03:22:42,093] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 90.0 in stage 0.0 (TID 90)
[2023-05-28 03:22:42,094] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 93.0 in stage 0.0 (TID 93) (c1224b457a2d, executor driver, partition 93, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,094] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 94.0 in stage 0.0 (TID 94) (c1224b457a2d, executor driver, partition 94, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,094] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 93.0 in stage 0.0 (TID 93)
[2023-05-28 03:22:42,095] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 88.0 in stage 0.0 (TID 88) in 16 ms on c1224b457a2d (executor driver) (89/199)
[2023-05-28 03:22:42,095] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 91.0 in stage 0.0 (TID 91) in 8 ms on c1224b457a2d (executor driver) (90/199)
[2023-05-28 03:22:42,096] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 85.0 in stage 0.0 (TID 85) in 23 ms on c1224b457a2d (executor driver) (91/199)
[2023-05-28 03:22:42,096] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 92.0 in stage 0.0 (TID 92)
[2023-05-28 03:22:42,097] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 94.0 in stage 0.0 (TID 94)
[2023-05-28 03:22:42,099] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 92.0 in stage 0.0 (TID 92). 1928 bytes result sent to driver
[2023-05-28 03:22:42,113] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 90.0 in stage 0.0 (TID 90). 1971 bytes result sent to driver
[2023-05-28 03:22:42,114] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 95.0 in stage 0.0 (TID 95) (c1224b457a2d, executor driver, partition 95, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,114] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 96.0 in stage 0.0 (TID 96) (c1224b457a2d, executor driver, partition 96, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,115] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 90.0 in stage 0.0 (TID 90) in 34 ms on c1224b457a2d (executor driver) (92/199)
[2023-05-28 03:22:42,115] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 96.0 in stage 0.0 (TID 96)
[2023-05-28 03:22:42,117] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 94.0 in stage 0.0 (TID 94). 1928 bytes result sent to driver
[2023-05-28 03:22:42,117] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 93.0 in stage 0.0 (TID 93). 1928 bytes result sent to driver
[2023-05-28 03:22:42,118] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 95.0 in stage 0.0 (TID 95)
[2023-05-28 03:22:42,120] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 92.0 in stage 0.0 (TID 92) in 23 ms on c1224b457a2d (executor driver) (93/199)
[2023-05-28 03:22:42,122] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 97.0 in stage 0.0 (TID 97) (c1224b457a2d, executor driver, partition 97, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,125] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 98.0 in stage 0.0 (TID 98) (c1224b457a2d, executor driver, partition 98, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,128] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 98.0 in stage 0.0 (TID 98)
[2023-05-28 03:22:42,129] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 94.0 in stage 0.0 (TID 94) in 29 ms on c1224b457a2d (executor driver) (94/199)
[2023-05-28 03:22:42,130] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 93.0 in stage 0.0 (TID 93) in 30 ms on c1224b457a2d (executor driver) (95/199)
[2023-05-28 03:22:42,131] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 97.0 in stage 0.0 (TID 97)
[2023-05-28 03:22:42,131] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 96.0 in stage 0.0 (TID 96). 1928 bytes result sent to driver
[2023-05-28 03:22:42,131] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 99.0 in stage 0.0 (TID 99) (c1224b457a2d, executor driver, partition 99, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,132] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 99.0 in stage 0.0 (TID 99)
[2023-05-28 03:22:42,132] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 96.0 in stage 0.0 (TID 96) in 10 ms on c1224b457a2d (executor driver) (96/199)
[2023-05-28 03:22:42,133] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 95.0 in stage 0.0 (TID 95). 1971 bytes result sent to driver
[2023-05-28 03:22:42,133] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 99.0 in stage 0.0 (TID 99). 1928 bytes result sent to driver
[2023-05-28 03:22:42,134] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 100.0 in stage 0.0 (TID 100) (c1224b457a2d, executor driver, partition 100, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,134] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 101.0 in stage 0.0 (TID 101) (c1224b457a2d, executor driver, partition 101, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,134] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 98.0 in stage 0.0 (TID 98). 1928 bytes result sent to driver
[2023-05-28 03:22:42,135] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 102.0 in stage 0.0 (TID 102) (c1224b457a2d, executor driver, partition 102, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,135] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 98.0 in stage 0.0 (TID 98) in 8 ms on c1224b457a2d (executor driver) (97/199)
[2023-05-28 03:22:42,136] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 101.0 in stage 0.0 (TID 101)
[2023-05-28 03:22:42,136] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 99.0 in stage 0.0 (TID 99) in 6 ms on c1224b457a2d (executor driver) (98/199)
[2023-05-28 03:22:42,136] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 95.0 in stage 0.0 (TID 95) in 17 ms on c1224b457a2d (executor driver) (99/199)
[2023-05-28 03:22:42,137] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 102.0 in stage 0.0 (TID 102)
[2023-05-28 03:22:42,137] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 100.0 in stage 0.0 (TID 100)
[2023-05-28 03:22:42,137] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 97.0 in stage 0.0 (TID 97). 1971 bytes result sent to driver
[2023-05-28 03:22:42,138] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 103.0 in stage 0.0 (TID 103) (c1224b457a2d, executor driver, partition 103, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,138] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 103.0 in stage 0.0 (TID 103)
[2023-05-28 03:22:42,139] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 97.0 in stage 0.0 (TID 97) in 13 ms on c1224b457a2d (executor driver) (100/199)
[2023-05-28 03:22:42,140] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 101.0 in stage 0.0 (TID 101). 1971 bytes result sent to driver
[2023-05-28 03:22:42,140] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 104.0 in stage 0.0 (TID 104) (c1224b457a2d, executor driver, partition 104, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,141] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 104.0 in stage 0.0 (TID 104)
[2023-05-28 03:22:42,141] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 101.0 in stage 0.0 (TID 101) in 10 ms on c1224b457a2d (executor driver) (101/199)
[2023-05-28 03:22:42,141] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 103.0 in stage 0.0 (TID 103). 1971 bytes result sent to driver
[2023-05-28 03:22:42,142] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 105.0 in stage 0.0 (TID 105) (c1224b457a2d, executor driver, partition 105, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,142] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 103.0 in stage 0.0 (TID 103) in 9 ms on c1224b457a2d (executor driver) (102/199)
[2023-05-28 03:22:42,143] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 105.0 in stage 0.0 (TID 105)
[2023-05-28 03:22:42,144] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 100.0 in stage 0.0 (TID 100). 1928 bytes result sent to driver
[2023-05-28 03:22:42,149] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 106.0 in stage 0.0 (TID 106) (c1224b457a2d, executor driver, partition 106, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,149] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 106.0 in stage 0.0 (TID 106)
[2023-05-28 03:22:42,150] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 100.0 in stage 0.0 (TID 100) in 20 ms on c1224b457a2d (executor driver) (103/199)
[2023-05-28 03:22:42,150] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 105.0 in stage 0.0 (TID 105). 1971 bytes result sent to driver
[2023-05-28 03:22:42,151] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 104.0 in stage 0.0 (TID 104). 1928 bytes result sent to driver
[2023-05-28 03:22:42,152] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 102.0 in stage 0.0 (TID 102). 1971 bytes result sent to driver
[2023-05-28 03:22:42,152] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 107.0 in stage 0.0 (TID 107) (c1224b457a2d, executor driver, partition 107, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,153] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 104.0 in stage 0.0 (TID 104) in 14 ms on c1224b457a2d (executor driver) (104/199)
[2023-05-28 03:22:42,153] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 107.0 in stage 0.0 (TID 107)
[2023-05-28 03:22:42,154] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 108.0 in stage 0.0 (TID 108) (c1224b457a2d, executor driver, partition 108, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,154] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 105.0 in stage 0.0 (TID 105) in 14 ms on c1224b457a2d (executor driver) (105/199)
[2023-05-28 03:22:42,161] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 109.0 in stage 0.0 (TID 109) (c1224b457a2d, executor driver, partition 109, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,161] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 102.0 in stage 0.0 (TID 102) in 32 ms on c1224b457a2d (executor driver) (106/199)
[2023-05-28 03:22:42,162] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 106.0 in stage 0.0 (TID 106). 2014 bytes result sent to driver
[2023-05-28 03:22:42,162] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 109.0 in stage 0.0 (TID 109)
[2023-05-28 03:22:42,163] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 110.0 in stage 0.0 (TID 110) (c1224b457a2d, executor driver, partition 110, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,163] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 108.0 in stage 0.0 (TID 108)
[2023-05-28 03:22:42,164] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 110.0 in stage 0.0 (TID 110)
[2023-05-28 03:22:42,164] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 106.0 in stage 0.0 (TID 106) in 16 ms on c1224b457a2d (executor driver) (107/199)
[2023-05-28 03:22:42,170] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 110.0 in stage 0.0 (TID 110). 1928 bytes result sent to driver
[2023-05-28 03:22:42,175] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 111.0 in stage 0.0 (TID 111) (c1224b457a2d, executor driver, partition 111, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,176] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 111.0 in stage 0.0 (TID 111)
[2023-05-28 03:22:42,176] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 107.0 in stage 0.0 (TID 107). 1928 bytes result sent to driver
[2023-05-28 03:22:42,177] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 108.0 in stage 0.0 (TID 108). 1928 bytes result sent to driver
[2023-05-28 03:22:42,177] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 110.0 in stage 0.0 (TID 110) in 14 ms on c1224b457a2d (executor driver) (108/199)
[2023-05-28 03:22:42,177] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 112.0 in stage 0.0 (TID 112) (c1224b457a2d, executor driver, partition 112, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,178] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 112.0 in stage 0.0 (TID 112)
[2023-05-28 03:22:42,178] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 109.0 in stage 0.0 (TID 109). 1928 bytes result sent to driver
[2023-05-28 03:22:42,179] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 113.0 in stage 0.0 (TID 113) (c1224b457a2d, executor driver, partition 113, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,179] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 113.0 in stage 0.0 (TID 113)
[2023-05-28 03:22:42,179] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 114.0 in stage 0.0 (TID 114) (c1224b457a2d, executor driver, partition 114, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,180] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 114.0 in stage 0.0 (TID 114)
[2023-05-28 03:22:42,180] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 108.0 in stage 0.0 (TID 108) in 25 ms on c1224b457a2d (executor driver) (109/199)
[2023-05-28 03:22:42,180] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 109.0 in stage 0.0 (TID 109) in 19 ms on c1224b457a2d (executor driver) (110/199)
[2023-05-28 03:22:42,181] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 107.0 in stage 0.0 (TID 107) in 27 ms on c1224b457a2d (executor driver) (111/199)
[2023-05-28 03:22:42,184] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 112.0 in stage 0.0 (TID 112). 1928 bytes result sent to driver
[2023-05-28 03:22:42,186] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 115.0 in stage 0.0 (TID 115) (c1224b457a2d, executor driver, partition 115, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,187] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 112.0 in stage 0.0 (TID 112) in 10 ms on c1224b457a2d (executor driver) (112/199)
[2023-05-28 03:22:42,187] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 115.0 in stage 0.0 (TID 115)
[2023-05-28 03:22:42,188] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 113.0 in stage 0.0 (TID 113). 1928 bytes result sent to driver
[2023-05-28 03:22:42,190] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 114.0 in stage 0.0 (TID 114). 1928 bytes result sent to driver
[2023-05-28 03:22:42,190] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 116.0 in stage 0.0 (TID 116) (c1224b457a2d, executor driver, partition 116, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,191] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 114.0 in stage 0.0 (TID 114) in 13 ms on c1224b457a2d (executor driver) (113/199)
[2023-05-28 03:22:42,192] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 116.0 in stage 0.0 (TID 116)
[2023-05-28 03:22:42,192] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 117.0 in stage 0.0 (TID 117) (c1224b457a2d, executor driver, partition 117, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,193] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 113.0 in stage 0.0 (TID 113) in 16 ms on c1224b457a2d (executor driver) (114/199)
[2023-05-28 03:22:42,193] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 111.0 in stage 0.0 (TID 111). 1928 bytes result sent to driver
[2023-05-28 03:22:42,196] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 118.0 in stage 0.0 (TID 118) (c1224b457a2d, executor driver, partition 118, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,197] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 118.0 in stage 0.0 (TID 118)
[2023-05-28 03:22:42,197] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 111.0 in stage 0.0 (TID 111) in 21 ms on c1224b457a2d (executor driver) (115/199)
[2023-05-28 03:22:42,198] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 115.0 in stage 0.0 (TID 115). 1928 bytes result sent to driver
[2023-05-28 03:22:42,199] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 119.0 in stage 0.0 (TID 119) (c1224b457a2d, executor driver, partition 119, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,199] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 117.0 in stage 0.0 (TID 117)
[2023-05-28 03:22:42,199] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 119.0 in stage 0.0 (TID 119)
[2023-05-28 03:22:42,200] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 115.0 in stage 0.0 (TID 115) in 14 ms on c1224b457a2d (executor driver) (116/199)
[2023-05-28 03:22:42,202] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 119.0 in stage 0.0 (TID 119). 1928 bytes result sent to driver
[2023-05-28 03:22:42,203] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 120.0 in stage 0.0 (TID 120) (c1224b457a2d, executor driver, partition 120, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,204] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 120.0 in stage 0.0 (TID 120)
[2023-05-28 03:22:42,204] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 119.0 in stage 0.0 (TID 119) in 6 ms on c1224b457a2d (executor driver) (117/199)
[2023-05-28 03:22:42,207] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 120.0 in stage 0.0 (TID 120). 1928 bytes result sent to driver
[2023-05-28 03:22:42,208] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 121.0 in stage 0.0 (TID 121) (c1224b457a2d, executor driver, partition 121, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,209] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 120.0 in stage 0.0 (TID 120) in 5 ms on c1224b457a2d (executor driver) (118/199)
[2023-05-28 03:22:42,209] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 121.0 in stage 0.0 (TID 121)
[2023-05-28 03:22:42,212] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 121.0 in stage 0.0 (TID 121). 1928 bytes result sent to driver
[2023-05-28 03:22:42,213] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 122.0 in stage 0.0 (TID 122) (c1224b457a2d, executor driver, partition 122, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,222] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 117.0 in stage 0.0 (TID 117). 2014 bytes result sent to driver
[2023-05-28 03:22:42,222] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 121.0 in stage 0.0 (TID 121) in 15 ms on c1224b457a2d (executor driver) (119/199)
[2023-05-28 03:22:42,229] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 123.0 in stage 0.0 (TID 123) (c1224b457a2d, executor driver, partition 123, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,230] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 122.0 in stage 0.0 (TID 122)
[2023-05-28 03:22:42,230] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 117.0 in stage 0.0 (TID 117) in 38 ms on c1224b457a2d (executor driver) (120/199)
[2023-05-28 03:22:42,231] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 123.0 in stage 0.0 (TID 123)
[2023-05-28 03:22:42,232] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 116.0 in stage 0.0 (TID 116). 1928 bytes result sent to driver
[2023-05-28 03:22:42,233] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 118.0 in stage 0.0 (TID 118). 1971 bytes result sent to driver
[2023-05-28 03:22:42,234] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 124.0 in stage 0.0 (TID 124) (c1224b457a2d, executor driver, partition 124, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,235] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 116.0 in stage 0.0 (TID 116) in 44 ms on c1224b457a2d (executor driver) (121/199)
[2023-05-28 03:22:42,235] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 125.0 in stage 0.0 (TID 125) (c1224b457a2d, executor driver, partition 125, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,235] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 118.0 in stage 0.0 (TID 118) in 39 ms on c1224b457a2d (executor driver) (122/199)
[2023-05-28 03:22:42,236] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 122.0 in stage 0.0 (TID 122). 1928 bytes result sent to driver
[2023-05-28 03:22:42,236] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 125.0 in stage 0.0 (TID 125)
[2023-05-28 03:22:42,237] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 124.0 in stage 0.0 (TID 124)
[2023-05-28 03:22:42,237] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 126.0 in stage 0.0 (TID 126) (c1224b457a2d, executor driver, partition 126, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,238] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 122.0 in stage 0.0 (TID 122) in 24 ms on c1224b457a2d (executor driver) (123/199)
[2023-05-28 03:22:42,238] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 126.0 in stage 0.0 (TID 126)
[2023-05-28 03:22:42,239] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 123.0 in stage 0.0 (TID 123). 1971 bytes result sent to driver
[2023-05-28 03:22:42,240] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 127.0 in stage 0.0 (TID 127) (c1224b457a2d, executor driver, partition 127, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,241] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 123.0 in stage 0.0 (TID 123) in 10 ms on c1224b457a2d (executor driver) (124/199)
[2023-05-28 03:22:42,241] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 127.0 in stage 0.0 (TID 127)
[2023-05-28 03:22:42,242] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 126.0 in stage 0.0 (TID 126). 1928 bytes result sent to driver
[2023-05-28 03:22:42,242] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 125.0 in stage 0.0 (TID 125). 2014 bytes result sent to driver
[2023-05-28 03:22:42,242] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 126.0 in stage 0.0 (TID 126) in 6 ms on c1224b457a2d (executor driver) (125/199)
[2023-05-28 03:22:42,243] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 128.0 in stage 0.0 (TID 128) (c1224b457a2d, executor driver, partition 128, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,243] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 129.0 in stage 0.0 (TID 129) (c1224b457a2d, executor driver, partition 129, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,244] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 128.0 in stage 0.0 (TID 128)
[2023-05-28 03:22:42,244] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 125.0 in stage 0.0 (TID 125) in 9 ms on c1224b457a2d (executor driver) (126/199)
[2023-05-28 03:22:42,244] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 129.0 in stage 0.0 (TID 129)
[2023-05-28 03:22:42,250] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 124.0 in stage 0.0 (TID 124). 2014 bytes result sent to driver
[2023-05-28 03:22:42,252] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 130.0 in stage 0.0 (TID 130) (c1224b457a2d, executor driver, partition 130, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,253] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 124.0 in stage 0.0 (TID 124) in 18 ms on c1224b457a2d (executor driver) (127/199)
[2023-05-28 03:22:42,253] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 130.0 in stage 0.0 (TID 130)
[2023-05-28 03:22:42,254] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 129.0 in stage 0.0 (TID 129). 1971 bytes result sent to driver
[2023-05-28 03:22:42,254] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 127.0 in stage 0.0 (TID 127). 2014 bytes result sent to driver
[2023-05-28 03:22:42,255] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 128.0 in stage 0.0 (TID 128). 2014 bytes result sent to driver
[2023-05-28 03:22:42,255] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 131.0 in stage 0.0 (TID 131) (c1224b457a2d, executor driver, partition 131, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,256] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 129.0 in stage 0.0 (TID 129) in 14 ms on c1224b457a2d (executor driver) (128/199)
[2023-05-28 03:22:42,257] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 132.0 in stage 0.0 (TID 132) (c1224b457a2d, executor driver, partition 132, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,257] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 127.0 in stage 0.0 (TID 127) in 19 ms on c1224b457a2d (executor driver) (129/199)
[2023-05-28 03:22:42,258] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 133.0 in stage 0.0 (TID 133) (c1224b457a2d, executor driver, partition 133, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,259] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 128.0 in stage 0.0 (TID 128) in 17 ms on c1224b457a2d (executor driver) (130/199)
[2023-05-28 03:22:42,260] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 133.0 in stage 0.0 (TID 133)
[2023-05-28 03:22:42,261] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 132.0 in stage 0.0 (TID 132)
[2023-05-28 03:22:42,262] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 131.0 in stage 0.0 (TID 131)
[2023-05-28 03:22:42,263] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 133.0 in stage 0.0 (TID 133). 1928 bytes result sent to driver
[2023-05-28 03:22:42,264] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 134.0 in stage 0.0 (TID 134) (c1224b457a2d, executor driver, partition 134, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,265] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 134.0 in stage 0.0 (TID 134)
[2023-05-28 03:22:42,267] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 133.0 in stage 0.0 (TID 133) in 6 ms on c1224b457a2d (executor driver) (131/199)
[2023-05-28 03:22:42,270] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 131.0 in stage 0.0 (TID 131). 1928 bytes result sent to driver
[2023-05-28 03:22:42,271] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 135.0 in stage 0.0 (TID 135) (c1224b457a2d, executor driver, partition 135, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,272] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 132.0 in stage 0.0 (TID 132). 1971 bytes result sent to driver
[2023-05-28 03:22:42,273] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 135.0 in stage 0.0 (TID 135)
[2023-05-28 03:22:42,274] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 134.0 in stage 0.0 (TID 134). 1928 bytes result sent to driver
[2023-05-28 03:22:42,274] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 131.0 in stage 0.0 (TID 131) in 17 ms on c1224b457a2d (executor driver) (132/199)
[2023-05-28 03:22:42,275] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 135.0 in stage 0.0 (TID 135). 1928 bytes result sent to driver
[2023-05-28 03:22:42,276] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 136.0 in stage 0.0 (TID 136) (c1224b457a2d, executor driver, partition 136, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,278] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 130.0 in stage 0.0 (TID 130). 1971 bytes result sent to driver
[2023-05-28 03:22:42,278] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 137.0 in stage 0.0 (TID 137) (c1224b457a2d, executor driver, partition 137, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,279] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 136.0 in stage 0.0 (TID 136)
[2023-05-28 03:22:42,279] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 132.0 in stage 0.0 (TID 132) in 20 ms on c1224b457a2d (executor driver) (133/199)
[2023-05-28 03:22:42,279] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 137.0 in stage 0.0 (TID 137)
[2023-05-28 03:22:42,280] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 138.0 in stage 0.0 (TID 138) (c1224b457a2d, executor driver, partition 138, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,280] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 138.0 in stage 0.0 (TID 138)
[2023-05-28 03:22:42,280] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 134.0 in stage 0.0 (TID 134) in 14 ms on c1224b457a2d (executor driver) (134/199)
[2023-05-28 03:22:42,281] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 135.0 in stage 0.0 (TID 135) in 6 ms on c1224b457a2d (executor driver) (135/199)
[2023-05-28 03:22:42,282] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 139.0 in stage 0.0 (TID 139) (c1224b457a2d, executor driver, partition 139, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,283] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 130.0 in stage 0.0 (TID 130) in 27 ms on c1224b457a2d (executor driver) (136/199)
[2023-05-28 03:22:42,284] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 139.0 in stage 0.0 (TID 139)
[2023-05-28 03:22:42,284] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 137.0 in stage 0.0 (TID 137). 1971 bytes result sent to driver
[2023-05-28 03:22:42,285] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 140.0 in stage 0.0 (TID 140) (c1224b457a2d, executor driver, partition 140, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,286] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 137.0 in stage 0.0 (TID 137) in 6 ms on c1224b457a2d (executor driver) (137/199)
[2023-05-28 03:22:42,286] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 138.0 in stage 0.0 (TID 138). 1928 bytes result sent to driver
[2023-05-28 03:22:42,287] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 141.0 in stage 0.0 (TID 141) (c1224b457a2d, executor driver, partition 141, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,287] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 139.0 in stage 0.0 (TID 139). 1928 bytes result sent to driver
[2023-05-28 03:22:42,288] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 141.0 in stage 0.0 (TID 141)
[2023-05-28 03:22:42,288] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 138.0 in stage 0.0 (TID 138) in 7 ms on c1224b457a2d (executor driver) (138/199)
[2023-05-28 03:22:42,288] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 140.0 in stage 0.0 (TID 140)
[2023-05-28 03:22:42,292] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 141.0 in stage 0.0 (TID 141). 1928 bytes result sent to driver
[2023-05-28 03:22:42,292] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 136.0 in stage 0.0 (TID 136). 1928 bytes result sent to driver
[2023-05-28 03:22:42,293] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 142.0 in stage 0.0 (TID 142) (c1224b457a2d, executor driver, partition 142, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,294] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 143.0 in stage 0.0 (TID 143) (c1224b457a2d, executor driver, partition 143, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,294] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 141.0 in stage 0.0 (TID 141) in 10 ms on c1224b457a2d (executor driver) (139/199)
[2023-05-28 03:22:42,294] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 143.0 in stage 0.0 (TID 143)
[2023-05-28 03:22:42,295] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 139.0 in stage 0.0 (TID 139) in 15 ms on c1224b457a2d (executor driver) (140/199)
[2023-05-28 03:22:42,295] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 142.0 in stage 0.0 (TID 142)
[2023-05-28 03:22:42,296] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 144.0 in stage 0.0 (TID 144) (c1224b457a2d, executor driver, partition 144, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,296] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 136.0 in stage 0.0 (TID 136) in 20 ms on c1224b457a2d (executor driver) (141/199)
[2023-05-28 03:22:42,297] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 143.0 in stage 0.0 (TID 143). 1928 bytes result sent to driver
[2023-05-28 03:22:42,298] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 144.0 in stage 0.0 (TID 144)
[2023-05-28 03:22:42,299] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 145.0 in stage 0.0 (TID 145) (c1224b457a2d, executor driver, partition 145, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,299] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 143.0 in stage 0.0 (TID 143) in 4 ms on c1224b457a2d (executor driver) (142/199)
[2023-05-28 03:22:42,300] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 145.0 in stage 0.0 (TID 145)
[2023-05-28 03:22:42,308] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 140.0 in stage 0.0 (TID 140). 1971 bytes result sent to driver
[2023-05-28 03:22:42,309] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 144.0 in stage 0.0 (TID 144). 1928 bytes result sent to driver
[2023-05-28 03:22:42,310] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 146.0 in stage 0.0 (TID 146) (c1224b457a2d, executor driver, partition 146, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,310] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 140.0 in stage 0.0 (TID 140) in 27 ms on c1224b457a2d (executor driver) (143/199)
[2023-05-28 03:22:42,311] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 145.0 in stage 0.0 (TID 145). 1971 bytes result sent to driver
[2023-05-28 03:22:42,311] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 147.0 in stage 0.0 (TID 147) (c1224b457a2d, executor driver, partition 147, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,311] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 147.0 in stage 0.0 (TID 147)
[2023-05-28 03:22:42,312] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 145.0 in stage 0.0 (TID 145) in 13 ms on c1224b457a2d (executor driver) (144/199)
[2023-05-28 03:22:42,312] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 146.0 in stage 0.0 (TID 146)
[2023-05-28 03:22:42,313] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 142.0 in stage 0.0 (TID 142). 1971 bytes result sent to driver
[2023-05-28 03:22:42,316] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 148.0 in stage 0.0 (TID 148) (c1224b457a2d, executor driver, partition 148, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,317] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 142.0 in stage 0.0 (TID 142) in 24 ms on c1224b457a2d (executor driver) (145/199)
[2023-05-28 03:22:42,317] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 148.0 in stage 0.0 (TID 148)
[2023-05-28 03:22:42,321] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 149.0 in stage 0.0 (TID 149) (c1224b457a2d, executor driver, partition 149, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,321] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 144.0 in stage 0.0 (TID 144) in 27 ms on c1224b457a2d (executor driver) (146/199)
[2023-05-28 03:22:42,328] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 148.0 in stage 0.0 (TID 148). 2014 bytes result sent to driver
[2023-05-28 03:22:42,329] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 150.0 in stage 0.0 (TID 150) (c1224b457a2d, executor driver, partition 150, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,329] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 150.0 in stage 0.0 (TID 150)
[2023-05-28 03:22:42,329] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 148.0 in stage 0.0 (TID 148) in 13 ms on c1224b457a2d (executor driver) (147/199)
[2023-05-28 03:22:42,330] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 147.0 in stage 0.0 (TID 147). 2014 bytes result sent to driver
[2023-05-28 03:22:42,330] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 151.0 in stage 0.0 (TID 151) (c1224b457a2d, executor driver, partition 151, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,331] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 151.0 in stage 0.0 (TID 151)
[2023-05-28 03:22:42,331] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 147.0 in stage 0.0 (TID 147) in 22 ms on c1224b457a2d (executor driver) (148/199)
[2023-05-28 03:22:42,333] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 150.0 in stage 0.0 (TID 150). 1928 bytes result sent to driver
[2023-05-28 03:22:42,334] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 152.0 in stage 0.0 (TID 152) (c1224b457a2d, executor driver, partition 152, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,334] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 152.0 in stage 0.0 (TID 152)
[2023-05-28 03:22:42,334] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 150.0 in stage 0.0 (TID 150) in 6 ms on c1224b457a2d (executor driver) (149/199)
[2023-05-28 03:22:42,336] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 151.0 in stage 0.0 (TID 151). 1928 bytes result sent to driver
[2023-05-28 03:22:42,337] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 153.0 in stage 0.0 (TID 153) (c1224b457a2d, executor driver, partition 153, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,338] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 152.0 in stage 0.0 (TID 152). 1928 bytes result sent to driver
[2023-05-28 03:22:42,338] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 151.0 in stage 0.0 (TID 151) in 7 ms on c1224b457a2d (executor driver) (150/199)
[2023-05-28 03:22:42,339] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 154.0 in stage 0.0 (TID 154) (c1224b457a2d, executor driver, partition 154, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,339] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 152.0 in stage 0.0 (TID 152) in 5 ms on c1224b457a2d (executor driver) (151/199)
[2023-05-28 03:22:42,339] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 154.0 in stage 0.0 (TID 154)
[2023-05-28 03:22:42,340] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 153.0 in stage 0.0 (TID 153)
[2023-05-28 03:22:42,344] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 154.0 in stage 0.0 (TID 154). 1928 bytes result sent to driver
[2023-05-28 03:22:42,352] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 155.0 in stage 0.0 (TID 155) (c1224b457a2d, executor driver, partition 155, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,355] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 149.0 in stage 0.0 (TID 149)
[2023-05-28 03:22:42,355] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 154.0 in stage 0.0 (TID 154) in 14 ms on c1224b457a2d (executor driver) (152/199)
[2023-05-28 03:22:42,356] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 155.0 in stage 0.0 (TID 155)
[2023-05-28 03:22:42,356] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 146.0 in stage 0.0 (TID 146). 2014 bytes result sent to driver
[2023-05-28 03:22:42,357] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 156.0 in stage 0.0 (TID 156) (c1224b457a2d, executor driver, partition 156, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,357] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 146.0 in stage 0.0 (TID 146) in 47 ms on c1224b457a2d (executor driver) (153/199)
[2023-05-28 03:22:42,359] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 156.0 in stage 0.0 (TID 156)
[2023-05-28 03:22:42,359] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 155.0 in stage 0.0 (TID 155). 1971 bytes result sent to driver
[2023-05-28 03:22:42,360] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 157.0 in stage 0.0 (TID 157) (c1224b457a2d, executor driver, partition 157, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,360] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 155.0 in stage 0.0 (TID 155) in 7 ms on c1224b457a2d (executor driver) (154/199)
[2023-05-28 03:22:42,362] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 156.0 in stage 0.0 (TID 156). 1928 bytes result sent to driver
[2023-05-28 03:22:42,363] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 158.0 in stage 0.0 (TID 158) (c1224b457a2d, executor driver, partition 158, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,363] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 156.0 in stage 0.0 (TID 156) in 8 ms on c1224b457a2d (executor driver) (155/199)
[2023-05-28 03:22:42,364] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 157.0 in stage 0.0 (TID 157)
[2023-05-28 03:22:42,366] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 158.0 in stage 0.0 (TID 158)
[2023-05-28 03:22:42,395] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 157.0 in stage 0.0 (TID 157). 1971 bytes result sent to driver
[2023-05-28 03:22:42,396] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 159.0 in stage 0.0 (TID 159) (c1224b457a2d, executor driver, partition 159, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,396] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 159.0 in stage 0.0 (TID 159)
[2023-05-28 03:22:42,397] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 157.0 in stage 0.0 (TID 157) in 38 ms on c1224b457a2d (executor driver) (156/199)
[2023-05-28 03:22:42,398] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 153.0 in stage 0.0 (TID 153). 1971 bytes result sent to driver
[2023-05-28 03:22:42,399] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 149.0 in stage 0.0 (TID 149). 1928 bytes result sent to driver
[2023-05-28 03:22:42,401] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 160.0 in stage 0.0 (TID 160) (c1224b457a2d, executor driver, partition 160, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,402] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 161.0 in stage 0.0 (TID 161) (c1224b457a2d, executor driver, partition 161, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,402] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 153.0 in stage 0.0 (TID 153) in 65 ms on c1224b457a2d (executor driver) (157/199)
[2023-05-28 03:22:42,403] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 149.0 in stage 0.0 (TID 149) in 82 ms on c1224b457a2d (executor driver) (158/199)
[2023-05-28 03:22:42,405] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 159.0 in stage 0.0 (TID 159). 1928 bytes result sent to driver
[2023-05-28 03:22:42,406] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 162.0 in stage 0.0 (TID 162) (c1224b457a2d, executor driver, partition 162, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,406] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 159.0 in stage 0.0 (TID 159) in 11 ms on c1224b457a2d (executor driver) (159/199)
[2023-05-28 03:22:42,412] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 162.0 in stage 0.0 (TID 162)
[2023-05-28 03:22:42,413] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 162.0 in stage 0.0 (TID 162). 1928 bytes result sent to driver
[2023-05-28 03:22:42,413] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 163.0 in stage 0.0 (TID 163) (c1224b457a2d, executor driver, partition 163, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,413] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 162.0 in stage 0.0 (TID 162) in 6 ms on c1224b457a2d (executor driver) (160/199)
[2023-05-28 03:22:42,414] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 163.0 in stage 0.0 (TID 163)
[2023-05-28 03:22:42,416] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 160.0 in stage 0.0 (TID 160)
[2023-05-28 03:22:42,420] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 163.0 in stage 0.0 (TID 163). 1971 bytes result sent to driver
[2023-05-28 03:22:42,421] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 164.0 in stage 0.0 (TID 164) (c1224b457a2d, executor driver, partition 164, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,422] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 164.0 in stage 0.0 (TID 164)
[2023-05-28 03:22:42,423] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 163.0 in stage 0.0 (TID 163) in 10 ms on c1224b457a2d (executor driver) (161/199)
[2023-05-28 03:22:42,424] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 158.0 in stage 0.0 (TID 158). 1971 bytes result sent to driver
[2023-05-28 03:22:42,425] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 165.0 in stage 0.0 (TID 165) (c1224b457a2d, executor driver, partition 165, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,426] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 158.0 in stage 0.0 (TID 158) in 61 ms on c1224b457a2d (executor driver) (162/199)
[2023-05-28 03:22:42,427] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 165.0 in stage 0.0 (TID 165)
[2023-05-28 03:22:42,427] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 164.0 in stage 0.0 (TID 164). 1928 bytes result sent to driver
[2023-05-28 03:22:42,428] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 166.0 in stage 0.0 (TID 166) (c1224b457a2d, executor driver, partition 166, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,428] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 164.0 in stage 0.0 (TID 164) in 6 ms on c1224b457a2d (executor driver) (163/199)
[2023-05-28 03:22:42,429] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 166.0 in stage 0.0 (TID 166)
[2023-05-28 03:22:42,432] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 161.0 in stage 0.0 (TID 161)
[2023-05-28 03:22:42,435] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 165.0 in stage 0.0 (TID 165). 1928 bytes result sent to driver
[2023-05-28 03:22:42,437] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 167.0 in stage 0.0 (TID 167) (c1224b457a2d, executor driver, partition 167, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,437] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 161.0 in stage 0.0 (TID 161). 1928 bytes result sent to driver
[2023-05-28 03:22:42,437] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 165.0 in stage 0.0 (TID 165) in 13 ms on c1224b457a2d (executor driver) (164/199)
[2023-05-28 03:22:42,438] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 167.0 in stage 0.0 (TID 167)
[2023-05-28 03:22:42,442] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 160.0 in stage 0.0 (TID 160). 1971 bytes result sent to driver
[2023-05-28 03:22:42,443] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 168.0 in stage 0.0 (TID 168) (c1224b457a2d, executor driver, partition 168, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,443] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 160.0 in stage 0.0 (TID 160) in 43 ms on c1224b457a2d (executor driver) (165/199)
[2023-05-28 03:22:42,444] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 168.0 in stage 0.0 (TID 168)
[2023-05-28 03:22:42,449] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 167.0 in stage 0.0 (TID 167). 1928 bytes result sent to driver
[2023-05-28 03:22:42,450] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 169.0 in stage 0.0 (TID 169) (c1224b457a2d, executor driver, partition 169, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,450] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 167.0 in stage 0.0 (TID 167) in 14 ms on c1224b457a2d (executor driver) (166/199)
[2023-05-28 03:22:42,451] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 169.0 in stage 0.0 (TID 169)
[2023-05-28 03:22:42,452] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 166.0 in stage 0.0 (TID 166). 1928 bytes result sent to driver
[2023-05-28 03:22:42,454] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 170.0 in stage 0.0 (TID 170) (c1224b457a2d, executor driver, partition 170, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,455] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 171.0 in stage 0.0 (TID 171) (c1224b457a2d, executor driver, partition 171, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,455] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 170.0 in stage 0.0 (TID 170)
[2023-05-28 03:22:42,456] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 166.0 in stage 0.0 (TID 166) in 29 ms on c1224b457a2d (executor driver) (167/199)
[2023-05-28 03:22:42,456] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 161.0 in stage 0.0 (TID 161) in 53 ms on c1224b457a2d (executor driver) (168/199)
[2023-05-28 03:22:42,456] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 171.0 in stage 0.0 (TID 171)
[2023-05-28 03:22:42,461] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 168.0 in stage 0.0 (TID 168). 1971 bytes result sent to driver
[2023-05-28 03:22:42,462] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 172.0 in stage 0.0 (TID 172) (c1224b457a2d, executor driver, partition 172, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,462] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 170.0 in stage 0.0 (TID 170). 1971 bytes result sent to driver
[2023-05-28 03:22:42,463] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 168.0 in stage 0.0 (TID 168) in 20 ms on c1224b457a2d (executor driver) (169/199)
[2023-05-28 03:22:42,463] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 172.0 in stage 0.0 (TID 172)
[2023-05-28 03:22:42,467] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 172.0 in stage 0.0 (TID 172). 1928 bytes result sent to driver
[2023-05-28 03:22:42,473] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 173.0 in stage 0.0 (TID 173) (c1224b457a2d, executor driver, partition 173, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,474] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 172.0 in stage 0.0 (TID 172) in 13 ms on c1224b457a2d (executor driver) (170/199)
[2023-05-28 03:22:42,475] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 173.0 in stage 0.0 (TID 173)
[2023-05-28 03:22:42,475] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 171.0 in stage 0.0 (TID 171). 1971 bytes result sent to driver
[2023-05-28 03:22:42,477] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 169.0 in stage 0.0 (TID 169). 1971 bytes result sent to driver
[2023-05-28 03:22:42,477] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 174.0 in stage 0.0 (TID 174) (c1224b457a2d, executor driver, partition 174, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,478] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 174.0 in stage 0.0 (TID 174)
[2023-05-28 03:22:42,478] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 170.0 in stage 0.0 (TID 170) in 25 ms on c1224b457a2d (executor driver) (171/199)
[2023-05-28 03:22:42,491] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 174.0 in stage 0.0 (TID 174). 2014 bytes result sent to driver
[2023-05-28 03:22:42,492] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 175.0 in stage 0.0 (TID 175) (c1224b457a2d, executor driver, partition 175, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,492] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 176.0 in stage 0.0 (TID 176) (c1224b457a2d, executor driver, partition 176, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,494] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 169.0 in stage 0.0 (TID 169) in 44 ms on c1224b457a2d (executor driver) (172/199)
[2023-05-28 03:22:42,495] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 171.0 in stage 0.0 (TID 171) in 41 ms on c1224b457a2d (executor driver) (173/199)
[2023-05-28 03:22:42,495] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 176.0 in stage 0.0 (TID 176)
[2023-05-28 03:22:42,496] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 175.0 in stage 0.0 (TID 175)
[2023-05-28 03:22:42,497] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 173.0 in stage 0.0 (TID 173). 1928 bytes result sent to driver
[2023-05-28 03:22:42,499] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 176.0 in stage 0.0 (TID 176). 1928 bytes result sent to driver
[2023-05-28 03:22:42,505] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 177.0 in stage 0.0 (TID 177) (c1224b457a2d, executor driver, partition 177, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,506] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 178.0 in stage 0.0 (TID 178) (c1224b457a2d, executor driver, partition 178, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,507] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 178.0 in stage 0.0 (TID 178)
[2023-05-28 03:22:42,507] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 173.0 in stage 0.0 (TID 173) in 27 ms on c1224b457a2d (executor driver) (174/199)
[2023-05-28 03:22:42,508] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 176.0 in stage 0.0 (TID 176) in 9 ms on c1224b457a2d (executor driver) (175/199)
[2023-05-28 03:22:42,508] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 177.0 in stage 0.0 (TID 177)
[2023-05-28 03:22:42,508] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 178.0 in stage 0.0 (TID 178). 1928 bytes result sent to driver
[2023-05-28 03:22:42,509] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 179.0 in stage 0.0 (TID 179) (c1224b457a2d, executor driver, partition 179, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,509] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 178.0 in stage 0.0 (TID 178) in 7 ms on c1224b457a2d (executor driver) (176/199)
[2023-05-28 03:22:42,510] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 179.0 in stage 0.0 (TID 179)
[2023-05-28 03:22:42,510] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 180.0 in stage 0.0 (TID 180) (c1224b457a2d, executor driver, partition 180, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,511] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 175.0 in stage 0.0 (TID 175). 1928 bytes result sent to driver
[2023-05-28 03:22:42,511] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 174.0 in stage 0.0 (TID 174) in 34 ms on c1224b457a2d (executor driver) (177/199)
[2023-05-28 03:22:42,512] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 180.0 in stage 0.0 (TID 180)
[2023-05-28 03:22:42,512] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 181.0 in stage 0.0 (TID 181) (c1224b457a2d, executor driver, partition 181, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,513] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 175.0 in stage 0.0 (TID 175) in 21 ms on c1224b457a2d (executor driver) (178/199)
[2023-05-28 03:22:42,513] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 181.0 in stage 0.0 (TID 181)
[2023-05-28 03:22:42,515] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 181.0 in stage 0.0 (TID 181). 1928 bytes result sent to driver
[2023-05-28 03:22:42,516] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 182.0 in stage 0.0 (TID 182) (c1224b457a2d, executor driver, partition 182, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,517] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 182.0 in stage 0.0 (TID 182)
[2023-05-28 03:22:42,517] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 181.0 in stage 0.0 (TID 181) in 7 ms on c1224b457a2d (executor driver) (179/199)
[2023-05-28 03:22:42,522] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 182.0 in stage 0.0 (TID 182). 1928 bytes result sent to driver
[2023-05-28 03:22:42,523] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 183.0 in stage 0.0 (TID 183) (c1224b457a2d, executor driver, partition 183, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,524] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 182.0 in stage 0.0 (TID 182) in 8 ms on c1224b457a2d (executor driver) (180/199)
[2023-05-28 03:22:42,524] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 183.0 in stage 0.0 (TID 183)
[2023-05-28 03:22:42,528] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 179.0 in stage 0.0 (TID 179). 1971 bytes result sent to driver
[2023-05-28 03:22:42,531] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 177.0 in stage 0.0 (TID 177). 2014 bytes result sent to driver
[2023-05-28 03:22:42,533] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 184.0 in stage 0.0 (TID 184) (c1224b457a2d, executor driver, partition 184, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,533] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 184.0 in stage 0.0 (TID 184)
[2023-05-28 03:22:42,533] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 185.0 in stage 0.0 (TID 185) (c1224b457a2d, executor driver, partition 185, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,534] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 179.0 in stage 0.0 (TID 179) in 27 ms on c1224b457a2d (executor driver) (181/199)
[2023-05-28 03:22:42,534] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 177.0 in stage 0.0 (TID 177) in 34 ms on c1224b457a2d (executor driver) (182/199)
[2023-05-28 03:22:42,535] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 185.0 in stage 0.0 (TID 185)
[2023-05-28 03:22:42,538] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 184.0 in stage 0.0 (TID 184). 1928 bytes result sent to driver
[2023-05-28 03:22:42,541] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 180.0 in stage 0.0 (TID 180). 1971 bytes result sent to driver
[2023-05-28 03:22:42,541] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 185.0 in stage 0.0 (TID 185). 1928 bytes result sent to driver
[2023-05-28 03:22:42,542] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 183.0 in stage 0.0 (TID 183). 1971 bytes result sent to driver
[2023-05-28 03:22:42,542] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 186.0 in stage 0.0 (TID 186) (c1224b457a2d, executor driver, partition 186, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,543] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 184.0 in stage 0.0 (TID 184) in 11 ms on c1224b457a2d (executor driver) (183/199)
[2023-05-28 03:22:42,543] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 186.0 in stage 0.0 (TID 186)
[2023-05-28 03:22:42,549] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 186.0 in stage 0.0 (TID 186). 1928 bytes result sent to driver
[2023-05-28 03:22:42,551] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 187.0 in stage 0.0 (TID 187) (c1224b457a2d, executor driver, partition 187, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,564] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 183.0 in stage 0.0 (TID 183) in 28 ms on c1224b457a2d (executor driver) (184/199)
[2023-05-28 03:22:42,565] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 187.0 in stage 0.0 (TID 187)
[2023-05-28 03:22:42,566] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 188.0 in stage 0.0 (TID 188) (c1224b457a2d, executor driver, partition 188, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,567] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 189.0 in stage 0.0 (TID 189) (c1224b457a2d, executor driver, partition 189, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,567] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 186.0 in stage 0.0 (TID 186) in 26 ms on c1224b457a2d (executor driver) (185/199)
[2023-05-28 03:22:42,568] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 180.0 in stage 0.0 (TID 180) in 58 ms on c1224b457a2d (executor driver) (186/199)
[2023-05-28 03:22:42,568] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 188.0 in stage 0.0 (TID 188)
[2023-05-28 03:22:42,568] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 189.0 in stage 0.0 (TID 189)
[2023-05-28 03:22:42,571] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 190.0 in stage 0.0 (TID 190) (c1224b457a2d, executor driver, partition 190, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,572] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 185.0 in stage 0.0 (TID 185) in 38 ms on c1224b457a2d (executor driver) (187/199)
[2023-05-28 03:22:42,572] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 190.0 in stage 0.0 (TID 190)
[2023-05-28 03:22:42,574] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 187.0 in stage 0.0 (TID 187). 1928 bytes result sent to driver
[2023-05-28 03:22:42,577] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 191.0 in stage 0.0 (TID 191) (c1224b457a2d, executor driver, partition 191, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,577] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 191.0 in stage 0.0 (TID 191)
[2023-05-28 03:22:42,577] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 187.0 in stage 0.0 (TID 187) in 26 ms on c1224b457a2d (executor driver) (188/199)
[2023-05-28 03:22:42,581] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 191.0 in stage 0.0 (TID 191). 1928 bytes result sent to driver
[2023-05-28 03:22:42,582] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 192.0 in stage 0.0 (TID 192) (c1224b457a2d, executor driver, partition 192, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,582] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 192.0 in stage 0.0 (TID 192)
[2023-05-28 03:22:42,583] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 191.0 in stage 0.0 (TID 191) in 5 ms on c1224b457a2d (executor driver) (189/199)
[2023-05-28 03:22:42,584] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 188.0 in stage 0.0 (TID 188). 1971 bytes result sent to driver
[2023-05-28 03:22:42,585] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 189.0 in stage 0.0 (TID 189). 1928 bytes result sent to driver
[2023-05-28 03:22:42,588] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 193.0 in stage 0.0 (TID 193) (c1224b457a2d, executor driver, partition 193, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,589] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 193.0 in stage 0.0 (TID 193)
[2023-05-28 03:22:42,590] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 194.0 in stage 0.0 (TID 194) (c1224b457a2d, executor driver, partition 194, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,593] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 190.0 in stage 0.0 (TID 190). 1971 bytes result sent to driver
[2023-05-28 03:22:42,594] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 189.0 in stage 0.0 (TID 189) in 27 ms on c1224b457a2d (executor driver) (190/199)
[2023-05-28 03:22:42,595] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 188.0 in stage 0.0 (TID 188) in 28 ms on c1224b457a2d (executor driver) (191/199)
[2023-05-28 03:22:42,596] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 194.0 in stage 0.0 (TID 194)
[2023-05-28 03:22:42,597] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 195.0 in stage 0.0 (TID 195) (c1224b457a2d, executor driver, partition 195, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,599] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 190.0 in stage 0.0 (TID 190) in 26 ms on c1224b457a2d (executor driver) (192/199)
[2023-05-28 03:22:42,601] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 195.0 in stage 0.0 (TID 195)
[2023-05-28 03:22:42,602] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 192.0 in stage 0.0 (TID 192). 1928 bytes result sent to driver
[2023-05-28 03:22:42,603] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 196.0 in stage 0.0 (TID 196) (c1224b457a2d, executor driver, partition 196, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,604] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 192.0 in stage 0.0 (TID 192) in 24 ms on c1224b457a2d (executor driver) (193/199)
[2023-05-28 03:22:42,604] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 196.0 in stage 0.0 (TID 196)
[2023-05-28 03:22:42,607] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 195.0 in stage 0.0 (TID 195). 1928 bytes result sent to driver
[2023-05-28 03:22:42,618] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 194.0 in stage 0.0 (TID 194). 1928 bytes result sent to driver
[2023-05-28 03:22:42,619] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 196.0 in stage 0.0 (TID 196). 1928 bytes result sent to driver
[2023-05-28 03:22:42,619] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 197.0 in stage 0.0 (TID 197) (c1224b457a2d, executor driver, partition 197, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,620] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 197.0 in stage 0.0 (TID 197)
[2023-05-28 03:22:42,621] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 198.0 in stage 0.0 (TID 198) (c1224b457a2d, executor driver, partition 198, PROCESS_LOCAL, 7500 bytes)
[2023-05-28 03:22:42,622] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 198.0 in stage 0.0 (TID 198)
[2023-05-28 03:22:42,622] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 193.0 in stage 0.0 (TID 193). 1971 bytes result sent to driver
[2023-05-28 03:22:42,623] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 196.0 in stage 0.0 (TID 196) in 19 ms on c1224b457a2d (executor driver) (194/199)
[2023-05-28 03:22:42,623] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 194.0 in stage 0.0 (TID 194) in 34 ms on c1224b457a2d (executor driver) (195/199)
[2023-05-28 03:22:42,632] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 198.0 in stage 0.0 (TID 198). 2014 bytes result sent to driver
[2023-05-28 03:22:42,637] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Finished task 197.0 in stage 0.0 (TID 197). 2014 bytes result sent to driver
[2023-05-28 03:22:42,638] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 195.0 in stage 0.0 (TID 195) in 42 ms on c1224b457a2d (executor driver) (196/199)
[2023-05-28 03:22:42,639] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 197.0 in stage 0.0 (TID 197) in 22 ms on c1224b457a2d (executor driver) (197/199)
[2023-05-28 03:22:42,640] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 198.0 in stage 0.0 (TID 198) in 23 ms on c1224b457a2d (executor driver) (198/199)
[2023-05-28 03:22:42,641] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Finished task 193.0 in stage 0.0 (TID 193) in 52 ms on c1224b457a2d (executor driver) (199/199)
[2023-05-28 03:22:42,642] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: ResultStage 0 (load at NativeMethodAccessorImpl.java:0) finished in 1.289 s
[2023-05-28 03:22:42,645] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2023-05-28 03:22:42,648] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-05-28 03:22:42,649] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2023-05-28 03:22:42,652] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Job 0 finished: load at NativeMethodAccessorImpl.java:0, took 1.341091 s
[2023-05-28 03:22:42,698] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO InMemoryFileIndex: It took 1612 ms to list leaf files for 199 paths.
[2023-05-28 03:22:42,798] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO SparkContext: Starting job: load at NativeMethodAccessorImpl.java:0
[2023-05-28 03:22:42,799] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Got job 1 (load at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-05-28 03:22:42,800] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Final stage: ResultStage 1 (load at NativeMethodAccessorImpl.java:0)
[2023-05-28 03:22:42,801] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Parents of final stage: List()
[2023-05-28 03:22:42,801] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Missing parents: List()
[2023-05-28 03:22:42,802] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[4] at load at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-28 03:22:42,805] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 103.2 KiB, free 434.2 MiB)
[2023-05-28 03:22:42,807] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 434.1 MiB)
[2023-05-28 03:22:42,808] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on c1224b457a2d:37283 (size: 37.1 KiB, free: 434.3 MiB)
[2023-05-28 03:22:42,808] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
[2023-05-28 03:22:42,809] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at load at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-05-28 03:22:42,809] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2023-05-28 03:22:42,811] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 199) (c1224b457a2d, executor driver, partition 0, PROCESS_LOCAL, 7596 bytes)
[2023-05-28 03:22:42,811] {spark_submit.py:490} INFO - 23/05/28 03:22:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 199)
[2023-05-28 03:22:43,028] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 199). 2072 bytes result sent to driver
[2023-05-28 03:22:43,029] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 199) in 219 ms on c1224b457a2d (executor driver) (1/1)
[2023-05-28 03:22:43,030] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2023-05-28 03:22:43,032] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO DAGScheduler: ResultStage 1 (load at NativeMethodAccessorImpl.java:0) finished in 0.229 s
[2023-05-28 03:22:43,033] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-05-28 03:22:43,033] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2023-05-28 03:22:43,034] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO DAGScheduler: Job 1 finished: load at NativeMethodAccessorImpl.java:0, took 0.232606 s
[2023-05-28 03:22:43,408] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on c1224b457a2d:37283 in memory (size: 37.1 KiB, free: 434.4 MiB)
[2023-05-28 03:22:43,416] {spark_submit.py:490} INFO - 23/05/28 03:22:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on c1224b457a2d:37283 in memory (size: 36.9 KiB, free: 434.4 MiB)
[2023-05-28 03:22:44,062] {spark_submit.py:490} INFO - /usr/local/spark/staging/20230528/feature_engineering/stocks.parquet
[2023-05-28 03:22:44,329] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileSourceStrategy: Pushed Filters:
[2023-05-28 03:22:44,330] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileSourceStrategy: Post-Scan Filters:
[2023-05-28 03:22:44,629] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO CodeGenerator: Code generated in 147.220875 ms
[2023-05-28 03:22:44,643] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.9 KiB, free 434.2 MiB)
[2023-05-28 03:22:44,662] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 434.2 MiB)
[2023-05-28 03:22:44,667] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on c1224b457a2d:37283 (size: 35.0 KiB, free: 434.4 MiB)
[2023-05-28 03:22:44,668] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO SparkContext: Created broadcast 2 from parquet at NativeMethodAccessorImpl.java:0
[2023-05-28 03:22:44,685] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2023-05-28 03:22:44,789] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Registering RDD 8 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2023-05-28 03:22:44,792] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Got map stage job 2 (parquet at NativeMethodAccessorImpl.java:0) with 11 output partitions
[2023-05-28 03:22:44,793] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0)
[2023-05-28 03:22:44,793] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Parents of final stage: List()
[2023-05-28 03:22:44,794] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Missing parents: List()
[2023-05-28 03:22:44,798] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-28 03:22:44,844] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.8 KiB, free 434.1 MiB)
[2023-05-28 03:22:44,845] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 434.1 MiB)
[2023-05-28 03:22:44,846] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on c1224b457a2d:37283 (size: 8.6 KiB, free: 434.4 MiB)
[2023-05-28 03:22:44,847] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
[2023-05-28 03:22:44,849] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2023-05-28 03:22:44,850] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 11 tasks resource profile 0
[2023-05-28 03:22:44,854] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 200) (c1224b457a2d, executor driver, partition 0, PROCESS_LOCAL, 9717 bytes)
[2023-05-28 03:22:44,855] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 201) (c1224b457a2d, executor driver, partition 1, PROCESS_LOCAL, 10097 bytes)
[2023-05-28 03:22:44,855] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 202) (c1224b457a2d, executor driver, partition 2, PROCESS_LOCAL, 10477 bytes)
[2023-05-28 03:22:44,856] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 203) (c1224b457a2d, executor driver, partition 3, PROCESS_LOCAL, 10667 bytes)
[2023-05-28 03:22:44,856] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 201)
[2023-05-28 03:22:44,856] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 200)
[2023-05-28 03:22:44,860] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO Executor: Running task 3.0 in stage 2.0 (TID 203)
[2023-05-28 03:22:44,861] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO Executor: Running task 2.0 in stage 2.0 (TID 202)
[2023-05-28 03:22:44,948] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO CodeGenerator: Code generated in 15.444167 ms
[2023-05-28 03:22:44,958] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00021-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6465344, partition values: [empty row]
[2023-05-28 03:22:44,960] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00015-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7099465, partition values: [empty row]
[2023-05-28 03:22:44,961] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00037-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5127883, partition values: [empty row]
[2023-05-28 03:22:44,962] {spark_submit.py:490} INFO - 23/05/28 03:22:44 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00000-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-13352657, partition values: [empty row]
[2023-05-28 03:22:45,278] {spark_submit.py:490} INFO - 23/05/28 03:22:45 INFO CodecPool: Got brand-new decompressor [.lz4]
[2023-05-28 03:22:45,317] {spark_submit.py:490} INFO - 23/05/28 03:22:45 INFO CodecPool: Got brand-new decompressor [.lz4]
[2023-05-28 03:22:45,364] {spark_submit.py:490} INFO - 23/05/28 03:22:45 INFO CodecPool: Got brand-new decompressor [.lz4]
[2023-05-28 03:22:45,457] {spark_submit.py:490} INFO - 23/05/28 03:22:45 INFO CodecPool: Got brand-new decompressor [.lz4]
[2023-05-28 03:22:46,912] {spark_submit.py:490} INFO - 23/05/28 03:22:46 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00032-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5071559, partition values: [empty row]
[2023-05-28 03:22:47,226] {spark_submit.py:490} INFO - 23/05/28 03:22:47 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00023-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6139800, partition values: [empty row]
[2023-05-28 03:22:47,273] {spark_submit.py:490} INFO - 23/05/28 03:22:47 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00004-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-11114096, partition values: [empty row]
[2023-05-28 03:22:47,465] {spark_submit.py:490} INFO - 23/05/28 03:22:47 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00010-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7093863, partition values: [empty row]
[2023-05-28 03:22:47,820] {spark_submit.py:490} INFO - 23/05/28 03:22:47 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00034-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5052731, partition values: [empty row]
[2023-05-28 03:22:48,131] {spark_submit.py:490} INFO - 23/05/28 03:22:48 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00031-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5820983, partition values: [empty row]
[2023-05-28 03:22:48,480] {spark_submit.py:490} INFO - 23/05/28 03:22:48 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00001-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-10130628, partition values: [empty row]
[2023-05-28 03:22:48,518] {spark_submit.py:490} INFO - 23/05/28 03:22:48 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00011-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7076119, partition values: [empty row]
[2023-05-28 03:22:48,665] {spark_submit.py:490} INFO - 23/05/28 03:22:48 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00035-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5032418, partition values: [empty row]
[2023-05-28 03:22:48,861] {spark_submit.py:490} INFO - 23/05/28 03:22:48 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00030-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5747797, partition values: [empty row]
[2023-05-28 03:22:49,255] {spark_submit.py:490} INFO - 23/05/28 03:22:49 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00038-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4942981, partition values: [empty row]
[2023-05-28 03:22:49,421] {spark_submit.py:490} INFO - 23/05/28 03:22:49 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00012-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6844294, partition values: [empty row]
[2023-05-28 03:22:49,466] {spark_submit.py:490} INFO - 23/05/28 03:22:49 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00025-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5696810, partition values: [empty row]
[2023-05-28 03:22:49,540] {spark_submit.py:490} INFO - 23/05/28 03:22:49 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00003-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-10045204, partition values: [empty row]
[2023-05-28 03:22:49,784] {spark_submit.py:490} INFO - 23/05/28 03:22:49 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00049-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4908041, partition values: [empty row]
[2023-05-28 03:22:50,214] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00024-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5683946, partition values: [empty row]
[2023-05-28 03:22:50,288] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00019-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6827689, partition values: [empty row]
[2023-05-28 03:22:50,294] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00046-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4888973, partition values: [empty row]
[2023-05-28 03:22:50,301] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00006-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-9353802, partition values: [empty row]
[2023-05-28 03:22:50,804] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00045-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4885124, partition values: [empty row]
[2023-05-28 03:22:50,837] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00029-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5679816, partition values: [empty row]
[2023-05-28 03:22:50,947] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00017-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6724396, partition values: [empty row]
[2023-05-28 03:22:50,997] {spark_submit.py:490} INFO - 23/05/28 03:22:50 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00005-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-9087389, partition values: [empty row]
[2023-05-28 03:22:51,339] {spark_submit.py:490} INFO - 23/05/28 03:22:51 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00043-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4776428, partition values: [empty row]
[2023-05-28 03:22:51,448] {spark_submit.py:490} INFO - 23/05/28 03:22:51 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00028-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5660399, partition values: [empty row]
[2023-05-28 03:22:51,575] {spark_submit.py:490} INFO - 23/05/28 03:22:51 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00018-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6697413, partition values: [empty row]
[2023-05-28 03:22:51,744] {spark_submit.py:490} INFO - 23/05/28 03:22:51 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00002-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-8018621, partition values: [empty row]
[2023-05-28 03:22:51,811] {spark_submit.py:490} INFO - 23/05/28 03:22:51 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00044-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4757814, partition values: [empty row]
[2023-05-28 03:22:52,125] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00026-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5648630, partition values: [empty row]
[2023-05-28 03:22:52,329] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00014-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6668752, partition values: [empty row]
[2023-05-28 03:22:52,348] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00047-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4734975, partition values: [empty row]
[2023-05-28 03:22:52,471] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00008-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7579454, partition values: [empty row]
[2023-05-28 03:22:52,626] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00027-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5445052, partition values: [empty row]
[2023-05-28 03:22:52,850] {spark_submit.py:490} INFO - 23/05/28 03:22:52 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00041-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4711757, partition values: [empty row]
[2023-05-28 03:22:53,023] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00016-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6609526, partition values: [empty row]
[2023-05-28 03:22:53,262] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00039-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5334738, partition values: [empty row]
[2023-05-28 03:22:53,271] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00007-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7468956, partition values: [empty row]
[2023-05-28 03:22:53,357] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00042-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4652744, partition values: [empty row]
[2023-05-28 03:22:53,571] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00013-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6543418, partition values: [empty row]
[2023-05-28 03:22:53,843] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00040-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5308973, partition values: [empty row]
[2023-05-28 03:22:53,881] {spark_submit.py:490} INFO - 23/05/28 03:22:53 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00050-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4607885, partition values: [empty row]
[2023-05-28 03:22:54,145] {spark_submit.py:490} INFO - 23/05/28 03:22:54 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00009-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-7355169, partition values: [empty row]
[2023-05-28 03:22:54,315] {spark_submit.py:490} INFO - 23/05/28 03:22:54 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00020-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6530223, partition values: [empty row]
[2023-05-28 03:22:54,415] {spark_submit.py:490} INFO - 23/05/28 03:22:54 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00061-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4584606, partition values: [empty row]
[2023-05-28 03:22:54,417] {spark_submit.py:490} INFO - 23/05/28 03:22:54 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00036-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5229916, partition values: [empty row]
[2023-05-28 03:22:54,942] {spark_submit.py:490} INFO - 23/05/28 03:22:54 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00022-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-6472312, partition values: [empty row]
[2023-05-28 03:22:55,094] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00033-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-5160319, partition values: [empty row]
[2023-05-28 03:22:55,294] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 200). 2283 bytes result sent to driver
[2023-05-28 03:22:55,296] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 204) (c1224b457a2d, executor driver, partition 4, PROCESS_LOCAL, 10857 bytes)
[2023-05-28 03:22:55,299] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 200) in 10447 ms on c1224b457a2d (executor driver) (1/11)
[2023-05-28 03:22:55,317] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO Executor: Running task 4.0 in stage 2.0 (TID 204)
[2023-05-28 03:22:55,344] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00048-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4572934, partition values: [empty row]
[2023-05-28 03:22:55,498] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO Executor: Finished task 3.0 in stage 2.0 (TID 203). 2240 bytes result sent to driver
[2023-05-28 03:22:55,498] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 205) (c1224b457a2d, executor driver, partition 5, PROCESS_LOCAL, 11047 bytes)
[2023-05-28 03:22:55,499] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO Executor: Running task 5.0 in stage 2.0 (TID 205)
[2023-05-28 03:22:55,499] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 203) in 10645 ms on c1224b457a2d (executor driver) (2/11)
[2023-05-28 03:22:55,502] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00065-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3818057, partition values: [empty row]
[2023-05-28 03:22:55,890] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00051-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4556032, partition values: [empty row]
[2023-05-28 03:22:55,968] {spark_submit.py:490} INFO - 23/05/28 03:22:55 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00070-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3709527, partition values: [empty row]
[2023-05-28 03:22:56,347] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00053-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4485229, partition values: [empty row]
[2023-05-28 03:22:56,385] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00073-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3702716, partition values: [empty row]
[2023-05-28 03:22:56,453] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 201). 2240 bytes result sent to driver
[2023-05-28 03:22:56,455] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 206) (c1224b457a2d, executor driver, partition 6, PROCESS_LOCAL, 11427 bytes)
[2023-05-28 03:22:56,462] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 201) in 11603 ms on c1224b457a2d (executor driver) (3/11)
[2023-05-28 03:22:56,465] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO Executor: Running task 6.0 in stage 2.0 (TID 206)
[2023-05-28 03:22:56,467] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00082-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3311918, partition values: [empty row]
[2023-05-28 03:22:56,537] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO Executor: Finished task 2.0 in stage 2.0 (TID 202). 2240 bytes result sent to driver
[2023-05-28 03:22:56,539] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 207) (c1224b457a2d, executor driver, partition 7, PROCESS_LOCAL, 11997 bytes)
[2023-05-28 03:22:56,540] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 202) in 11686 ms on c1224b457a2d (executor driver) (4/11)
[2023-05-28 03:22:56,541] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO Executor: Running task 7.0 in stage 2.0 (TID 207)
[2023-05-28 03:22:56,544] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00108-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2413032, partition values: [empty row]
[2023-05-28 03:22:56,718] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00068-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3700319, partition values: [empty row]
[2023-05-28 03:22:56,735] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00105-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2406909, partition values: [empty row]
[2023-05-28 03:22:56,824] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00085-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3196718, partition values: [empty row]
[2023-05-28 03:22:56,852] {spark_submit.py:490} INFO - 23/05/28 03:22:56 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00054-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4438752, partition values: [empty row]
[2023-05-28 03:22:57,012] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00107-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2280801, partition values: [empty row]
[2023-05-28 03:22:57,093] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00079-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3683903, partition values: [empty row]
[2023-05-28 03:22:57,227] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00093-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3170643, partition values: [empty row]
[2023-05-28 03:22:57,294] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00102-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2239162, partition values: [empty row]
[2023-05-28 03:22:57,365] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00052-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4369670, partition values: [empty row]
[2023-05-28 03:22:57,420] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00074-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3643561, partition values: [empty row]
[2023-05-28 03:22:57,528] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00091-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3158363, partition values: [empty row]
[2023-05-28 03:22:57,780] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00104-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2175278, partition values: [empty row]
[2023-05-28 03:22:57,939] {spark_submit.py:490} INFO - 23/05/28 03:22:57 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00075-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3143847, partition values: [empty row]
[2023-05-28 03:22:58,260] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00056-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4368883, partition values: [empty row]
[2023-05-28 03:22:58,366] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00089-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3132958, partition values: [empty row]
[2023-05-28 03:22:58,368] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00071-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3618654, partition values: [empty row]
[2023-05-28 03:22:58,374] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00116-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2155767, partition values: [empty row]
[2023-05-28 03:22:58,601] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00055-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4321881, partition values: [empty row]
[2023-05-28 03:22:58,625] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00115-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2098555, partition values: [empty row]
[2023-05-28 03:22:58,670] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00090-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3120938, partition values: [empty row]
[2023-05-28 03:22:58,686] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00080-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3575763, partition values: [empty row]
[2023-05-28 03:22:58,820] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00106-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2091387, partition values: [empty row]
[2023-05-28 03:22:58,930] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00060-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4320137, partition values: [empty row]
[2023-05-28 03:22:58,939] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00096-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3102341, partition values: [empty row]
[2023-05-28 03:22:58,976] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00081-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3560832, partition values: [empty row]
[2023-05-28 03:22:58,995] {spark_submit.py:490} INFO - 23/05/28 03:22:58 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00114-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2061237, partition values: [empty row]
[2023-05-28 03:22:59,168] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00088-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3061420, partition values: [empty row]
[2023-05-28 03:22:59,206] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00118-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2041943, partition values: [empty row]
[2023-05-28 03:22:59,229] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00058-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4251334, partition values: [empty row]
[2023-05-28 03:22:59,300] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00077-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3540293, partition values: [empty row]
[2023-05-28 03:22:59,365] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00119-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2010488, partition values: [empty row]
[2023-05-28 03:22:59,390] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00087-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3058676, partition values: [empty row]
[2023-05-28 03:22:59,552] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00057-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4250132, partition values: [empty row]
[2023-05-28 03:22:59,555] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00121-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1939977, partition values: [empty row]
[2023-05-28 03:22:59,602] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00066-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3511921, partition values: [empty row]
[2023-05-28 03:22:59,662] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00094-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2923629, partition values: [empty row]
[2023-05-28 03:22:59,763] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00110-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1927359, partition values: [empty row]
[2023-05-28 03:22:59,969] {spark_submit.py:490} INFO - 23/05/28 03:22:59 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00059-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4129709, partition values: [empty row]
[2023-05-28 03:23:00,006] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00120-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1926613, partition values: [empty row]
[2023-05-28 03:23:00,044] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00095-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2875838, partition values: [empty row]
[2023-05-28 03:23:00,069] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00076-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3459694, partition values: [empty row]
[2023-05-28 03:23:00,210] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00117-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1922947, partition values: [empty row]
[2023-05-28 03:23:00,344] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00098-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2848535, partition values: [empty row]
[2023-05-28 03:23:00,376] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00112-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1889549, partition values: [empty row]
[2023-05-28 03:23:00,377] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00062-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-4084264, partition values: [empty row]
[2023-05-28 03:23:00,414] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00072-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3437342, partition values: [empty row]
[2023-05-28 03:23:00,555] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00092-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2847903, partition values: [empty row]
[2023-05-28 03:23:00,567] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00113-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1864379, partition values: [empty row]
[2023-05-28 03:23:00,730] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00109-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1837011, partition values: [empty row]
[2023-05-28 03:23:00,732] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00064-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3992458, partition values: [empty row]
[2023-05-28 03:23:00,737] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00078-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3435810, partition values: [empty row]
[2023-05-28 03:23:00,766] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00099-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2668270, partition values: [empty row]
[2023-05-28 03:23:00,882] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00123-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1812341, partition values: [empty row]
[2023-05-28 03:23:00,997] {spark_submit.py:490} INFO - 23/05/28 03:23:00 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00097-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2567453, partition values: [empty row]
[2023-05-28 03:23:01,037] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00069-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3962023, partition values: [empty row]
[2023-05-28 03:23:01,046] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00111-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1786933, partition values: [empty row]
[2023-05-28 03:23:01,065] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00083-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3386899, partition values: [empty row]
[2023-05-28 03:23:01,166] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00100-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2517000, partition values: [empty row]
[2023-05-28 03:23:01,237] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00122-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1660875, partition values: [empty row]
[2023-05-28 03:23:01,364] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00084-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3368732, partition values: [empty row]
[2023-05-28 03:23:01,386] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00067-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3908504, partition values: [empty row]
[2023-05-28 03:23:01,389] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00101-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2504209, partition values: [empty row]
[2023-05-28 03:23:01,398] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00126-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1615753, partition values: [empty row]
[2023-05-28 03:23:01,585] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00086-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3341206, partition values: [empty row]
[2023-05-28 03:23:01,620] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00103-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-2499873, partition values: [empty row]
[2023-05-28 03:23:01,692] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00063-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-3842591, partition values: [empty row]
[2023-05-28 03:23:01,858] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO Executor: Finished task 7.0 in stage 2.0 (TID 207). 2240 bytes result sent to driver
[2023-05-28 03:23:01,859] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 208) (c1224b457a2d, executor driver, partition 8, PROCESS_LOCAL, 12377 bytes)
[2023-05-28 03:23:01,860] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 207) in 5321 ms on c1224b457a2d (executor driver) (5/11)
[2023-05-28 03:23:01,860] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO Executor: Running task 8.0 in stage 2.0 (TID 208)
[2023-05-28 03:23:01,866] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00129-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1591287, partition values: [empty row]
[2023-05-28 03:23:01,969] {spark_submit.py:490} INFO - 23/05/28 03:23:01 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00124-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1578934, partition values: [empty row]
[2023-05-28 03:23:02,088] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00133-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1559527, partition values: [empty row]
[2023-05-28 03:23:02,197] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO Executor: Finished task 6.0 in stage 2.0 (TID 206). 2240 bytes result sent to driver
[2023-05-28 03:23:02,200] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 209) (c1224b457a2d, executor driver, partition 9, PROCESS_LOCAL, 12947 bytes)
[2023-05-28 03:23:02,200] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO Executor: Running task 9.0 in stage 2.0 (TID 209)
[2023-05-28 03:23:02,201] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 206) in 5744 ms on c1224b457a2d (executor driver) (6/11)
[2023-05-28 03:23:02,204] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00149-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1136968, partition values: [empty row]
[2023-05-28 03:23:02,205] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00132-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1547547, partition values: [empty row]
[2023-05-28 03:23:02,299] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00152-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1117587, partition values: [empty row]
[2023-05-28 03:23:02,318] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00128-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1541935, partition values: [empty row]
[2023-05-28 03:23:02,411] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00153-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1103366, partition values: [empty row]
[2023-05-28 03:23:02,437] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00127-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1526949, partition values: [empty row]
[2023-05-28 03:23:02,444] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO Executor: Finished task 5.0 in stage 2.0 (TID 205). 2240 bytes result sent to driver
[2023-05-28 03:23:02,445] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 210) (c1224b457a2d, executor driver, partition 10, PROCESS_LOCAL, 12187 bytes)
[2023-05-28 03:23:02,446] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO Executor: Running task 10.0 in stage 2.0 (TID 210)
[2023-05-28 03:23:02,446] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 205) in 6948 ms on c1224b457a2d (executor driver) (7/11)
[2023-05-28 03:23:02,449] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00175-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-480294, partition values: [empty row]
[2023-05-28 03:23:02,485] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00154-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1102641, partition values: [empty row]
[2023-05-28 03:23:02,488] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00176-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-478346, partition values: [empty row]
[2023-05-28 03:23:02,533] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00178-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-387525, partition values: [empty row]
[2023-05-28 03:23:02,534] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00130-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1503469, partition values: [empty row]
[2023-05-28 03:23:02,564] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00179-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-382248, partition values: [empty row]
[2023-05-28 03:23:02,570] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO Executor: Finished task 4.0 in stage 2.0 (TID 204). 2240 bytes result sent to driver
[2023-05-28 03:23:02,571] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 204) in 7275 ms on c1224b457a2d (executor driver) (8/11)
[2023-05-28 03:23:02,577] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00147-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1100892, partition values: [empty row]
[2023-05-28 03:23:02,607] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00180-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-354935, partition values: [empty row]
[2023-05-28 03:23:02,631] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00183-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-345510, partition values: [empty row]
[2023-05-28 03:23:02,638] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00131-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1470987, partition values: [empty row]
[2023-05-28 03:23:02,652] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00151-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1100630, partition values: [empty row]
[2023-05-28 03:23:02,657] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00181-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-340760, partition values: [empty row]
[2023-05-28 03:23:02,693] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00182-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-315258, partition values: [empty row]
[2023-05-28 03:23:02,720] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00155-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1089053, partition values: [empty row]
[2023-05-28 03:23:02,723] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00186-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-284882, partition values: [empty row]
[2023-05-28 03:23:02,726] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00125-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1466834, partition values: [empty row]
[2023-05-28 03:23:02,748] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00185-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-273996, partition values: [empty row]
[2023-05-28 03:23:02,773] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00187-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-265985, partition values: [empty row]
[2023-05-28 03:23:02,796] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00156-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1021410, partition values: [empty row]
[2023-05-28 03:23:02,799] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00184-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-258751, partition values: [empty row]
[2023-05-28 03:23:02,828] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00188-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-254243, partition values: [empty row]
[2023-05-28 03:23:02,845] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00189-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-235916, partition values: [empty row]
[2023-05-28 03:23:02,848] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00134-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1421025, partition values: [empty row]
[2023-05-28 03:23:02,862] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00190-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-232396, partition values: [empty row]
[2023-05-28 03:23:02,866] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00157-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-914836, partition values: [empty row]
[2023-05-28 03:23:02,885] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00191-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-188681, partition values: [empty row]
[2023-05-28 03:23:02,911] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00193-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-171811, partition values: [empty row]
[2023-05-28 03:23:02,929] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00161-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-861206, partition values: [empty row]
[2023-05-28 03:23:02,937] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00139-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1368402, partition values: [empty row]
[2023-05-28 03:23:02,939] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00192-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-162429, partition values: [empty row]
[2023-05-28 03:23:02,960] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00194-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-138498, partition values: [empty row]
[2023-05-28 03:23:02,976] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00195-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-105453, partition values: [empty row]
[2023-05-28 03:23:02,988] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00196-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-70879, partition values: [empty row]
[2023-05-28 03:23:02,998] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00197-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-59238, partition values: [empty row]
[2023-05-28 03:23:02,998] {spark_submit.py:490} INFO - 23/05/28 03:23:02 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00162-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-859745, partition values: [empty row]
[2023-05-28 03:23:03,009] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00198-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-17900, partition values: [empty row]
[2023-05-28 03:23:03,037] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00136-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1355470, partition values: [empty row]
[2023-05-28 03:23:03,052] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00160-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-850482, partition values: [empty row]
[2023-05-28 03:23:03,062] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO Executor: Finished task 10.0 in stage 2.0 (TID 210). 2240 bytes result sent to driver
[2023-05-28 03:23:03,064] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 210) in 619 ms on c1224b457a2d (executor driver) (9/11)
[2023-05-28 03:23:03,110] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00159-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-847270, partition values: [empty row]
[2023-05-28 03:23:03,135] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00142-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1316461, partition values: [empty row]
[2023-05-28 03:23:03,165] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00158-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-840808, partition values: [empty row]
[2023-05-28 03:23:03,210] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00138-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1300370, partition values: [empty row]
[2023-05-28 03:23:03,216] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00163-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-820340, partition values: [empty row]
[2023-05-28 03:23:03,265] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00164-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-759217, partition values: [empty row]
[2023-05-28 03:23:03,294] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00146-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1298936, partition values: [empty row]
[2023-05-28 03:23:03,336] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00166-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-751837, partition values: [empty row]
[2023-05-28 03:23:03,379] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00165-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-700841, partition values: [empty row]
[2023-05-28 03:23:03,380] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00135-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1294963, partition values: [empty row]
[2023-05-28 03:23:03,434] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00167-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-660687, partition values: [empty row]
[2023-05-28 03:23:03,473] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00148-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1260208, partition values: [empty row]
[2023-05-28 03:23:03,477] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00169-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-619828, partition values: [empty row]
[2023-05-28 03:23:03,517] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00168-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-609323, partition values: [empty row]
[2023-05-28 03:23:03,540] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00143-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1229501, partition values: [empty row]
[2023-05-28 03:23:03,557] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00171-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-558179, partition values: [empty row]
[2023-05-28 03:23:03,587] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00172-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-546879, partition values: [empty row]
[2023-05-28 03:23:03,608] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00140-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1211902, partition values: [empty row]
[2023-05-28 03:23:03,625] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00170-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-540821, partition values: [empty row]
[2023-05-28 03:23:03,670] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00173-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-529771, partition values: [empty row]
[2023-05-28 03:23:03,692] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00141-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1198899, partition values: [empty row]
[2023-05-28 03:23:03,703] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00174-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-513742, partition values: [empty row]
[2023-05-28 03:23:03,737] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00177-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-488609, partition values: [empty row]
[2023-05-28 03:23:03,764] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00144-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1191198, partition values: [empty row]
[2023-05-28 03:23:03,837] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00145-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1171234, partition values: [empty row]
[2023-05-28 03:23:03,869] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO Executor: Finished task 9.0 in stage 2.0 (TID 209). 2240 bytes result sent to driver
[2023-05-28 03:23:03,870] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 209) in 1672 ms on c1224b457a2d (executor driver) (10/11)
[2023-05-28 03:23:03,905] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00137-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1158728, partition values: [empty row]
[2023-05-28 03:23:03,973] {spark_submit.py:490} INFO - 23/05/28 03:23:03 INFO FileScanRDD: Reading File path: file:/usr/local/spark/staging/20230528/raw_data_processing/stocks.parquet/part-00150-d3cddbab-9218-4484-b64c-f11b252a7c48-c000.lz4.parquet, range: 0-1137543, partition values: [empty row]
[2023-05-28 03:23:04,167] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO Executor: Finished task 8.0 in stage 2.0 (TID 208). 2240 bytes result sent to driver
[2023-05-28 03:23:04,168] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 208) in 2308 ms on c1224b457a2d (executor driver) (11/11)
[2023-05-28 03:23:04,169] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2023-05-28 03:23:04,169] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0) finished in 19.362 s
[2023-05-28 03:23:04,170] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: looking for newly runnable stages
[2023-05-28 03:23:04,170] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: running: Set()
[2023-05-28 03:23:04,171] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: waiting: Set()
[2023-05-28 03:23:04,171] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: failed: Set()
[2023-05-28 03:23:04,190] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 67108864, minimum partition size: 1048576
[2023-05-28 03:23:04,235] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:04,246] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:04,247] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:04,248] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:04,248] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:04,249] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:04,249] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:04,288] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 10.693292 ms
[2023-05-28 03:23:04,304] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 9.994292 ms
[2023-05-28 03:23:04,316] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 7.476875 ms
[2023-05-28 03:23:04,356] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2023-05-28 03:23:04,357] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 28 output partitions
[2023-05-28 03:23:04,358] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0)
[2023-05-28 03:23:04,358] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
[2023-05-28 03:23:04,359] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Missing parents: List()
[2023-05-28 03:23:04,359] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-28 03:23:04,383] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 248.3 KiB, free 433.9 MiB)
[2023-05-28 03:23:04,385] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 90.3 KiB, free 433.8 MiB)
[2023-05-28 03:23:04,386] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on c1224b457a2d:37283 (size: 90.3 KiB, free: 434.3 MiB)
[2023-05-28 03:23:04,386] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
[2023-05-28 03:23:04,387] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO DAGScheduler: Submitting 28 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2023-05-28 03:23:04,387] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSchedulerImpl: Adding task set 4.0 with 28 tasks resource profile 0
[2023-05-28 03:23:04,391] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 211) (c1224b457a2d, executor driver, partition 0, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:23:04,392] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 212) (c1224b457a2d, executor driver, partition 1, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:23:04,393] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 213) (c1224b457a2d, executor driver, partition 2, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:23:04,393] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 214) (c1224b457a2d, executor driver, partition 3, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:23:04,393] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO Executor: Running task 3.0 in stage 4.0 (TID 214)
[2023-05-28 03:23:04,394] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO Executor: Running task 2.0 in stage 4.0 (TID 213)
[2023-05-28 03:23:04,394] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO Executor: Running task 0.0 in stage 4.0 (TID 211)
[2023-05-28 03:23:04,395] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO Executor: Running task 1.0 in stage 4.0 (TID 212)
[2023-05-28 03:23:04,460] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Getting 11 (63.8 MiB) non-empty blocks including 11 (63.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:23:04,460] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Getting 11 (62.6 MiB) non-empty blocks including 11 (62.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:23:04,461] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Getting 11 (58.0 MiB) non-empty blocks including 11 (58.0 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:23:04,461] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2023-05-28 03:23:04,462] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2023-05-28 03:23:04,462] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2023-05-28 03:23:04,463] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Getting 11 (55.1 MiB) non-empty blocks including 11 (55.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:23:04,463] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2023-05-28 03:23:04,485] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 10.617959 ms
[2023-05-28 03:23:04,500] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 5.255375 ms
[2023-05-28 03:23:04,568] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 8.220083 ms
[2023-05-28 03:23:04,573] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO CodeGenerator: Code generated in 3.549084 ms
[2023-05-28 03:23:04,924] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:23:04,945] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:23:04,953] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:23:04,968] {spark_submit.py:490} INFO - 23/05/28 03:23:04 INFO UnsafeExternalSorter: Thread 64 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:23:05,005] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO BlockManagerInfo: Removed broadcast_3_piece0 on c1224b457a2d:37283 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2023-05-28 03:23:05,388] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO UnsafeExternalSorter: Thread 64 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:23:05,392] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO UnsafeExternalSorter: Thread 71 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:23:05,393] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:23:05,393] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:23:05,659] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 3.433166 ms
[2023-05-28 03:23:05,683] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 15.641125 ms
[2023-05-28 03:23:05,690] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 5.035125 ms
[2023-05-28 03:23:05,699] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 3.2725 ms
[2023-05-28 03:23:05,711] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 7.352083 ms
[2023-05-28 03:23:05,732] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:05,735] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:05,743] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 4.942792 ms
[2023-05-28 03:23:05,749] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodeGenerator: Code generated in 3.752375 ms
[2023-05-28 03:23:05,753] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,754] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,754] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,755] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,755] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,756] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,757] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,757] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,757] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,758] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,758] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,758] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,759] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,759] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,759] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,760] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,760] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,760] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,761] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,761] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,762] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,762] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:23:05,763] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:23:05,763] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:23:05,772] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,774] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,776] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,777] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,794] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:23:05,798] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:05,799] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:23:05,801] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:23:05,803] {spark_submit.py:490} INFO - {
[2023-05-28 03:23:05,803] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:23:05,804] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:23:05,804] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:23:05,805] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,805] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,805] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,805] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,806] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:23:05,806] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,807] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,807] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,807] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,808] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:23:05,808] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,809] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,809] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,809] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,810] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:23:05,810] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,811] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,811] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,811] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,811] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:23:05,812] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,814] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,815] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,815] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,815] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:23:05,816] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,816] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,817] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,817] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,817] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:23:05,818] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,818] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,818] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,819] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,819] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:23:05,820] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,820] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,820] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,820] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,821] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:23:05,821] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,821] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,821] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,822] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,832] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:23:05,834] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,834] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,835] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,835] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,836] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:23:05,836] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,837] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,838] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,838] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:23:05,839] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,839] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:23:05,840] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:23:05,840] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:23:05,840] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:23:05,841] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:23:05,841] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:23:05,841] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:23:05,843] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:23:05,844] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:23:05,844] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:23:05,845] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:23:05,845] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:23:05,845] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:23:05,846] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,846] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,846] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,847] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:23:05,847] {spark_submit.py:490} INFO - {
[2023-05-28 03:23:05,847] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:23:05,848] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:23:05,848] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:23:05,849] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,849] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,850] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,850] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,850] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:23:05,851] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,851] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,852] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,852] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,852] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:23:05,853] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,853] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,855] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,855] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,856] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:23:05,856] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,857] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,857] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,858] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,858] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:23:05,859] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,859] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,859] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,860] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,860] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:23:05,862] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,866] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,866] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,866] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,867] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:23:05,867] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,868] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,868] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,869] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,870] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:23:05,870] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,871] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,871] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,872] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,872] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:23:05,873] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,873] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,874] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,874] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,875] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:23:05,875] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,875] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,876] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,876] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,877] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:23:05,878] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,878] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,878] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,879] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:23:05,879] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,880] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:23:05,880] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:23:05,881] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:23:05,881] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:23:05,882] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:23:05,882] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:23:05,883] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:23:05,883] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:23:05,884] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:23:05,884] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:23:05,884] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:23:05,885] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:23:05,885] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:23:05,886] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,886] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,887] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,887] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:05,888] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,888] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,889] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:23:05,891] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:23:05,891] {spark_submit.py:490} INFO - {
[2023-05-28 03:23:05,892] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:23:05,892] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:23:05,893] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:23:05,893] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,894] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,894] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,895] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,895] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:23:05,896] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,896] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,896] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,897] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,897] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:23:05,898] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,900] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,901] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,901] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,902] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:23:05,902] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,903] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,903] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,904] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,904] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:23:05,905] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,905] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,905] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,906] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,906] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:23:05,907] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,907] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,907] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,908] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,908] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:23:05,914] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,918] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,918] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,919] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,919] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:23:05,922] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,923] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,927] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,928] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,929] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:23:05,929] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,930] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,931] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,932] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,932] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:23:05,933] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,933] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,934] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,934] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,935] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:23:05,935] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,936] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,936] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,937] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:23:05,937] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,938] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:23:05,938] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:23:05,939] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:23:05,939] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:23:05,940] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:23:05,940] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:23:05,941] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:23:05,942] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:23:05,942] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:23:05,943] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:23:05,943] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:23:05,944] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:23:05,944] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:23:05,945] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,945] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,946] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,946] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:05,947] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,950] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:23:05,951] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:23:05,952] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:23:05,952] {spark_submit.py:490} INFO - {
[2023-05-28 03:23:05,953] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:23:05,953] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:23:05,953] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:23:05,954] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,955] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,955] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,955] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,956] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:23:05,956] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,956] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,957] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,957] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,959] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:23:05,959] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,960] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,960] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,960] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,961] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:23:05,961] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,962] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,962] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,963] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,963] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:23:05,964] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,965] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,965] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,966] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,966] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:23:05,967] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,967] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,967] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,969] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,970] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:23:05,970] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,971] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,971] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,972] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,972] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:23:05,972] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,974] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,975] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,975] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,975] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:23:05,976] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:23:05,976] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,977] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,977] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,977] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:23:05,978] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,980] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,980] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,981] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:23:05,981] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:23:05,982] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:23:05,982] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:23:05,983] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:23:05,983] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:23:05,984] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,985] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:23:05,985] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:23:05,986] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:23:05,986] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:23:05,987] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:23:05,987] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:23:05,987] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:23:05,988] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:23:05,989] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:23:05,990] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:23:05,990] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:23:05,991] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:23:05,991] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:23:05,992] {spark_submit.py:490} INFO - }
[2023-05-28 03:23:05,992] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,992] {spark_submit.py:490} INFO - 
[2023-05-28 03:23:05,993] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecPool: Got brand-new compressor [.lz4]
[2023-05-28 03:23:05,993] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecPool: Got brand-new compressor [.lz4]
[2023-05-28 03:23:05,994] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecPool: Got brand-new compressor [.lz4]
[2023-05-28 03:23:05,994] {spark_submit.py:490} INFO - 23/05/28 03:23:05 INFO CodecPool: Got brand-new compressor [.lz4]
[2023-05-28 03:23:06,052] {spark_submit.py:490} INFO - 23/05/28 03:23:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:06,680] {spark_submit.py:490} INFO - 23/05/28 03:23:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:06,766] {spark_submit.py:490} INFO - 23/05/28 03:23:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:06,907] {spark_submit.py:490} INFO - 23/05/28 03:23:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:07,363] {spark_submit.py:490} INFO - 23/05/28 03:23:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:07,873] {spark_submit.py:490} INFO - 23/05/28 03:23:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,388] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,398] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,403] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,589] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,597] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:09,624] {spark_submit.py:490} INFO - 23/05/28 03:23:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:10,197] {spark_submit.py:490} INFO - 23/05/28 03:23:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:10,210] {spark_submit.py:490} INFO - 23/05/28 03:23:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:11,299] {spark_submit.py:490} INFO - 23/05/28 03:23:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:11,487] {spark_submit.py:490} INFO - 23/05/28 03:23:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:11,557] {spark_submit.py:490} INFO - 23/05/28 03:23:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:12,993] {spark_submit.py:490} INFO - 23/05/28 03:23:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,071] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,521] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,556] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,632] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,639] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,774] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,880] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:13,885] {spark_submit.py:490} INFO - 23/05/28 03:23:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:14,795] {spark_submit.py:490} INFO - 23/05/28 03:23:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:15,933] {spark_submit.py:490} INFO - 23/05/28 03:23:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:15,948] {spark_submit.py:490} INFO - 23/05/28 03:23:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:15,952] {spark_submit.py:490} INFO - 23/05/28 03:23:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:16,082] {spark_submit.py:490} INFO - 23/05/28 03:23:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:16,088] {spark_submit.py:490} INFO - 23/05/28 03:23:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:16,105] {spark_submit.py:490} INFO - 23/05/28 03:23:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:16,527] {spark_submit.py:490} INFO - 23/05/28 03:23:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:16,560] {spark_submit.py:490} INFO - 23/05/28 03:23:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:17,101] {spark_submit.py:490} INFO - 23/05/28 03:23:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:17,209] {spark_submit.py:490} INFO - 23/05/28 03:23:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:17,305] {spark_submit.py:490} INFO - 23/05/28 03:23:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:17,506] {spark_submit.py:490} INFO - 23/05/28 03:23:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:17,515] {spark_submit.py:490} INFO - 23/05/28 03:23:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:18,758] {spark_submit.py:490} INFO - 23/05/28 03:23:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:18,766] {spark_submit.py:490} INFO - 23/05/28 03:23:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:18,788] {spark_submit.py:490} INFO - 23/05/28 03:23:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:18,953] {spark_submit.py:490} INFO - 23/05/28 03:23:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:19,979] {spark_submit.py:490} INFO - 23/05/28 03:23:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:20,111] {spark_submit.py:490} INFO - 23/05/28 03:23:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:21,058] {spark_submit.py:490} INFO - 23/05/28 03:23:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:21,066] {spark_submit.py:490} INFO - 23/05/28 03:23:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:21,986] {spark_submit.py:490} INFO - 23/05/28 03:23:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,044] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,107] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,275] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,280] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,363] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,367] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,639] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:22,649] {spark_submit.py:490} INFO - 23/05/28 03:23:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:23,277] {spark_submit.py:490} INFO - 23/05/28 03:23:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:23,596] {spark_submit.py:490} INFO - 23/05/28 03:23:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:23,601] {spark_submit.py:490} INFO - 23/05/28 03:23:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:23,671] {spark_submit.py:490} INFO - 23/05/28 03:23:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:23,916] {spark_submit.py:490} INFO - 23/05/28 03:23:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,201] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,230] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,236] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,417] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,486] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,518] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,594] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,594] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,659] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:24,667] {spark_submit.py:490} INFO - 23/05/28 03:23:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:26,375] {spark_submit.py:490} INFO - 23/05/28 03:23:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:26,479] {spark_submit.py:490} INFO - 23/05/28 03:23:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:27,249] {spark_submit.py:490} INFO - 23/05/28 03:23:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:27,252] {spark_submit.py:490} INFO - 23/05/28 03:23:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:27,586] {spark_submit.py:490} INFO - 23/05/28 03:23:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:27,612] {spark_submit.py:490} INFO - 23/05/28 03:23:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:27,615] {spark_submit.py:490} INFO - 23/05/28 03:23:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,007] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,218] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,232] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,232] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,235] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:28,238] {spark_submit.py:490} INFO - 23/05/28 03:23:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:29,248] {spark_submit.py:490} INFO - 23/05/28 03:23:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:29,264] {spark_submit.py:490} INFO - 23/05/28 03:23:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:29,267] {spark_submit.py:490} INFO - 23/05/28 03:23:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:29,718] {spark_submit.py:490} INFO - 23/05/28 03:23:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:31,878] {spark_submit.py:490} INFO - 23/05/28 03:23:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:32,383] {spark_submit.py:490} INFO - 23/05/28 03:23:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:32,445] {spark_submit.py:490} INFO - 23/05/28 03:23:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:32,447] {spark_submit.py:490} INFO - 23/05/28 03:23:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:32,643] {spark_submit.py:490} INFO - 23/05/28 03:23:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:32,911] {spark_submit.py:490} INFO - 23/05/28 03:23:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:33,700] {spark_submit.py:490} INFO - 23/05/28 03:23:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:33,753] {spark_submit.py:490} INFO - 23/05/28 03:23:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,338] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,356] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,482] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,494] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,506] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,605] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:34,657] {spark_submit.py:490} INFO - 23/05/28 03:23:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:35,272] {spark_submit.py:490} INFO - 23/05/28 03:23:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:35,277] {spark_submit.py:490} INFO - 23/05/28 03:23:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:35,648] {spark_submit.py:490} INFO - 23/05/28 03:23:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:35,655] {spark_submit.py:490} INFO - 23/05/28 03:23:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:35,658] {spark_submit.py:490} INFO - 23/05/28 03:23:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:36,150] {spark_submit.py:490} INFO - 23/05/28 03:23:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:36,326] {spark_submit.py:490} INFO - 23/05/28 03:23:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:36,606] {spark_submit.py:490} INFO - 23/05/28 03:23:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:36,701] {spark_submit.py:490} INFO - 23/05/28 03:23:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:37,121] {spark_submit.py:490} INFO - 23/05/28 03:23:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:37,486] {spark_submit.py:490} INFO - 23/05/28 03:23:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:38,285] {spark_submit.py:490} INFO - 23/05/28 03:23:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:38,299] {spark_submit.py:490} INFO - 23/05/28 03:23:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:38,598] {spark_submit.py:490} INFO - 23/05/28 03:23:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:38,699] {spark_submit.py:490} INFO - 23/05/28 03:23:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,493] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,551] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,563] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,684] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,717] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:39,721] {spark_submit.py:490} INFO - 23/05/28 03:23:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:40,401] {spark_submit.py:490} INFO - 23/05/28 03:23:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:40,407] {spark_submit.py:490} INFO - 23/05/28 03:23:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:40,600] {spark_submit.py:490} INFO - 23/05/28 03:23:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:40,603] {spark_submit.py:490} INFO - 23/05/28 03:23:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:40,697] {spark_submit.py:490} INFO - 23/05/28 03:23:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:41,042] {spark_submit.py:490} INFO - 23/05/28 03:23:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:41,063] {spark_submit.py:490} INFO - 23/05/28 03:23:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:42,646] {spark_submit.py:490} INFO - 23/05/28 03:23:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:43,049] {spark_submit.py:490} INFO - 23/05/28 03:23:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:43,674] {spark_submit.py:490} INFO - 23/05/28 03:23:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:44,583] {spark_submit.py:490} INFO - 23/05/28 03:23:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,033] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,079] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,291] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,602] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,610] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:45,612] {spark_submit.py:490} INFO - 23/05/28 03:23:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:46,191] {spark_submit.py:490} INFO - 23/05/28 03:23:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:46,283] {spark_submit.py:490} INFO - 23/05/28 03:23:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:46,302] {spark_submit.py:490} INFO - 23/05/28 03:23:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:46,306] {spark_submit.py:490} INFO - 23/05/28 03:23:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:46,579] {spark_submit.py:490} INFO - 23/05/28 03:23:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,242] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,273] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,275] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,606] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,711] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,761] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,762] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,879] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,880] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:47,966] {spark_submit.py:490} INFO - 23/05/28 03:23:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,304] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,391] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,393] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,505] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,648] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:48,652] {spark_submit.py:490} INFO - 23/05/28 03:23:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:49,277] {spark_submit.py:490} INFO - 23/05/28 03:23:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:49,745] {spark_submit.py:490} INFO - 23/05/28 03:23:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:50,060] {spark_submit.py:490} INFO - 23/05/28 03:23:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:50,225] {spark_submit.py:490} INFO - 23/05/28 03:23:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:50,551] {spark_submit.py:490} INFO - 23/05/28 03:23:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:50,562] {spark_submit.py:490} INFO - 23/05/28 03:23:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:50,568] {spark_submit.py:490} INFO - 23/05/28 03:23:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:51,386] {spark_submit.py:490} INFO - 23/05/28 03:23:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:51,394] {spark_submit.py:490} INFO - 23/05/28 03:23:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:51,419] {spark_submit.py:490} INFO - 23/05/28 03:23:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:51,885] {spark_submit.py:490} INFO - 23/05/28 03:23:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:51,900] {spark_submit.py:490} INFO - 23/05/28 03:23:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:52,483] {spark_submit.py:490} INFO - 23/05/28 03:23:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:52,606] {spark_submit.py:490} INFO - 23/05/28 03:23:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:52,610] {spark_submit.py:490} INFO - 23/05/28 03:23:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:53,382] {spark_submit.py:490} INFO - 23/05/28 03:23:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:53,575] {spark_submit.py:490} INFO - 23/05/28 03:23:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:53,737] {spark_submit.py:490} INFO - 23/05/28 03:23:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,191] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,196] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,429] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,891] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,959] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:54,960] {spark_submit.py:490} INFO - 23/05/28 03:23:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:55,646] {spark_submit.py:490} INFO - 23/05/28 03:23:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,044] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,051] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,054] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,316] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,370] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:56,373] {spark_submit.py:490} INFO - 23/05/28 03:23:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:57,135] {spark_submit.py:490} INFO - 23/05/28 03:23:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:57,137] {spark_submit.py:490} INFO - 23/05/28 03:23:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:57,139] {spark_submit.py:490} INFO - 23/05/28 03:23:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:57,306] {spark_submit.py:490} INFO - 23/05/28 03:23:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:58,017] {spark_submit.py:490} INFO - 23/05/28 03:23:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:58,032] {spark_submit.py:490} INFO - 23/05/28 03:23:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:58,805] {spark_submit.py:490} INFO - 23/05/28 03:23:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:58,991] {spark_submit.py:490} INFO - 23/05/28 03:23:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,151] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,155] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,448] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,517] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,538] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,561] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,948] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:23:59,951] {spark_submit.py:490} INFO - 23/05/28 03:23:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:00,614] {spark_submit.py:490} INFO - 23/05/28 03:24:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:01,078] {spark_submit.py:490} INFO - 23/05/28 03:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:01,083] {spark_submit.py:490} INFO - 23/05/28 03:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:01,222] {spark_submit.py:490} INFO - 23/05/28 03:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:01,223] {spark_submit.py:490} INFO - 23/05/28 03:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:01,752] {spark_submit.py:490} INFO - 23/05/28 03:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:02,480] {spark_submit.py:490} INFO - 23/05/28 03:24:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:02,501] {spark_submit.py:490} INFO - 23/05/28 03:24:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:02,641] {spark_submit.py:490} INFO - 23/05/28 03:24:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:03,046] {spark_submit.py:490} INFO - 23/05/28 03:24:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:03,216] {spark_submit.py:490} INFO - 23/05/28 03:24:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:03,841] {spark_submit.py:490} INFO - 23/05/28 03:24:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:04,171] {spark_submit.py:490} INFO - 23/05/28 03:24:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:04,218] {spark_submit.py:490} INFO - 23/05/28 03:24:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:04,221] {spark_submit.py:490} INFO - 23/05/28 03:24:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:04,256] {spark_submit.py:490} INFO - 23/05/28 03:24:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:04,272] {spark_submit.py:490} INFO - 23/05/28 03:24:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:05,459] {spark_submit.py:490} INFO - 23/05/28 03:24:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:05,712] {spark_submit.py:490} INFO - 23/05/28 03:24:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:05,862] {spark_submit.py:490} INFO - 23/05/28 03:24:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:05,864] {spark_submit.py:490} INFO - 23/05/28 03:24:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,074] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,078] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,521] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,551] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,717] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,880] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:06,965] {spark_submit.py:490} INFO - 23/05/28 03:24:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:07,332] {spark_submit.py:490} INFO - 23/05/28 03:24:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:07,911] {spark_submit.py:490} INFO - 23/05/28 03:24:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:08,202] {spark_submit.py:490} INFO - 23/05/28 03:24:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:08,419] {spark_submit.py:490} INFO - 23/05/28 03:24:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:08,674] {spark_submit.py:490} INFO - 23/05/28 03:24:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:08,691] {spark_submit.py:490} INFO - 23/05/28 03:24:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:08,700] {spark_submit.py:490} INFO - 23/05/28 03:24:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,291] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,329] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,553] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,796] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,834] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,836] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:09,928] {spark_submit.py:490} INFO - 23/05/28 03:24:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:10,507] {spark_submit.py:490} INFO - 23/05/28 03:24:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:10,549] {spark_submit.py:490} INFO - 23/05/28 03:24:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:10,555] {spark_submit.py:490} INFO - 23/05/28 03:24:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:11,459] {spark_submit.py:490} INFO - 23/05/28 03:24:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:11,619] {spark_submit.py:490} INFO - 23/05/28 03:24:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:11,637] {spark_submit.py:490} INFO - 23/05/28 03:24:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:11,668] {spark_submit.py:490} INFO - 23/05/28 03:24:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:12,139] {spark_submit.py:490} INFO - 23/05/28 03:24:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:12,156] {spark_submit.py:490} INFO - 23/05/28 03:24:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:12,276] {spark_submit.py:490} INFO - 23/05/28 03:24:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:12,396] {spark_submit.py:490} INFO - 23/05/28 03:24:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:12,656] {spark_submit.py:490} INFO - 23/05/28 03:24:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:13,011] {spark_submit.py:490} INFO - 23/05/28 03:24:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:13,015] {spark_submit.py:490} INFO - 23/05/28 03:24:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:14,536] {spark_submit.py:490} INFO - 23/05/28 03:24:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:14,958] {spark_submit.py:490} INFO - 23/05/28 03:24:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:14,985] {spark_submit.py:490} INFO - 23/05/28 03:24:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:15,009] {spark_submit.py:490} INFO - 23/05/28 03:24:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:15,012] {spark_submit.py:490} INFO - 23/05/28 03:24:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:15,183] {spark_submit.py:490} INFO - 23/05/28 03:24:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:15,844] {spark_submit.py:490} INFO - 23/05/28 03:24:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,024] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,029] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,115] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,125] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,128] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:16,380] {spark_submit.py:490} INFO - 23/05/28 03:24:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:17,516] {spark_submit.py:490} INFO - 23/05/28 03:24:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:17,642] {spark_submit.py:490} INFO - 23/05/28 03:24:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:17,919] {spark_submit.py:490} INFO - 23/05/28 03:24:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:18,161] {spark_submit.py:490} INFO - 23/05/28 03:24:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:18,163] {spark_submit.py:490} INFO - 23/05/28 03:24:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:18,220] {spark_submit.py:490} INFO - 23/05/28 03:24:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:18,517] {spark_submit.py:490} INFO - 23/05/28 03:24:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:18,520] {spark_submit.py:490} INFO - 23/05/28 03:24:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:19,070] {spark_submit.py:490} INFO - 23/05/28 03:24:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:19,165] {spark_submit.py:490} INFO - 23/05/28 03:24:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:19,395] {spark_submit.py:490} INFO - 23/05/28 03:24:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:19,815] {spark_submit.py:490} INFO - 23/05/28 03:24:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:20,209] {spark_submit.py:490} INFO - 23/05/28 03:24:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:20,281] {spark_submit.py:490} INFO - 23/05/28 03:24:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:20,296] {spark_submit.py:490} INFO - 23/05/28 03:24:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:21,471] {spark_submit.py:490} INFO - 23/05/28 03:24:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:21,474] {spark_submit.py:490} INFO - 23/05/28 03:24:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:22,321] {spark_submit.py:490} INFO - 23/05/28 03:24:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:22,323] {spark_submit.py:490} INFO - 23/05/28 03:24:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:22,494] {spark_submit.py:490} INFO - 23/05/28 03:24:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:22,504] {spark_submit.py:490} INFO - 23/05/28 03:24:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:23,142] {spark_submit.py:490} INFO - 23/05/28 03:24:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:23,164] {spark_submit.py:490} INFO - 23/05/28 03:24:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:23,190] {spark_submit.py:490} INFO - 23/05/28 03:24:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:23,193] {spark_submit.py:490} INFO - 23/05/28 03:24:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:24,639] {spark_submit.py:490} INFO - 23/05/28 03:24:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:25,084] {spark_submit.py:490} INFO - 23/05/28 03:24:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:25,366] {spark_submit.py:490} INFO - 23/05/28 03:24:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:26,365] {spark_submit.py:490} INFO - 23/05/28 03:24:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:26,587] {spark_submit.py:490} INFO - 23/05/28 03:24:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:26,771] {spark_submit.py:490} INFO - 23/05/28 03:24:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:26,774] {spark_submit.py:490} INFO - 23/05/28 03:24:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:27,050] {spark_submit.py:490} INFO - 23/05/28 03:24:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:27,063] {spark_submit.py:490} INFO - 23/05/28 03:24:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:27,349] {spark_submit.py:490} INFO - 23/05/28 03:24:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:27,365] {spark_submit.py:490} INFO - 23/05/28 03:24:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:27,858] {spark_submit.py:490} INFO - 23/05/28 03:24:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:28,096] {spark_submit.py:490} INFO - 23/05/28 03:24:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:28,233] {spark_submit.py:490} INFO - 23/05/28 03:24:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:28,587] {spark_submit.py:490} INFO - 23/05/28 03:24:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:30,118] {spark_submit.py:490} INFO - 23/05/28 03:24:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:30,162] {spark_submit.py:490} INFO - 23/05/28 03:24:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:30,226] {spark_submit.py:490} INFO - 23/05/28 03:24:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:30,233] {spark_submit.py:490} INFO - 23/05/28 03:24:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:30,241] {spark_submit.py:490} INFO - 23/05/28 03:24:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,019] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,121] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,123] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,682] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,793] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:31,795] {spark_submit.py:490} INFO - 23/05/28 03:24:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,119] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,152] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,154] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,439] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,459] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,539] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,921] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:32,945] {spark_submit.py:490} INFO - 23/05/28 03:24:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:33,378] {spark_submit.py:490} INFO - 23/05/28 03:24:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,024] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,027] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,028] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,517] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,666] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,672] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:34,741] {spark_submit.py:490} INFO - 23/05/28 03:24:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:35,005] {spark_submit.py:490} INFO - 23/05/28 03:24:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:35,214] {spark_submit.py:490} INFO - 23/05/28 03:24:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:36,987] {spark_submit.py:490} INFO - 23/05/28 03:24:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:37,023] {spark_submit.py:490} INFO - 23/05/28 03:24:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:37,116] {spark_submit.py:490} INFO - 23/05/28 03:24:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:37,118] {spark_submit.py:490} INFO - 23/05/28 03:24:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:38,264] {spark_submit.py:490} INFO - 23/05/28 03:24:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:38,887] {spark_submit.py:490} INFO - 23/05/28 03:24:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:38,945] {spark_submit.py:490} INFO - 23/05/28 03:24:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:39,157] {spark_submit.py:490} INFO - 23/05/28 03:24:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:39,469] {spark_submit.py:490} INFO - 23/05/28 03:24:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:39,969] {spark_submit.py:490} INFO - 23/05/28 03:24:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,107] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,109] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,342] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,436] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,440] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:40,753] {spark_submit.py:490} INFO - 23/05/28 03:24:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,046] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,054] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,366] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,658] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,715] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,912] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,922] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:41,959] {spark_submit.py:490} INFO - 23/05/28 03:24:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:42,000] {spark_submit.py:490} INFO - 23/05/28 03:24:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:42,004] {spark_submit.py:490} INFO - 23/05/28 03:24:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:42,010] {spark_submit.py:490} INFO - 23/05/28 03:24:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:42,013] {spark_submit.py:490} INFO - 23/05/28 03:24:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:43,289] {spark_submit.py:490} INFO - 23/05/28 03:24:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:43,345] {spark_submit.py:490} INFO - 23/05/28 03:24:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:43,348] {spark_submit.py:490} INFO - 23/05/28 03:24:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:43,488] {spark_submit.py:490} INFO - 23/05/28 03:24:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:43,489] {spark_submit.py:490} INFO - 23/05/28 03:24:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:44,142] {spark_submit.py:490} INFO - 23/05/28 03:24:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:44,161] {spark_submit.py:490} INFO - 23/05/28 03:24:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:44,452] {spark_submit.py:490} INFO - 23/05/28 03:24:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:44,457] {spark_submit.py:490} INFO - 23/05/28 03:24:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:45,064] {spark_submit.py:490} INFO - 23/05/28 03:24:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:45,774] {spark_submit.py:490} INFO - 23/05/28 03:24:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:45,777] {spark_submit.py:490} INFO - 23/05/28 03:24:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:47,474] {spark_submit.py:490} INFO - 23/05/28 03:24:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:47,477] {spark_submit.py:490} INFO - 23/05/28 03:24:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:47,849] {spark_submit.py:490} INFO - 23/05/28 03:24:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:47,868] {spark_submit.py:490} INFO - 23/05/28 03:24:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,422] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,435] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,542] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,546] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,855] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:48,860] {spark_submit.py:490} INFO - 23/05/28 03:24:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:49,131] {spark_submit.py:490} INFO - 23/05/28 03:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:49,342] {spark_submit.py:490} INFO - 23/05/28 03:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:49,354] {spark_submit.py:490} INFO - 23/05/28 03:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:49,763] {spark_submit.py:490} INFO - 23/05/28 03:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:49,765] {spark_submit.py:490} INFO - 23/05/28 03:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:50,250] {spark_submit.py:490} INFO - 23/05/28 03:24:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:50,381] {spark_submit.py:490} INFO - 23/05/28 03:24:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:51,800] {spark_submit.py:490} INFO - 23/05/28 03:24:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:51,831] {spark_submit.py:490} INFO - 23/05/28 03:24:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:51,844] {spark_submit.py:490} INFO - 23/05/28 03:24:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:52,098] {spark_submit.py:490} INFO - 23/05/28 03:24:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:52,509] {spark_submit.py:490} INFO - 23/05/28 03:24:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:52,740] {spark_submit.py:490} INFO - 23/05/28 03:24:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:52,989] {spark_submit.py:490} INFO - 23/05/28 03:24:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:53,325] {spark_submit.py:490} INFO - 23/05/28 03:24:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:53,876] {spark_submit.py:490} INFO - 23/05/28 03:24:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:53,888] {spark_submit.py:490} INFO - 23/05/28 03:24:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:54,405] {spark_submit.py:490} INFO - 23/05/28 03:24:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:54,462] {spark_submit.py:490} INFO - 23/05/28 03:24:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:55,070] {spark_submit.py:490} INFO - 23/05/28 03:24:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:55,075] {spark_submit.py:490} INFO - 23/05/28 03:24:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:55,391] {spark_submit.py:490} INFO - 23/05/28 03:24:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:55,480] {spark_submit.py:490} INFO - 23/05/28 03:24:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:56,216] {spark_submit.py:490} INFO - 23/05/28 03:24:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:56,236] {spark_submit.py:490} INFO - 23/05/28 03:24:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:56,238] {spark_submit.py:490} INFO - 23/05/28 03:24:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:57,041] {spark_submit.py:490} INFO - 23/05/28 03:24:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:57,907] {spark_submit.py:490} INFO - 23/05/28 03:24:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,101] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,102] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,343] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,432] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,463] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,484] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:24:58,735] {spark_submit.py:490} INFO - 23/05/28 03:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:00,448] {spark_submit.py:490} INFO - 23/05/28 03:25:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:00,552] {spark_submit.py:490} INFO - 23/05/28 03:25:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:00,556] {spark_submit.py:490} INFO - 23/05/28 03:25:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:00,565] {spark_submit.py:490} INFO - 23/05/28 03:25:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:00,622] {spark_submit.py:490} INFO - 23/05/28 03:25:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:01,412] {spark_submit.py:490} INFO - 23/05/28 03:25:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:01,430] {spark_submit.py:490} INFO - 23/05/28 03:25:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:01,434] {spark_submit.py:490} INFO - 23/05/28 03:25:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:01,724] {spark_submit.py:490} INFO - 23/05/28 03:25:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:02,211] {spark_submit.py:490} INFO - 23/05/28 03:25:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:02,528] {spark_submit.py:490} INFO - 23/05/28 03:25:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:02,534] {spark_submit.py:490} INFO - 23/05/28 03:25:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:02,565] {spark_submit.py:490} INFO - 23/05/28 03:25:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,059] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,105] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,213] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,268] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,273] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,594] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,650] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,653] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:03,847] {spark_submit.py:490} INFO - 23/05/28 03:25:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:04,374] {spark_submit.py:490} INFO - 23/05/28 03:25:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:04,784] {spark_submit.py:490} INFO - 23/05/28 03:25:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,252] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,390] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,395] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,399] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,415] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,456] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,459] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,672] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:06,674] {spark_submit.py:490} INFO - 23/05/28 03:25:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:07,389] {spark_submit.py:490} INFO - 23/05/28 03:25:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:07,423] {spark_submit.py:490} INFO - 23/05/28 03:25:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:07,594] {spark_submit.py:490} INFO - 23/05/28 03:25:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:07,943] {spark_submit.py:490} INFO - 23/05/28 03:25:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:08,036] {spark_submit.py:490} INFO - 23/05/28 03:25:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:08,673] {spark_submit.py:490} INFO - 23/05/28 03:25:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:08,676] {spark_submit.py:490} INFO - 23/05/28 03:25:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:08,790] {spark_submit.py:490} INFO - 23/05/28 03:25:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:09,189] {spark_submit.py:490} INFO - 23/05/28 03:25:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:09,221] {spark_submit.py:490} INFO - 23/05/28 03:25:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:09,230] {spark_submit.py:490} INFO - 23/05/28 03:25:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:09,232] {spark_submit.py:490} INFO - 23/05/28 03:25:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,024] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,026] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,150] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,287] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,314] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,316] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,376] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,381] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:10,757] {spark_submit.py:490} INFO - 23/05/28 03:25:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:11,678] {spark_submit.py:490} INFO - 23/05/28 03:25:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,000] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,051] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,768] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,827] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,830] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:12,868] {spark_submit.py:490} INFO - 23/05/28 03:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,336] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,397] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,400] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,413] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,475] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,547] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:14,552] {spark_submit.py:490} INFO - 23/05/28 03:25:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:15,338] {spark_submit.py:490} INFO - 23/05/28 03:25:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:15,660] {spark_submit.py:490} INFO - 23/05/28 03:25:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:15,671] {spark_submit.py:490} INFO - 23/05/28 03:25:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:15,683] {spark_submit.py:490} INFO - 23/05/28 03:25:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,069] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,072] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,151] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,824] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,892] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:16,916] {spark_submit.py:490} INFO - 23/05/28 03:25:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,076] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,093] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,350] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,359] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,385] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,387] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,579] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:17,582] {spark_submit.py:490} INFO - 23/05/28 03:25:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:18,064] {spark_submit.py:490} INFO - 23/05/28 03:25:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:18,075] {spark_submit.py:490} INFO - 23/05/28 03:25:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:18,547] {spark_submit.py:490} INFO - 23/05/28 03:25:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:19,272] {spark_submit.py:490} INFO - 23/05/28 03:25:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:19,906] {spark_submit.py:490} INFO - 23/05/28 03:25:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:19,932] {spark_submit.py:490} INFO - 23/05/28 03:25:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:19,936] {spark_submit.py:490} INFO - 23/05/28 03:25:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:21,268] {spark_submit.py:490} INFO - 23/05/28 03:25:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:21,649] {spark_submit.py:490} INFO - 23/05/28 03:25:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:21,712] {spark_submit.py:490} INFO - 23/05/28 03:25:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:21,865] {spark_submit.py:490} INFO - 23/05/28 03:25:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:21,872] {spark_submit.py:490} INFO - 23/05/28 03:25:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:22,058] {spark_submit.py:490} INFO - 23/05/28 03:25:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:22,064] {spark_submit.py:490} INFO - 23/05/28 03:25:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:22,953] {spark_submit.py:490} INFO - 23/05/28 03:25:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:23,512] {spark_submit.py:490} INFO - 23/05/28 03:25:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:23,533] {spark_submit.py:490} INFO - 23/05/28 03:25:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:23,626] {spark_submit.py:490} INFO - 23/05/28 03:25:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:24,466] {spark_submit.py:490} INFO - 23/05/28 03:25:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:24,610] {spark_submit.py:490} INFO - 23/05/28 03:25:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:24,623] {spark_submit.py:490} INFO - 23/05/28 03:25:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:25,390] {spark_submit.py:490} INFO - 23/05/28 03:25:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:25,560] {spark_submit.py:490} INFO - 23/05/28 03:25:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:25,943] {spark_submit.py:490} INFO - 23/05/28 03:25:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,189] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,192] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,218] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,466] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,483] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,485] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,958] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,976] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:26,977] {spark_submit.py:490} INFO - 23/05/28 03:25:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,021] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,024] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,029] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,508] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,520] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,567] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,569] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,634] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,639] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:27,892] {spark_submit.py:490} INFO - 23/05/28 03:25:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:28,097] {spark_submit.py:490} INFO - 23/05/28 03:25:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:28,104] {spark_submit.py:490} INFO - 23/05/28 03:25:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:28,835] {spark_submit.py:490} INFO - 23/05/28 03:25:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:28,839] {spark_submit.py:490} INFO - 23/05/28 03:25:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:28,918] {spark_submit.py:490} INFO - 23/05/28 03:25:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:29,233] {spark_submit.py:490} INFO - 23/05/28 03:25:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:29,236] {spark_submit.py:490} INFO - 23/05/28 03:25:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:30,325] {spark_submit.py:490} INFO - 23/05/28 03:25:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:30,443] {spark_submit.py:490} INFO - 23/05/28 03:25:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:30,653] {spark_submit.py:490} INFO - 23/05/28 03:25:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:30,658] {spark_submit.py:490} INFO - 23/05/28 03:25:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:31,568] {spark_submit.py:490} INFO - 23/05/28 03:25:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:31,780] {spark_submit.py:490} INFO - 23/05/28 03:25:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,051] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,057] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,203] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,207] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,779] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:32,956] {spark_submit.py:490} INFO - 23/05/28 03:25:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:33,686] {spark_submit.py:490} INFO - 23/05/28 03:25:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:33,687] {spark_submit.py:490} INFO - 23/05/28 03:25:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:34,313] {spark_submit.py:490} INFO - 23/05/28 03:25:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:34,432] {spark_submit.py:490} INFO - 23/05/28 03:25:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:34,569] {spark_submit.py:490} INFO - 23/05/28 03:25:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,145] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,315] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,318] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,410] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,425] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:35,431] {spark_submit.py:490} INFO - 23/05/28 03:25:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:36,217] {spark_submit.py:490} INFO - 23/05/28 03:25:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:36,232] {spark_submit.py:490} INFO - 23/05/28 03:25:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:36,237] {spark_submit.py:490} INFO - 23/05/28 03:25:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:36,883] {spark_submit.py:490} INFO - 23/05/28 03:25:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:37,225] {spark_submit.py:490} INFO - 23/05/28 03:25:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:37,430] {spark_submit.py:490} INFO - 23/05/28 03:25:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:38,475] {spark_submit.py:490} INFO - 23/05/28 03:25:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:38,626] {spark_submit.py:490} INFO - 23/05/28 03:25:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:38,632] {spark_submit.py:490} INFO - 23/05/28 03:25:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:39,632] {spark_submit.py:490} INFO - 23/05/28 03:25:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:39,675] {spark_submit.py:490} INFO - 23/05/28 03:25:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,485] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,533] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,565] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,676] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,749] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:40,794] {spark_submit.py:490} INFO - 23/05/28 03:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:42,401] {spark_submit.py:490} INFO - 23/05/28 03:25:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:43,040] {spark_submit.py:490} INFO - 23/05/28 03:25:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:43,191] {spark_submit.py:490} INFO - 23/05/28 03:25:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:43,435] {spark_submit.py:490} INFO - 23/05/28 03:25:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:43,444] {spark_submit.py:490} INFO - 23/05/28 03:25:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:44,233] {spark_submit.py:490} INFO - 23/05/28 03:25:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:44,286] {spark_submit.py:490} INFO - 23/05/28 03:25:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:44,858] {spark_submit.py:490} INFO - 23/05/28 03:25:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,132] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,146] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,173] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,749] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,811] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:45,867] {spark_submit.py:490} INFO - 23/05/28 03:25:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:46,757] {spark_submit.py:490} INFO - 23/05/28 03:25:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:46,786] {spark_submit.py:490} INFO - 23/05/28 03:25:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:47,151] {spark_submit.py:490} INFO - 23/05/28 03:25:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:47,199] {spark_submit.py:490} INFO - 23/05/28 03:25:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:48,325] {spark_submit.py:490} INFO - 23/05/28 03:25:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:48,337] {spark_submit.py:490} INFO - 23/05/28 03:25:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:48,356] {spark_submit.py:490} INFO - 23/05/28 03:25:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:48,473] {spark_submit.py:490} INFO - 23/05/28 03:25:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:48,520] {spark_submit.py:490} INFO - 23/05/28 03:25:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,062] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,069] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,070] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,107] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,109] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,659] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,661] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,973] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,987] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:49,995] {spark_submit.py:490} INFO - 23/05/28 03:25:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:50,104] {spark_submit.py:490} INFO - 23/05/28 03:25:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:50,107] {spark_submit.py:490} INFO - 23/05/28 03:25:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:50,339] {spark_submit.py:490} INFO - 23/05/28 03:25:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:50,711] {spark_submit.py:490} INFO - 23/05/28 03:25:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:51,760] {spark_submit.py:490} INFO - 23/05/28 03:25:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:52,017] {spark_submit.py:490} INFO - 23/05/28 03:25:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:52,029] {spark_submit.py:490} INFO - 23/05/28 03:25:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:52,172] {spark_submit.py:490} INFO - 23/05/28 03:25:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:52,172] {spark_submit.py:490} INFO - 23/05/28 03:25:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:53,230] {spark_submit.py:490} INFO - 23/05/28 03:25:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:53,328] {spark_submit.py:490} INFO - 23/05/28 03:25:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:54,224] {spark_submit.py:490} INFO - 23/05/28 03:25:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:54,693] {spark_submit.py:490} INFO - 23/05/28 03:25:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:54,718] {spark_submit.py:490} INFO - 23/05/28 03:25:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:55,123] {spark_submit.py:490} INFO - 23/05/28 03:25:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:55,713] {spark_submit.py:490} INFO - 23/05/28 03:25:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:56,383] {spark_submit.py:490} INFO - 23/05/28 03:25:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:56,408] {spark_submit.py:490} INFO - 23/05/28 03:25:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:56,681] {spark_submit.py:490} INFO - 23/05/28 03:25:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:57,714] {spark_submit.py:490} INFO - 23/05/28 03:25:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:57,730] {spark_submit.py:490} INFO - 23/05/28 03:25:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:59,252] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:59,292] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000003_214' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000003
[2023-05-28 03:25:59,293] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000003_214: Committed. Elapsed time: 3 ms.
[2023-05-28 03:25:59,311] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO Executor: Finished task 3.0 in stage 4.0 (TID 214). 6113 bytes result sent to driver
[2023-05-28 03:25:59,313] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 215) (c1224b457a2d, executor driver, partition 4, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:25:59,315] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 214) in 174923 ms on c1224b457a2d (executor driver) (1/28)
[2023-05-28 03:25:59,326] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO Executor: Running task 4.0 in stage 4.0 (TID 215)
[2023-05-28 03:25:59,346] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ShuffleBlockFetcherIterator: Getting 11 (58.7 MiB) non-empty blocks including 11 (58.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:25:59,347] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-28 03:25:59,382] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:59,605] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO UnsafeExternalSorter: Thread 121 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:25:59,772] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:25:59,805] {spark_submit.py:490} INFO - 23/05/28 03:25:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:00,043] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO UnsafeExternalSorter: Thread 121 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:26:00,413] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:00,414] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:00,415] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:00,415] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:00,416] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:00,417] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:00,417] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:00,419] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:00,424] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:00,425] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:26:00,427] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:26:00,427] {spark_submit.py:490} INFO - {
[2023-05-28 03:26:00,428] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:26:00,428] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:26:00,428] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:26:00,429] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,429] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,429] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,430] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,430] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:26:00,430] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,431] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,431] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,432] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,432] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:26:00,432] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,433] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,433] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,433] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,434] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:26:00,434] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,434] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,435] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,435] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,435] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:26:00,436] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,436] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,437] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,437] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,437] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:26:00,438] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,438] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,438] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,439] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,439] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:26:00,441] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,442] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,442] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,443] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,443] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:26:00,444] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,444] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,445] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,445] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,445] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:26:00,446] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:00,447] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,447] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,447] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,448] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:26:00,448] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:00,449] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,449] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,450] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:00,450] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:26:00,450] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:00,451] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:00,451] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:00,451] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:26:00,452] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:00,452] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:26:00,452] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:26:00,453] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:26:00,453] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:26:00,453] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:26:00,454] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:26:00,454] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:26:00,454] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:26:00,455] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:26:00,455] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:26:00,455] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:26:00,456] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:26:00,456] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:26:00,456] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:00,457] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:00,457] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:00,528] {spark_submit.py:490} INFO - 23/05/28 03:26:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:01,252] {spark_submit.py:490} INFO - 23/05/28 03:26:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:01,258] {spark_submit.py:490} INFO - 23/05/28 03:26:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:01,769] {spark_submit.py:490} INFO - 23/05/28 03:26:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:01,830] {spark_submit.py:490} INFO - 23/05/28 03:26:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:02,405] {spark_submit.py:490} INFO - 23/05/28 03:26:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:02,646] {spark_submit.py:490} INFO - 23/05/28 03:26:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:02,648] {spark_submit.py:490} INFO - 23/05/28 03:26:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:03,544] {spark_submit.py:490} INFO - 23/05/28 03:26:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,052] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,364] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,494] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,506] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,593] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:04,608] {spark_submit.py:490} INFO - 23/05/28 03:26:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:05,087] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000001_212' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000001
[2023-05-28 03:26:05,088] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000001_212: Committed. Elapsed time: 17 ms.
[2023-05-28 03:26:05,089] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO Executor: Finished task 1.0 in stage 4.0 (TID 212). 6070 bytes result sent to driver
[2023-05-28 03:26:05,090] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 216) (c1224b457a2d, executor driver, partition 5, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:26:05,091] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 212) in 180700 ms on c1224b457a2d (executor driver) (2/28)
[2023-05-28 03:26:05,092] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO Executor: Running task 5.0 in stage 4.0 (TID 216)
[2023-05-28 03:26:05,111] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO ShuffleBlockFetcherIterator: Getting 11 (62.1 MiB) non-empty blocks including 11 (62.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:26:05,112] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-28 03:26:05,243] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:26:05,590] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:26:05,962] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:05,985] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:05,993] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:05,994] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:05,995] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:05,995] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:05,996] {spark_submit.py:490} INFO - 23/05/28 03:26:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:06,011] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:06,041] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:06,045] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:06,055] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:06,057] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:26:06,058] {spark_submit.py:490} INFO - 23/05/28 03:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:26:06,058] {spark_submit.py:490} INFO - {
[2023-05-28 03:26:06,059] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:26:06,060] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:26:06,060] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:26:06,061] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,061] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,061] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,062] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,062] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:26:06,062] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,063] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,063] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,064] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,064] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:26:06,064] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,064] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,065] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,065] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,065] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:26:06,066] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,066] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,067] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,067] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,067] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:26:06,067] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,068] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,068] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,068] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,069] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:26:06,069] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,070] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,070] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,070] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,071] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:26:06,071] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,071] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,071] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,072] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,072] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:26:06,073] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,073] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,074] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,074] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,075] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:26:06,077] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:06,078] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,078] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,079] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,079] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:26:06,080] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:06,080] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,081] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,081] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:06,082] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:26:06,082] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:06,082] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:06,083] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:06,083] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:26:06,084] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:06,085] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:26:06,085] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:26:06,085] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:26:06,086] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:26:06,086] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:26:06,087] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:26:06,087] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:26:06,087] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:26:06,088] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:26:06,088] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:26:06,089] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:26:06,089] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:26:06,089] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:26:06,090] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:06,090] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:06,091] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:08,203] {spark_submit.py:490} INFO - 23/05/28 03:26:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:08,206] {spark_submit.py:490} INFO - 23/05/28 03:26:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:08,350] {spark_submit.py:490} INFO - 23/05/28 03:26:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:08,508] {spark_submit.py:490} INFO - 23/05/28 03:26:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:08,583] {spark_submit.py:490} INFO - 23/05/28 03:26:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:09,328] {spark_submit.py:490} INFO - 23/05/28 03:26:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:09,480] {spark_submit.py:490} INFO - 23/05/28 03:26:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:09,842] {spark_submit.py:490} INFO - 23/05/28 03:26:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:09,859] {spark_submit.py:490} INFO - 23/05/28 03:26:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:10,394] {spark_submit.py:490} INFO - 23/05/28 03:26:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:10,474] {spark_submit.py:490} INFO - 23/05/28 03:26:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:11,691] {spark_submit.py:490} INFO - 23/05/28 03:26:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:11,862] {spark_submit.py:490} INFO - 23/05/28 03:26:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:11,935] {spark_submit.py:490} INFO - 23/05/28 03:26:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:12,247] {spark_submit.py:490} INFO - 23/05/28 03:26:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:12,316] {spark_submit.py:490} INFO - 23/05/28 03:26:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:12,510] {spark_submit.py:490} INFO - 23/05/28 03:26:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:12,689] {spark_submit.py:490} INFO - 23/05/28 03:26:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:13,297] {spark_submit.py:490} INFO - 23/05/28 03:26:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:13,302] {spark_submit.py:490} INFO - 23/05/28 03:26:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:15,780] {spark_submit.py:490} INFO - 23/05/28 03:26:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,066] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,105] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,200] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,204] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,264] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,273] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,279] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:16,671] {spark_submit.py:490} INFO - 23/05/28 03:26:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,384] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,511] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,516] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,671] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,675] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,678] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,680] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:17,695] {spark_submit.py:490} INFO - 23/05/28 03:26:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:18,910] {spark_submit.py:490} INFO - 23/05/28 03:26:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:19,291] {spark_submit.py:490} INFO - 23/05/28 03:26:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:19,295] {spark_submit.py:490} INFO - 23/05/28 03:26:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:19,324] {spark_submit.py:490} INFO - 23/05/28 03:26:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:19,329] {spark_submit.py:490} INFO - 23/05/28 03:26:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:19,864] {spark_submit.py:490} INFO - 23/05/28 03:26:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:20,819] {spark_submit.py:490} INFO - 23/05/28 03:26:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:20,821] {spark_submit.py:490} INFO - 23/05/28 03:26:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:21,689] {spark_submit.py:490} INFO - 23/05/28 03:26:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:22,313] {spark_submit.py:490} INFO - 23/05/28 03:26:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:22,344] {spark_submit.py:490} INFO - 23/05/28 03:26:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:22,351] {spark_submit.py:490} INFO - 23/05/28 03:26:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:22,565] {spark_submit.py:490} INFO - 23/05/28 03:26:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:22,574] {spark_submit.py:490} INFO - 23/05/28 03:26:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,234] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,240] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,416] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,422] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,632] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:23,646] {spark_submit.py:490} INFO - 23/05/28 03:26:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:24,513] {spark_submit.py:490} INFO - 23/05/28 03:26:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:24,777] {spark_submit.py:490} INFO - 23/05/28 03:26:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:25,945] {spark_submit.py:490} INFO - 23/05/28 03:26:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:25,954] {spark_submit.py:490} INFO - 23/05/28 03:26:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:25,955] {spark_submit.py:490} INFO - 23/05/28 03:26:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:26,592] {spark_submit.py:490} INFO - 23/05/28 03:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:26,595] {spark_submit.py:490} INFO - 23/05/28 03:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:26,866] {spark_submit.py:490} INFO - 23/05/28 03:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:26,871] {spark_submit.py:490} INFO - 23/05/28 03:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:26,954] {spark_submit.py:490} INFO - 23/05/28 03:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:27,079] {spark_submit.py:490} INFO - 23/05/28 03:26:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:27,200] {spark_submit.py:490} INFO - 23/05/28 03:26:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:27,892] {spark_submit.py:490} INFO - 23/05/28 03:26:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:28,080] {spark_submit.py:490} INFO - 23/05/28 03:26:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:28,106] {spark_submit.py:490} INFO - 23/05/28 03:26:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:28,118] {spark_submit.py:490} INFO - 23/05/28 03:26:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,004] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,018] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,021] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,415] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,421] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:29,844] {spark_submit.py:490} INFO - 23/05/28 03:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:30,698] {spark_submit.py:490} INFO - 23/05/28 03:26:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:30,715] {spark_submit.py:490} INFO - 23/05/28 03:26:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:30,778] {spark_submit.py:490} INFO - 23/05/28 03:26:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:32,014] {spark_submit.py:490} INFO - 23/05/28 03:26:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:32,462] {spark_submit.py:490} INFO - 23/05/28 03:26:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:32,465] {spark_submit.py:490} INFO - 23/05/28 03:26:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:32,538] {spark_submit.py:490} INFO - 23/05/28 03:26:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:32,541] {spark_submit.py:490} INFO - 23/05/28 03:26:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:33,383] {spark_submit.py:490} INFO - 23/05/28 03:26:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:33,486] {spark_submit.py:490} INFO - 23/05/28 03:26:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:33,534] {spark_submit.py:490} INFO - 23/05/28 03:26:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:33,581] {spark_submit.py:490} INFO - 23/05/28 03:26:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:35,503] {spark_submit.py:490} INFO - 23/05/28 03:26:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:35,567] {spark_submit.py:490} INFO - 23/05/28 03:26:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:35,570] {spark_submit.py:490} INFO - 23/05/28 03:26:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:36,137] {spark_submit.py:490} INFO - 23/05/28 03:26:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:36,166] {spark_submit.py:490} INFO - 23/05/28 03:26:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:36,170] {spark_submit.py:490} INFO - 23/05/28 03:26:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:37,241] {spark_submit.py:490} INFO - 23/05/28 03:26:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:37,797] {spark_submit.py:490} INFO - 23/05/28 03:26:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:39,622] {spark_submit.py:490} INFO - 23/05/28 03:26:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:39,719] {spark_submit.py:490} INFO - 23/05/28 03:26:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:40,103] {spark_submit.py:490} INFO - 23/05/28 03:26:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:40,273] {spark_submit.py:490} INFO - 23/05/28 03:26:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:40,278] {spark_submit.py:490} INFO - 23/05/28 03:26:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:41,123] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000000_211' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000000
[2023-05-28 03:26:41,124] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000000_211: Committed. Elapsed time: 2 ms.
[2023-05-28 03:26:41,126] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO Executor: Finished task 0.0 in stage 4.0 (TID 211). 6113 bytes result sent to driver
[2023-05-28 03:26:41,128] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 217) (c1224b457a2d, executor driver, partition 6, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:26:41,130] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO Executor: Running task 6.0 in stage 4.0 (TID 217)
[2023-05-28 03:26:41,132] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 211) in 216740 ms on c1224b457a2d (executor driver) (3/28)
[2023-05-28 03:26:41,148] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO ShuffleBlockFetcherIterator: Getting 11 (62.1 MiB) non-empty blocks including 11 (62.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:26:41,149] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2023-05-28 03:26:41,455] {spark_submit.py:490} INFO - 23/05/28 03:26:41 INFO UnsafeExternalSorter: Thread 64 spilling sort data of 144.0 MiB to disk (0  time so far)
[2023-05-28 03:26:42,005] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:42,013] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:42,014] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:42,014] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:42,015] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:42,015] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:42,015] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:42,018] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:42,027] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:42,028] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:42,031] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:26:42,045] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:26:42,046] {spark_submit.py:490} INFO - {
[2023-05-28 03:26:42,049] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:26:42,050] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:26:42,051] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:26:42,051] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,052] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,052] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,053] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,054] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:26:42,055] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,055] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,056] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,056] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,057] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:26:42,057] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,058] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,058] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,058] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,059] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:26:42,059] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,060] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,061] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,061] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,062] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:26:42,063] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,063] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,064] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,064] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,064] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:26:42,065] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,065] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,080] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,081] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,081] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:26:42,082] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,083] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,083] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,083] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,084] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:26:42,084] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,085] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,085] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,086] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,086] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:26:42,087] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:42,087] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,088] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,088] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,089] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:26:42,089] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:42,090] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,090] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,091] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:42,092] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:26:42,092] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:42,093] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:42,093] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:42,094] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:26:42,094] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:42,095] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:26:42,095] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:26:42,095] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:26:42,096] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:26:42,097] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:26:42,098] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:26:42,102] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:26:42,103] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:26:42,103] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:26:42,104] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:26:42,105] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:26:42,105] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:26:42,106] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:26:42,106] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:42,107] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:42,107] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:42,108] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:42,116] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:42,144] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000002_213' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000002
[2023-05-28 03:26:42,144] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000002_213: Committed. Elapsed time: 4 ms.
[2023-05-28 03:26:42,152] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO Executor: Finished task 2.0 in stage 4.0 (TID 213). 6070 bytes result sent to driver
[2023-05-28 03:26:42,158] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 218) (c1224b457a2d, executor driver, partition 7, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:26:42,159] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO Executor: Running task 7.0 in stage 4.0 (TID 218)
[2023-05-28 03:26:42,161] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 213) in 217770 ms on c1224b457a2d (executor driver) (4/28)
[2023-05-28 03:26:42,171] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ShuffleBlockFetcherIterator: Getting 11 (63.9 MiB) non-empty blocks including 11 (63.9 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:26:42,172] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-28 03:26:42,361] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 100.0 MiB to disk (0  time so far)
[2023-05-28 03:26:42,687] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:26:42,993] {spark_submit.py:490} INFO - 23/05/28 03:26:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,025] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:43,026] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:43,026] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:43,027] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:26:43,027] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:26:43,027] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:26:43,028] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,029] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:43,029] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:26:43,030] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:26:43,030] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:26:43,031] {spark_submit.py:490} INFO - {
[2023-05-28 03:26:43,031] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:26:43,032] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:26:43,032] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:26:43,033] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,033] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,033] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,034] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,034] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:26:43,035] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,035] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,035] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,036] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,036] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:26:43,036] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,037] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,037] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,037] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,038] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:26:43,038] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,038] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,038] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,039] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,039] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:26:43,039] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,040] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,040] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,040] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,040] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:26:43,041] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,041] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,042] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,042] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,044] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:26:43,044] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,045] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,045] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,046] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,046] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:26:43,046] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,047] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,047] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,047] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,048] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:26:43,048] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:26:43,049] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,049] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,050] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,050] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:26:43,051] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:43,051] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,051] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,052] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:26:43,052] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:26:43,053] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:26:43,053] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:26:43,054] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:26:43,054] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:26:43,055] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:43,055] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:26:43,056] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:26:43,056] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:26:43,056] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:26:43,057] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:26:43,057] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:26:43,057] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:26:43,058] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:26:43,058] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:26:43,058] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:26:43,059] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:26:43,059] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:26:43,059] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:26:43,060] {spark_submit.py:490} INFO - }
[2023-05-28 03:26:43,060] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:43,060] {spark_submit.py:490} INFO - 
[2023-05-28 03:26:43,083] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,170] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,220] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,222] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,520] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:43,522] {spark_submit.py:490} INFO - 23/05/28 03:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:44,139] {spark_submit.py:490} INFO - 23/05/28 03:26:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:44,243] {spark_submit.py:490} INFO - 23/05/28 03:26:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:44,247] {spark_submit.py:490} INFO - 23/05/28 03:26:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:44,298] {spark_submit.py:490} INFO - 23/05/28 03:26:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:44,350] {spark_submit.py:490} INFO - 23/05/28 03:26:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:45,204] {spark_submit.py:490} INFO - 23/05/28 03:26:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:45,396] {spark_submit.py:490} INFO - 23/05/28 03:26:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:45,400] {spark_submit.py:490} INFO - 23/05/28 03:26:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:45,526] {spark_submit.py:490} INFO - 23/05/28 03:26:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:45,559] {spark_submit.py:490} INFO - 23/05/28 03:26:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:47,161] {spark_submit.py:490} INFO - 23/05/28 03:26:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:47,615] {spark_submit.py:490} INFO - 23/05/28 03:26:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:47,621] {spark_submit.py:490} INFO - 23/05/28 03:26:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:47,629] {spark_submit.py:490} INFO - 23/05/28 03:26:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:49,335] {spark_submit.py:490} INFO - 23/05/28 03:26:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:49,569] {spark_submit.py:490} INFO - 23/05/28 03:26:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:49,572] {spark_submit.py:490} INFO - 23/05/28 03:26:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,216] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,266] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,519] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,648] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,659] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:50,895] {spark_submit.py:490} INFO - 23/05/28 03:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:51,570] {spark_submit.py:490} INFO - 23/05/28 03:26:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:51,702] {spark_submit.py:490} INFO - 23/05/28 03:26:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:51,906] {spark_submit.py:490} INFO - 23/05/28 03:26:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:52,191] {spark_submit.py:490} INFO - 23/05/28 03:26:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:52,272] {spark_submit.py:490} INFO - 23/05/28 03:26:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:52,277] {spark_submit.py:490} INFO - 23/05/28 03:26:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:53,186] {spark_submit.py:490} INFO - 23/05/28 03:26:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:53,295] {spark_submit.py:490} INFO - 23/05/28 03:26:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:53,297] {spark_submit.py:490} INFO - 23/05/28 03:26:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:53,434] {spark_submit.py:490} INFO - 23/05/28 03:26:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:53,513] {spark_submit.py:490} INFO - 23/05/28 03:26:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:54,024] {spark_submit.py:490} INFO - 23/05/28 03:26:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:54,540] {spark_submit.py:490} INFO - 23/05/28 03:26:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:54,706] {spark_submit.py:490} INFO - 23/05/28 03:26:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:54,708] {spark_submit.py:490} INFO - 23/05/28 03:26:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:55,568] {spark_submit.py:490} INFO - 23/05/28 03:26:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:55,585] {spark_submit.py:490} INFO - 23/05/28 03:26:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:55,960] {spark_submit.py:490} INFO - 23/05/28 03:26:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:55,972] {spark_submit.py:490} INFO - 23/05/28 03:26:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,228] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,241] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,445] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,448] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,680] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:57,840] {spark_submit.py:490} INFO - 23/05/28 03:26:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,112] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,127] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,130] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,330] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,441] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,565] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,590] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:58,631] {spark_submit.py:490} INFO - 23/05/28 03:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:59,193] {spark_submit.py:490} INFO - 23/05/28 03:26:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:59,460] {spark_submit.py:490} INFO - 23/05/28 03:26:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:59,464] {spark_submit.py:490} INFO - 23/05/28 03:26:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:59,794] {spark_submit.py:490} INFO - 23/05/28 03:26:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:26:59,798] {spark_submit.py:490} INFO - 23/05/28 03:26:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,185] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,199] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,375] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,646] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,650] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,748] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,751] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,840] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,899] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:00,913] {spark_submit.py:490} INFO - 23/05/28 03:27:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:01,560] {spark_submit.py:490} INFO - 23/05/28 03:27:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:01,566] {spark_submit.py:490} INFO - 23/05/28 03:27:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:02,229] {spark_submit.py:490} INFO - 23/05/28 03:27:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:02,374] {spark_submit.py:490} INFO - 23/05/28 03:27:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:03,502] {spark_submit.py:490} INFO - 23/05/28 03:27:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:03,551] {spark_submit.py:490} INFO - 23/05/28 03:27:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:03,555] {spark_submit.py:490} INFO - 23/05/28 03:27:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:04,232] {spark_submit.py:490} INFO - 23/05/28 03:27:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:04,248] {spark_submit.py:490} INFO - 23/05/28 03:27:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:04,253] {spark_submit.py:490} INFO - 23/05/28 03:27:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:04,256] {spark_submit.py:490} INFO - 23/05/28 03:27:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:04,927] {spark_submit.py:490} INFO - 23/05/28 03:27:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:05,195] {spark_submit.py:490} INFO - 23/05/28 03:27:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:05,202] {spark_submit.py:490} INFO - 23/05/28 03:27:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,088] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,190] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,790] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,833] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,907] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:06,913] {spark_submit.py:490} INFO - 23/05/28 03:27:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:07,182] {spark_submit.py:490} INFO - 23/05/28 03:27:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:07,189] {spark_submit.py:490} INFO - 23/05/28 03:27:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:07,446] {spark_submit.py:490} INFO - 23/05/28 03:27:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:07,455] {spark_submit.py:490} INFO - 23/05/28 03:27:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:07,458] {spark_submit.py:490} INFO - 23/05/28 03:27:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:08,760] {spark_submit.py:490} INFO - 23/05/28 03:27:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:08,791] {spark_submit.py:490} INFO - 23/05/28 03:27:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:08,864] {spark_submit.py:490} INFO - 23/05/28 03:27:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:09,203] {spark_submit.py:490} INFO - 23/05/28 03:27:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:09,206] {spark_submit.py:490} INFO - 23/05/28 03:27:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:10,000] {spark_submit.py:490} INFO - 23/05/28 03:27:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:10,002] {spark_submit.py:490} INFO - 23/05/28 03:27:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:10,562] {spark_submit.py:490} INFO - 23/05/28 03:27:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:11,271] {spark_submit.py:490} INFO - 23/05/28 03:27:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:11,283] {spark_submit.py:490} INFO - 23/05/28 03:27:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:11,705] {spark_submit.py:490} INFO - 23/05/28 03:27:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:11,709] {spark_submit.py:490} INFO - 23/05/28 03:27:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:12,895] {spark_submit.py:490} INFO - 23/05/28 03:27:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:12,979] {spark_submit.py:490} INFO - 23/05/28 03:27:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:13,794] {spark_submit.py:490} INFO - 23/05/28 03:27:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,308] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,317] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,321] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,331] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,473] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,507] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,536] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,565] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:14,611] {spark_submit.py:490} INFO - 23/05/28 03:27:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:15,627] {spark_submit.py:490} INFO - 23/05/28 03:27:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:15,863] {spark_submit.py:490} INFO - 23/05/28 03:27:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:15,873] {spark_submit.py:490} INFO - 23/05/28 03:27:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:16,221] {spark_submit.py:490} INFO - 23/05/28 03:27:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:16,406] {spark_submit.py:490} INFO - 23/05/28 03:27:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:16,502] {spark_submit.py:490} INFO - 23/05/28 03:27:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:16,508] {spark_submit.py:490} INFO - 23/05/28 03:27:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:17,175] {spark_submit.py:490} INFO - 23/05/28 03:27:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:17,572] {spark_submit.py:490} INFO - 23/05/28 03:27:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:17,575] {spark_submit.py:490} INFO - 23/05/28 03:27:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:17,837] {spark_submit.py:490} INFO - 23/05/28 03:27:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:18,295] {spark_submit.py:490} INFO - 23/05/28 03:27:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:18,296] {spark_submit.py:490} INFO - 23/05/28 03:27:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:19,336] {spark_submit.py:490} INFO - 23/05/28 03:27:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:19,340] {spark_submit.py:490} INFO - 23/05/28 03:27:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:19,642] {spark_submit.py:490} INFO - 23/05/28 03:27:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:19,652] {spark_submit.py:490} INFO - 23/05/28 03:27:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:19,972] {spark_submit.py:490} INFO - 23/05/28 03:27:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:20,194] {spark_submit.py:490} INFO - 23/05/28 03:27:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:20,428] {spark_submit.py:490} INFO - 23/05/28 03:27:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:20,429] {spark_submit.py:490} INFO - 23/05/28 03:27:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:20,471] {spark_submit.py:490} INFO - 23/05/28 03:27:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:20,480] {spark_submit.py:490} INFO - 23/05/28 03:27:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:21,756] {spark_submit.py:490} INFO - 23/05/28 03:27:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:21,760] {spark_submit.py:490} INFO - 23/05/28 03:27:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,548] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,640] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,651] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,657] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,687] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:22,968] {spark_submit.py:490} INFO - 23/05/28 03:27:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,086] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,088] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,670] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,675] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,696] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,714] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:23,721] {spark_submit.py:490} INFO - 23/05/28 03:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:24,211] {spark_submit.py:490} INFO - 23/05/28 03:27:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:24,907] {spark_submit.py:490} INFO - 23/05/28 03:27:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:25,009] {spark_submit.py:490} INFO - 23/05/28 03:27:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:25,030] {spark_submit.py:490} INFO - 23/05/28 03:27:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:25,927] {spark_submit.py:490} INFO - 23/05/28 03:27:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:25,946] {spark_submit.py:490} INFO - 23/05/28 03:27:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:26,801] {spark_submit.py:490} INFO - 23/05/28 03:27:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:26,833] {spark_submit.py:490} INFO - 23/05/28 03:27:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:26,835] {spark_submit.py:490} INFO - 23/05/28 03:27:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:27,757] {spark_submit.py:490} INFO - 23/05/28 03:27:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:27,818] {spark_submit.py:490} INFO - 23/05/28 03:27:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:27,819] {spark_submit.py:490} INFO - 23/05/28 03:27:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:27,954] {spark_submit.py:490} INFO - 23/05/28 03:27:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:28,642] {spark_submit.py:490} INFO - 23/05/28 03:27:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,001] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,767] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,848] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,849] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,957] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:29,986] {spark_submit.py:490} INFO - 23/05/28 03:27:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:30,569] {spark_submit.py:490} INFO - 23/05/28 03:27:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:30,805] {spark_submit.py:490} INFO - 23/05/28 03:27:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:30,934] {spark_submit.py:490} INFO - 23/05/28 03:27:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,397] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,535] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,536] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,558] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,610] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,616] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,858] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,952] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:31,957] {spark_submit.py:490} INFO - 23/05/28 03:27:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:32,002] {spark_submit.py:490} INFO - 23/05/28 03:27:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:32,265] {spark_submit.py:490} INFO - 23/05/28 03:27:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:32,588] {spark_submit.py:490} INFO - 23/05/28 03:27:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:32,592] {spark_submit.py:490} INFO - 23/05/28 03:27:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:34,285] {spark_submit.py:490} INFO - 23/05/28 03:27:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:34,596] {spark_submit.py:490} INFO - 23/05/28 03:27:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:34,615] {spark_submit.py:490} INFO - 23/05/28 03:27:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:34,621] {spark_submit.py:490} INFO - 23/05/28 03:27:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:35,198] {spark_submit.py:490} INFO - 23/05/28 03:27:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:35,231] {spark_submit.py:490} INFO - 23/05/28 03:27:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:35,252] {spark_submit.py:490} INFO - 23/05/28 03:27:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:35,257] {spark_submit.py:490} INFO - 23/05/28 03:27:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:35,341] {spark_submit.py:490} INFO - 23/05/28 03:27:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:36,686] {spark_submit.py:490} INFO - 23/05/28 03:27:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:36,837] {spark_submit.py:490} INFO - 23/05/28 03:27:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:36,846] {spark_submit.py:490} INFO - 23/05/28 03:27:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:37,046] {spark_submit.py:490} INFO - 23/05/28 03:27:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:37,289] {spark_submit.py:490} INFO - 23/05/28 03:27:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:37,356] {spark_submit.py:490} INFO - 23/05/28 03:27:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:38,287] {spark_submit.py:490} INFO - 23/05/28 03:27:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:38,291] {spark_submit.py:490} INFO - 23/05/28 03:27:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:38,399] {spark_submit.py:490} INFO - 23/05/28 03:27:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:38,817] {spark_submit.py:490} INFO - 23/05/28 03:27:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:39,143] {spark_submit.py:490} INFO - 23/05/28 03:27:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:39,146] {spark_submit.py:490} INFO - 23/05/28 03:27:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:39,723] {spark_submit.py:490} INFO - 23/05/28 03:27:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:39,745] {spark_submit.py:490} INFO - 23/05/28 03:27:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:40,422] {spark_submit.py:490} INFO - 23/05/28 03:27:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:40,435] {spark_submit.py:490} INFO - 23/05/28 03:27:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:40,554] {spark_submit.py:490} INFO - 23/05/28 03:27:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:41,952] {spark_submit.py:490} INFO - 23/05/28 03:27:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:42,003] {spark_submit.py:490} INFO - 23/05/28 03:27:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:42,018] {spark_submit.py:490} INFO - 23/05/28 03:27:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:42,123] {spark_submit.py:490} INFO - 23/05/28 03:27:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:42,981] {spark_submit.py:490} INFO - 23/05/28 03:27:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,445] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,486] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,650] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,725] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,727] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:43,871] {spark_submit.py:490} INFO - 23/05/28 03:27:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:44,458] {spark_submit.py:490} INFO - 23/05/28 03:27:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:44,566] {spark_submit.py:490} INFO - 23/05/28 03:27:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:44,568] {spark_submit.py:490} INFO - 23/05/28 03:27:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:45,241] {spark_submit.py:490} INFO - 23/05/28 03:27:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:45,331] {spark_submit.py:490} INFO - 23/05/28 03:27:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:45,338] {spark_submit.py:490} INFO - 23/05/28 03:27:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:45,345] {spark_submit.py:490} INFO - 23/05/28 03:27:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:46,087] {spark_submit.py:490} INFO - 23/05/28 03:27:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:46,248] {spark_submit.py:490} INFO - 23/05/28 03:27:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:46,762] {spark_submit.py:490} INFO - 23/05/28 03:27:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:47,092] {spark_submit.py:490} INFO - 23/05/28 03:27:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:47,167] {spark_submit.py:490} INFO - 23/05/28 03:27:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,409] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,418] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,420] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,489] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,539] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,599] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,658] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,662] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,927] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:48,930] {spark_submit.py:490} INFO - 23/05/28 03:27:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:49,238] {spark_submit.py:490} INFO - 23/05/28 03:27:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:49,369] {spark_submit.py:490} INFO - 23/05/28 03:27:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:49,857] {spark_submit.py:490} INFO - 23/05/28 03:27:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,013] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,073] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,082] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,089] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,350] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:50,872] {spark_submit.py:490} INFO - 23/05/28 03:27:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:51,695] {spark_submit.py:490} INFO - 23/05/28 03:27:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:51,748] {spark_submit.py:490} INFO - 23/05/28 03:27:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:52,269] {spark_submit.py:490} INFO - 23/05/28 03:27:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:52,382] {spark_submit.py:490} INFO - 23/05/28 03:27:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:52,989] {spark_submit.py:490} INFO - 23/05/28 03:27:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:52,999] {spark_submit.py:490} INFO - 23/05/28 03:27:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:53,248] {spark_submit.py:490} INFO - 23/05/28 03:27:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:53,419] {spark_submit.py:490} INFO - 23/05/28 03:27:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:53,430] {spark_submit.py:490} INFO - 23/05/28 03:27:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:53,651] {spark_submit.py:490} INFO - 23/05/28 03:27:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:54,134] {spark_submit.py:490} INFO - 23/05/28 03:27:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:54,868] {spark_submit.py:490} INFO - 23/05/28 03:27:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:54,873] {spark_submit.py:490} INFO - 23/05/28 03:27:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:54,878] {spark_submit.py:490} INFO - 23/05/28 03:27:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:55,003] {spark_submit.py:490} INFO - 23/05/28 03:27:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:55,092] {spark_submit.py:490} INFO - 23/05/28 03:27:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:55,767] {spark_submit.py:490} INFO - 23/05/28 03:27:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:55,827] {spark_submit.py:490} INFO - 23/05/28 03:27:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:55,930] {spark_submit.py:490} INFO - 23/05/28 03:27:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:56,015] {spark_submit.py:490} INFO - 23/05/28 03:27:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:56,027] {spark_submit.py:490} INFO - 23/05/28 03:27:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:56,030] {spark_submit.py:490} INFO - 23/05/28 03:27:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:56,050] {spark_submit.py:490} INFO - 23/05/28 03:27:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:57,385] {spark_submit.py:490} INFO - 23/05/28 03:27:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:57,389] {spark_submit.py:490} INFO - 23/05/28 03:27:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:57,402] {spark_submit.py:490} INFO - 23/05/28 03:27:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:58,740] {spark_submit.py:490} INFO - 23/05/28 03:27:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:58,755] {spark_submit.py:490} INFO - 23/05/28 03:27:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:59,363] {spark_submit.py:490} INFO - 23/05/28 03:27:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:59,366] {spark_submit.py:490} INFO - 23/05/28 03:27:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:27:59,835] {spark_submit.py:490} INFO - 23/05/28 03:27:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:00,085] {spark_submit.py:490} INFO - 23/05/28 03:28:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:00,090] {spark_submit.py:490} INFO - 23/05/28 03:28:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:00,310] {spark_submit.py:490} INFO - 23/05/28 03:28:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:00,357] {spark_submit.py:490} INFO - 23/05/28 03:28:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:00,670] {spark_submit.py:490} INFO - 23/05/28 03:28:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,024] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,144] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,150] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,497] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,662] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:01,873] {spark_submit.py:490} INFO - 23/05/28 03:28:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:02,129] {spark_submit.py:490} INFO - 23/05/28 03:28:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:02,142] {spark_submit.py:490} INFO - 23/05/28 03:28:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:02,150] {spark_submit.py:490} INFO - 23/05/28 03:28:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:02,367] {spark_submit.py:490} INFO - 23/05/28 03:28:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:03,080] {spark_submit.py:490} INFO - 23/05/28 03:28:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:03,155] {spark_submit.py:490} INFO - 23/05/28 03:28:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:03,332] {spark_submit.py:490} INFO - 23/05/28 03:28:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:03,347] {spark_submit.py:490} INFO - 23/05/28 03:28:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:04,469] {spark_submit.py:490} INFO - 23/05/28 03:28:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,173] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,182] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,208] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,212] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,228] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,292] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,294] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,545] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:05,879] {spark_submit.py:490} INFO - 23/05/28 03:28:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:06,188] {spark_submit.py:490} INFO - 23/05/28 03:28:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:06,216] {spark_submit.py:490} INFO - 23/05/28 03:28:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:06,848] {spark_submit.py:490} INFO - 23/05/28 03:28:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:06,851] {spark_submit.py:490} INFO - 23/05/28 03:28:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:07,708] {spark_submit.py:490} INFO - 23/05/28 03:28:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:07,760] {spark_submit.py:490} INFO - 23/05/28 03:28:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:07,872] {spark_submit.py:490} INFO - 23/05/28 03:28:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:07,884] {spark_submit.py:490} INFO - 23/05/28 03:28:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:07,886] {spark_submit.py:490} INFO - 23/05/28 03:28:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:08,070] {spark_submit.py:490} INFO - 23/05/28 03:28:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:08,077] {spark_submit.py:490} INFO - 23/05/28 03:28:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:09,286] {spark_submit.py:490} INFO - 23/05/28 03:28:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:09,584] {spark_submit.py:490} INFO - 23/05/28 03:28:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:09,586] {spark_submit.py:490} INFO - 23/05/28 03:28:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:10,475] {spark_submit.py:490} INFO - 23/05/28 03:28:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:10,611] {spark_submit.py:490} INFO - 23/05/28 03:28:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:10,615] {spark_submit.py:490} INFO - 23/05/28 03:28:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:10,620] {spark_submit.py:490} INFO - 23/05/28 03:28:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:10,641] {spark_submit.py:490} INFO - 23/05/28 03:28:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:11,008] {spark_submit.py:490} INFO - 23/05/28 03:28:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:11,010] {spark_submit.py:490} INFO - 23/05/28 03:28:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:11,481] {spark_submit.py:490} INFO - 23/05/28 03:28:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:11,581] {spark_submit.py:490} INFO - 23/05/28 03:28:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:12,813] {spark_submit.py:490} INFO - 23/05/28 03:28:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:12,828] {spark_submit.py:490} INFO - 23/05/28 03:28:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:12,946] {spark_submit.py:490} INFO - 23/05/28 03:28:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:13,041] {spark_submit.py:490} INFO - 23/05/28 03:28:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:13,138] {spark_submit.py:490} INFO - 23/05/28 03:28:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:13,323] {spark_submit.py:490} INFO - 23/05/28 03:28:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:14,432] {spark_submit.py:490} INFO - 23/05/28 03:28:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:14,438] {spark_submit.py:490} INFO - 23/05/28 03:28:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:14,898] {spark_submit.py:490} INFO - 23/05/28 03:28:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:14,985] {spark_submit.py:490} INFO - 23/05/28 03:28:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:15,474] {spark_submit.py:490} INFO - 23/05/28 03:28:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:15,481] {spark_submit.py:490} INFO - 23/05/28 03:28:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:15,486] {spark_submit.py:490} INFO - 23/05/28 03:28:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:15,898] {spark_submit.py:490} INFO - 23/05/28 03:28:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:16,476] {spark_submit.py:490} INFO - 23/05/28 03:28:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:16,481] {spark_submit.py:490} INFO - 23/05/28 03:28:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:17,315] {spark_submit.py:490} INFO - 23/05/28 03:28:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:17,316] {spark_submit.py:490} INFO - 23/05/28 03:28:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:18,641] {spark_submit.py:490} INFO - 23/05/28 03:28:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:18,644] {spark_submit.py:490} INFO - 23/05/28 03:28:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:18,649] {spark_submit.py:490} INFO - 23/05/28 03:28:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:18,657] {spark_submit.py:490} INFO - 23/05/28 03:28:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:19,713] {spark_submit.py:490} INFO - 23/05/28 03:28:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:19,732] {spark_submit.py:490} INFO - 23/05/28 03:28:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:20,080] {spark_submit.py:490} INFO - 23/05/28 03:28:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:20,398] {spark_submit.py:490} INFO - 23/05/28 03:28:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:20,400] {spark_submit.py:490} INFO - 23/05/28 03:28:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:21,339] {spark_submit.py:490} INFO - 23/05/28 03:28:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:21,426] {spark_submit.py:490} INFO - 23/05/28 03:28:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:21,442] {spark_submit.py:490} INFO - 23/05/28 03:28:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:21,799] {spark_submit.py:490} INFO - 23/05/28 03:28:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:21,867] {spark_submit.py:490} INFO - 23/05/28 03:28:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:22,100] {spark_submit.py:490} INFO - 23/05/28 03:28:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:22,103] {spark_submit.py:490} INFO - 23/05/28 03:28:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:22,217] {spark_submit.py:490} INFO - 23/05/28 03:28:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:23,303] {spark_submit.py:490} INFO - 23/05/28 03:28:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:23,354] {spark_submit.py:490} INFO - 23/05/28 03:28:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:23,397] {spark_submit.py:490} INFO - 23/05/28 03:28:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:23,415] {spark_submit.py:490} INFO - 23/05/28 03:28:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,037] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,475] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,490] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,496] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,711] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,716] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,810] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:24,824] {spark_submit.py:490} INFO - 23/05/28 03:28:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,063] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,066] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,616] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,683] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,687] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:26,937] {spark_submit.py:490} INFO - 23/05/28 03:28:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:27,599] {spark_submit.py:490} INFO - 23/05/28 03:28:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:27,939] {spark_submit.py:490} INFO - 23/05/28 03:28:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:27,944] {spark_submit.py:490} INFO - 23/05/28 03:28:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,024] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,027] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,112] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,177] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,179] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:28,883] {spark_submit.py:490} INFO - 23/05/28 03:28:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:29,374] {spark_submit.py:490} INFO - 23/05/28 03:28:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:29,380] {spark_submit.py:490} INFO - 23/05/28 03:28:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:31,382] {spark_submit.py:490} INFO - 23/05/28 03:28:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:31,944] {spark_submit.py:490} INFO - 23/05/28 03:28:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,064] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,073] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,193] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,463] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,475] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,476] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:32,490] {spark_submit.py:490} INFO - 23/05/28 03:28:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:33,529] {spark_submit.py:490} INFO - 23/05/28 03:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:33,582] {spark_submit.py:490} INFO - 23/05/28 03:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:33,592] {spark_submit.py:490} INFO - 23/05/28 03:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:33,642] {spark_submit.py:490} INFO - 23/05/28 03:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:33,650] {spark_submit.py:490} INFO - 23/05/28 03:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:35,750] {spark_submit.py:490} INFO - 23/05/28 03:28:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:36,271] {spark_submit.py:490} INFO - 23/05/28 03:28:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,006] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,204] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,229] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,305] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,311] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:37,934] {spark_submit.py:490} INFO - 23/05/28 03:28:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:38,214] {spark_submit.py:490} INFO - 23/05/28 03:28:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:38,586] {spark_submit.py:490} INFO - 23/05/28 03:28:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:38,593] {spark_submit.py:490} INFO - 23/05/28 03:28:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,252] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,492] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,525] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,613] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,617] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,755] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:39,842] {spark_submit.py:490} INFO - 23/05/28 03:28:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:40,762] {spark_submit.py:490} INFO - 23/05/28 03:28:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:41,928] {spark_submit.py:490} INFO - 23/05/28 03:28:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,349] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,354] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,361] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,500] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,554] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:43,559] {spark_submit.py:490} INFO - 23/05/28 03:28:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:44,459] {spark_submit.py:490} INFO - 23/05/28 03:28:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:44,471] {spark_submit.py:490} INFO - 23/05/28 03:28:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:44,475] {spark_submit.py:490} INFO - 23/05/28 03:28:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:44,776] {spark_submit.py:490} INFO - 23/05/28 03:28:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:44,787] {spark_submit.py:490} INFO - 23/05/28 03:28:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:45,265] {spark_submit.py:490} INFO - 23/05/28 03:28:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:45,404] {spark_submit.py:490} INFO - 23/05/28 03:28:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:45,679] {spark_submit.py:490} INFO - 23/05/28 03:28:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:45,683] {spark_submit.py:490} INFO - 23/05/28 03:28:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:46,288] {spark_submit.py:490} INFO - 23/05/28 03:28:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:46,331] {spark_submit.py:490} INFO - 23/05/28 03:28:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:46,971] {spark_submit.py:490} INFO - 23/05/28 03:28:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:46,973] {spark_submit.py:490} INFO - 23/05/28 03:28:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,194] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,642] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,645] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,646] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,651] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:47,839] {spark_submit.py:490} INFO - 23/05/28 03:28:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:48,054] {spark_submit.py:490} INFO - 23/05/28 03:28:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:49,256] {spark_submit.py:490} INFO - 23/05/28 03:28:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:49,631] {spark_submit.py:490} INFO - 23/05/28 03:28:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:49,653] {spark_submit.py:490} INFO - 23/05/28 03:28:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:50,027] {spark_submit.py:490} INFO - 23/05/28 03:28:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:50,033] {spark_submit.py:490} INFO - 23/05/28 03:28:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:50,095] {spark_submit.py:490} INFO - 23/05/28 03:28:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:50,102] {spark_submit.py:490} INFO - 23/05/28 03:28:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,281] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,456] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,482] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,572] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,630] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:51,735] {spark_submit.py:490} INFO - 23/05/28 03:28:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:52,146] {spark_submit.py:490} INFO - 23/05/28 03:28:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:52,297] {spark_submit.py:490} INFO - 23/05/28 03:28:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:52,308] {spark_submit.py:490} INFO - 23/05/28 03:28:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:52,485] {spark_submit.py:490} INFO - 23/05/28 03:28:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:52,541] {spark_submit.py:490} INFO - 23/05/28 03:28:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:53,086] {spark_submit.py:490} INFO - 23/05/28 03:28:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:53,172] {spark_submit.py:490} INFO - 23/05/28 03:28:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:53,174] {spark_submit.py:490} INFO - 23/05/28 03:28:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:54,041] {spark_submit.py:490} INFO - 23/05/28 03:28:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:54,056] {spark_submit.py:490} INFO - 23/05/28 03:28:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:54,060] {spark_submit.py:490} INFO - 23/05/28 03:28:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:54,247] {spark_submit.py:490} INFO - 23/05/28 03:28:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:55,216] {spark_submit.py:490} INFO - 23/05/28 03:28:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:55,369] {spark_submit.py:490} INFO - 23/05/28 03:28:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:55,896] {spark_submit.py:490} INFO - 23/05/28 03:28:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:55,911] {spark_submit.py:490} INFO - 23/05/28 03:28:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:56,829] {spark_submit.py:490} INFO - 23/05/28 03:28:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:56,846] {spark_submit.py:490} INFO - 23/05/28 03:28:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:56,848] {spark_submit.py:490} INFO - 23/05/28 03:28:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:57,370] {spark_submit.py:490} INFO - 23/05/28 03:28:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:57,700] {spark_submit.py:490} INFO - 23/05/28 03:28:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:57,710] {spark_submit.py:490} INFO - 23/05/28 03:28:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:58,271] {spark_submit.py:490} INFO - 23/05/28 03:28:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:58,816] {spark_submit.py:490} INFO - 23/05/28 03:28:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:59,919] {spark_submit.py:490} INFO - 23/05/28 03:28:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:59,923] {spark_submit.py:490} INFO - 23/05/28 03:28:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:28:59,928] {spark_submit.py:490} INFO - 23/05/28 03:28:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:00,792] {spark_submit.py:490} INFO - 23/05/28 03:29:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:00,843] {spark_submit.py:490} INFO - 23/05/28 03:29:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:00,852] {spark_submit.py:490} INFO - 23/05/28 03:29:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:01,331] {spark_submit.py:490} INFO - 23/05/28 03:29:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:01,333] {spark_submit.py:490} INFO - 23/05/28 03:29:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:01,519] {spark_submit.py:490} INFO - 23/05/28 03:29:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:01,529] {spark_submit.py:490} INFO - 23/05/28 03:29:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,230] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,497] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,590] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,779] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,785] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:02,792] {spark_submit.py:490} INFO - 23/05/28 03:29:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:03,225] {spark_submit.py:490} INFO - 23/05/28 03:29:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:03,328] {spark_submit.py:490} INFO - 23/05/28 03:29:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:03,337] {spark_submit.py:490} INFO - 23/05/28 03:29:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:03,521] {spark_submit.py:490} INFO - 23/05/28 03:29:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:03,632] {spark_submit.py:490} INFO - 23/05/28 03:29:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:04,087] {spark_submit.py:490} INFO - 23/05/28 03:29:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:04,698] {spark_submit.py:490} INFO - 23/05/28 03:29:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:04,703] {spark_submit.py:490} INFO - 23/05/28 03:29:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:05,660] {spark_submit.py:490} INFO - 23/05/28 03:29:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:05,678] {spark_submit.py:490} INFO - 23/05/28 03:29:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:06,429] {spark_submit.py:490} INFO - 23/05/28 03:29:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:06,571] {spark_submit.py:490} INFO - 23/05/28 03:29:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:06,790] {spark_submit.py:490} INFO - 23/05/28 03:29:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:06,815] {spark_submit.py:490} INFO - 23/05/28 03:29:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,054] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,058] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,094] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,097] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,136] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,963] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,970] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:07,976] {spark_submit.py:490} INFO - 23/05/28 03:29:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:08,013] {spark_submit.py:490} INFO - 23/05/28 03:29:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:10,082] {spark_submit.py:490} INFO - 23/05/28 03:29:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:10,093] {spark_submit.py:490} INFO - 23/05/28 03:29:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:11,375] {spark_submit.py:490} INFO - 23/05/28 03:29:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:11,376] {spark_submit.py:490} INFO - 23/05/28 03:29:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:12,062] {spark_submit.py:490} INFO - 23/05/28 03:29:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:12,259] {spark_submit.py:490} INFO - 23/05/28 03:29:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:13,488] {spark_submit.py:490} INFO - 23/05/28 03:29:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:13,504] {spark_submit.py:490} INFO - 23/05/28 03:29:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:13,677] {spark_submit.py:490} INFO - 23/05/28 03:29:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:13,682] {spark_submit.py:490} INFO - 23/05/28 03:29:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:14,233] {spark_submit.py:490} INFO - 23/05/28 03:29:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:14,345] {spark_submit.py:490} INFO - 23/05/28 03:29:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:14,702] {spark_submit.py:490} INFO - 23/05/28 03:29:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:15,171] {spark_submit.py:490} INFO - 23/05/28 03:29:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:15,186] {spark_submit.py:490} INFO - 23/05/28 03:29:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:15,245] {spark_submit.py:490} INFO - 23/05/28 03:29:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:16,119] {spark_submit.py:490} INFO - 23/05/28 03:29:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:16,299] {spark_submit.py:490} INFO - 23/05/28 03:29:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:16,762] {spark_submit.py:490} INFO - 23/05/28 03:29:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:16,767] {spark_submit.py:490} INFO - 23/05/28 03:29:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:17,186] {spark_submit.py:490} INFO - 23/05/28 03:29:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:17,197] {spark_submit.py:490} INFO - 23/05/28 03:29:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:17,560] {spark_submit.py:490} INFO - 23/05/28 03:29:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:17,698] {spark_submit.py:490} INFO - 23/05/28 03:29:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,428] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,591] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,696] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,697] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,744] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,746] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,858] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:18,862] {spark_submit.py:490} INFO - 23/05/28 03:29:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:19,405] {spark_submit.py:490} INFO - 23/05/28 03:29:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,076] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000004_215' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000004
[2023-05-28 03:29:20,077] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000004_215: Committed. Elapsed time: 8 ms.
[2023-05-28 03:29:20,120] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO Executor: Finished task 4.0 in stage 4.0 (TID 215). 6113 bytes result sent to driver
[2023-05-28 03:29:20,121] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 219) (c1224b457a2d, executor driver, partition 8, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:29:20,122] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO Executor: Running task 8.0 in stage 4.0 (TID 219)
[2023-05-28 03:29:20,150] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 215) in 200837 ms on c1224b457a2d (executor driver) (5/28)
[2023-05-28 03:29:20,160] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ShuffleBlockFetcherIterator: Getting 11 (60.7 MiB) non-empty blocks including 11 (60.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:29:20,161] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-28 03:29:20,232] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,346] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO UnsafeExternalSorter: Thread 121 spilling sort data of 100.0 MiB to disk (0  time so far)
[2023-05-28 03:29:20,347] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,676] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,744] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,757] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO UnsafeExternalSorter: Thread 121 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:29:20,764] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:20,800] {spark_submit.py:490} INFO - 23/05/28 03:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,062] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,070] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:29:21,071] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:29:21,071] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:29:21,072] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:29:21,073] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:29:21,073] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:29:21,073] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,084] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,086] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:29:21,086] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:29:21,087] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:29:21,088] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:29:21,089] {spark_submit.py:490} INFO - {
[2023-05-28 03:29:21,089] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:29:21,089] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:29:21,090] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:29:21,090] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,091] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,091] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,091] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,092] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:29:21,094] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,094] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,094] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,095] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,095] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:29:21,095] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,096] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,096] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,097] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,097] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:29:21,097] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,097] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,098] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,098] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,098] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:29:21,099] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,099] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,099] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,099] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,100] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:29:21,100] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,100] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,101] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,101] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,101] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:29:21,101] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,102] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,102] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,102] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,103] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:29:21,103] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,103] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,104] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,104] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,104] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:29:21,105] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:21,105] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,105] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,105] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,106] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:29:21,106] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:29:21,107] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,107] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,108] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:21,108] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:29:21,108] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:29:21,109] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:21,109] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:21,110] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:29:21,110] {spark_submit.py:490} INFO - }
[2023-05-28 03:29:21,111] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:29:21,111] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:29:21,111] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:29:21,112] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:29:21,112] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:29:21,113] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:29:21,113] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:29:21,114] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:29:21,114] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:29:21,115] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:29:21,115] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:29:21,115] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:29:21,116] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:29:21,116] {spark_submit.py:490} INFO - }
[2023-05-28 03:29:21,117] {spark_submit.py:490} INFO - 
[2023-05-28 03:29:21,117] {spark_submit.py:490} INFO - 
[2023-05-28 03:29:21,704] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,782] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,787] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,955] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:21,960] {spark_submit.py:490} INFO - 23/05/28 03:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:22,213] {spark_submit.py:490} INFO - 23/05/28 03:29:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:22,443] {spark_submit.py:490} INFO - 23/05/28 03:29:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:22,801] {spark_submit.py:490} INFO - 23/05/28 03:29:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:22,806] {spark_submit.py:490} INFO - 23/05/28 03:29:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:23,272] {spark_submit.py:490} INFO - 23/05/28 03:29:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:24,897] {spark_submit.py:490} INFO - 23/05/28 03:29:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,082] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,088] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,118] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,125] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,172] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,570] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,587] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:25,974] {spark_submit.py:490} INFO - 23/05/28 03:29:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:26,522] {spark_submit.py:490} INFO - 23/05/28 03:29:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:26,536] {spark_submit.py:490} INFO - 23/05/28 03:29:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:26,551] {spark_submit.py:490} INFO - 23/05/28 03:29:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:27,797] {spark_submit.py:490} INFO - 23/05/28 03:29:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:27,892] {spark_submit.py:490} INFO - 23/05/28 03:29:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:28,789] {spark_submit.py:490} INFO - 23/05/28 03:29:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:28,806] {spark_submit.py:490} INFO - 23/05/28 03:29:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:28,818] {spark_submit.py:490} INFO - 23/05/28 03:29:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:29,257] {spark_submit.py:490} INFO - 23/05/28 03:29:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:29,267] {spark_submit.py:490} INFO - 23/05/28 03:29:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:29,613] {spark_submit.py:490} INFO - 23/05/28 03:29:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:29,626] {spark_submit.py:490} INFO - 23/05/28 03:29:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:30,278] {spark_submit.py:490} INFO - 23/05/28 03:29:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:30,284] {spark_submit.py:490} INFO - 23/05/28 03:29:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:30,904] {spark_submit.py:490} INFO - 23/05/28 03:29:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:30,909] {spark_submit.py:490} INFO - 23/05/28 03:29:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:31,755] {spark_submit.py:490} INFO - 23/05/28 03:29:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:32,208] {spark_submit.py:490} INFO - 23/05/28 03:29:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:32,251] {spark_submit.py:490} INFO - 23/05/28 03:29:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:32,750] {spark_submit.py:490} INFO - 23/05/28 03:29:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:32,753] {spark_submit.py:490} INFO - 23/05/28 03:29:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,408] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,435] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,468] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,513] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,515] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,556] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,567] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:33,864] {spark_submit.py:490} INFO - 23/05/28 03:29:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:34,404] {spark_submit.py:490} INFO - 23/05/28 03:29:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:34,441] {spark_submit.py:490} INFO - 23/05/28 03:29:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:34,444] {spark_submit.py:490} INFO - 23/05/28 03:29:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,054] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,090] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,096] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,270] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,275] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,702] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,704] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:35,706] {spark_submit.py:490} INFO - 23/05/28 03:29:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:36,536] {spark_submit.py:490} INFO - 23/05/28 03:29:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:37,129] {spark_submit.py:490} INFO - 23/05/28 03:29:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:37,165] {spark_submit.py:490} INFO - 23/05/28 03:29:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:37,167] {spark_submit.py:490} INFO - 23/05/28 03:29:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:37,545] {spark_submit.py:490} INFO - 23/05/28 03:29:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,130] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,151] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,154] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,201] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,222] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,224] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,480] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:38,830] {spark_submit.py:490} INFO - 23/05/28 03:29:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:39,264] {spark_submit.py:490} INFO - 23/05/28 03:29:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:39,279] {spark_submit.py:490} INFO - 23/05/28 03:29:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:39,410] {spark_submit.py:490} INFO - 23/05/28 03:29:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:39,421] {spark_submit.py:490} INFO - 23/05/28 03:29:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:40,341] {spark_submit.py:490} INFO - 23/05/28 03:29:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:40,528] {spark_submit.py:490} INFO - 23/05/28 03:29:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:40,537] {spark_submit.py:490} INFO - 23/05/28 03:29:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:40,934] {spark_submit.py:490} INFO - 23/05/28 03:29:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:40,936] {spark_submit.py:490} INFO - 23/05/28 03:29:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:41,313] {spark_submit.py:490} INFO - 23/05/28 03:29:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:41,322] {spark_submit.py:490} INFO - 23/05/28 03:29:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:42,169] {spark_submit.py:490} INFO - 23/05/28 03:29:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:42,174] {spark_submit.py:490} INFO - 23/05/28 03:29:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:42,461] {spark_submit.py:490} INFO - 23/05/28 03:29:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:42,835] {spark_submit.py:490} INFO - 23/05/28 03:29:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:43,222] {spark_submit.py:490} INFO - 23/05/28 03:29:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:43,380] {spark_submit.py:490} INFO - 23/05/28 03:29:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,037] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,070] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,171] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,272] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,676] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,687] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,696] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,888] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:44,905] {spark_submit.py:490} INFO - 23/05/28 03:29:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:46,929] {spark_submit.py:490} INFO - 23/05/28 03:29:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,017] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,019] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,230] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,232] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,575] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:47,810] {spark_submit.py:490} INFO - 23/05/28 03:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:48,045] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:48,048] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:48,995] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000005_216' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000005
[2023-05-28 03:29:48,996] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000005_216: Committed. Elapsed time: 3 ms.
[2023-05-28 03:29:48,998] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO Executor: Finished task 5.0 in stage 4.0 (TID 216). 6070 bytes result sent to driver
[2023-05-28 03:29:49,000] {spark_submit.py:490} INFO - 23/05/28 03:29:48 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 220) (c1224b457a2d, executor driver, partition 9, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:29:49,001] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 216) in 223911 ms on c1224b457a2d (executor driver) (6/28)
[2023-05-28 03:29:49,003] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO Executor: Running task 9.0 in stage 4.0 (TID 220)
[2023-05-28 03:29:49,009] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ShuffleBlockFetcherIterator: Getting 11 (56.7 MiB) non-empty blocks including 11 (56.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:29:49,017] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2023-05-28 03:29:49,272] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 144.0 MiB to disk (0  time so far)
[2023-05-28 03:29:49,553] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,614] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,617] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,711] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO UnsafeExternalSorter: Thread 72 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:29:49,722] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,936] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,943] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:29:49,943] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:29:49,944] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:29:49,946] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:29:49,947] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:29:49,947] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:29:49,955] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:49,958] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:29:49,959] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:29:49,960] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:29:49,967] {spark_submit.py:490} INFO - 23/05/28 03:29:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:29:49,967] {spark_submit.py:490} INFO - {
[2023-05-28 03:29:49,968] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:29:49,968] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:29:49,969] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:29:49,969] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,970] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,970] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,971] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,971] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:29:49,971] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,972] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,972] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,972] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,973] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:29:49,973] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,973] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,974] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,974] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,974] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:29:49,974] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,975] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,975] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,975] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,976] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:29:49,976] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,976] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,977] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,977] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,978] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:29:49,978] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,978] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,979] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,979] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,980] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:29:49,980] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,980] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,981] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,981] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,981] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:29:49,982] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,982] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,982] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,983] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,983] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:29:49,983] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:29:49,984] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,984] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,985] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,985] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:29:49,986] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:29:49,986] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,986] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,987] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:29:49,987] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:29:49,987] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:29:49,988] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:29:49,988] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:29:49,988] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:29:49,989] {spark_submit.py:490} INFO - }
[2023-05-28 03:29:49,989] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:29:49,989] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:29:49,990] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:29:49,991] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:29:49,991] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:29:49,991] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:29:49,992] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:29:49,992] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:29:49,992] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:29:49,993] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:29:49,993] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:29:49,993] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:29:49,993] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:29:49,994] {spark_submit.py:490} INFO - }
[2023-05-28 03:29:49,994] {spark_submit.py:490} INFO - 
[2023-05-28 03:29:49,994] {spark_submit.py:490} INFO - 
[2023-05-28 03:29:50,854] {spark_submit.py:490} INFO - 23/05/28 03:29:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:50,872] {spark_submit.py:490} INFO - 23/05/28 03:29:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:52,206] {spark_submit.py:490} INFO - 23/05/28 03:29:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:52,563] {spark_submit.py:490} INFO - 23/05/28 03:29:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:52,569] {spark_submit.py:490} INFO - 23/05/28 03:29:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:52,610] {spark_submit.py:490} INFO - 23/05/28 03:29:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:52,613] {spark_submit.py:490} INFO - 23/05/28 03:29:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,064] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,281] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,286] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,336] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,347] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,699] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,703] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,926] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:53,937] {spark_submit.py:490} INFO - 23/05/28 03:29:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:54,825] {spark_submit.py:490} INFO - 23/05/28 03:29:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:54,846] {spark_submit.py:490} INFO - 23/05/28 03:29:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:54,973] {spark_submit.py:490} INFO - 23/05/28 03:29:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:55,194] {spark_submit.py:490} INFO - 23/05/28 03:29:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:56,245] {spark_submit.py:490} INFO - 23/05/28 03:29:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:56,446] {spark_submit.py:490} INFO - 23/05/28 03:29:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:56,447] {spark_submit.py:490} INFO - 23/05/28 03:29:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:56,501] {spark_submit.py:490} INFO - 23/05/28 03:29:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:56,505] {spark_submit.py:490} INFO - 23/05/28 03:29:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:57,341] {spark_submit.py:490} INFO - 23/05/28 03:29:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:57,347] {spark_submit.py:490} INFO - 23/05/28 03:29:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:57,679] {spark_submit.py:490} INFO - 23/05/28 03:29:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:57,724] {spark_submit.py:490} INFO - 23/05/28 03:29:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:57,727] {spark_submit.py:490} INFO - 23/05/28 03:29:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:58,214] {spark_submit.py:490} INFO - 23/05/28 03:29:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:58,330] {spark_submit.py:490} INFO - 23/05/28 03:29:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:58,403] {spark_submit.py:490} INFO - 23/05/28 03:29:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:59,324] {spark_submit.py:490} INFO - 23/05/28 03:29:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:29:59,328] {spark_submit.py:490} INFO - 23/05/28 03:29:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,480] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,482] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,493] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,617] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,631] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,635] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:00,846] {spark_submit.py:490} INFO - 23/05/28 03:30:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:01,510] {spark_submit.py:490} INFO - 23/05/28 03:30:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:01,521] {spark_submit.py:490} INFO - 23/05/28 03:30:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:01,818] {spark_submit.py:490} INFO - 23/05/28 03:30:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:01,924] {spark_submit.py:490} INFO - 23/05/28 03:30:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:01,930] {spark_submit.py:490} INFO - 23/05/28 03:30:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,235] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,297] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,658] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,662] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,763] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,869] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:02,969] {spark_submit.py:490} INFO - 23/05/28 03:30:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:03,263] {spark_submit.py:490} INFO - 23/05/28 03:30:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:03,267] {spark_submit.py:490} INFO - 23/05/28 03:30:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,375] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,383] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,566] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,571] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,580] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,633] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:04,643] {spark_submit.py:490} INFO - 23/05/28 03:30:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:05,125] {spark_submit.py:490} INFO - 23/05/28 03:30:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:05,473] {spark_submit.py:490} INFO - 23/05/28 03:30:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:05,941] {spark_submit.py:490} INFO - 23/05/28 03:30:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:05,958] {spark_submit.py:490} INFO - 23/05/28 03:30:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:06,182] {spark_submit.py:490} INFO - 23/05/28 03:30:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:06,479] {spark_submit.py:490} INFO - 23/05/28 03:30:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:06,633] {spark_submit.py:490} INFO - 23/05/28 03:30:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,032] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,035] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,190] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,401] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,659] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,674] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,862] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:07,871] {spark_submit.py:490} INFO - 23/05/28 03:30:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:08,782] {spark_submit.py:490} INFO - 23/05/28 03:30:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:08,962] {spark_submit.py:490} INFO - 23/05/28 03:30:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,274] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,459] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,615] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,803] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,809] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:09,812] {spark_submit.py:490} INFO - 23/05/28 03:30:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:10,702] {spark_submit.py:490} INFO - 23/05/28 03:30:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:11,108] {spark_submit.py:490} INFO - 23/05/28 03:30:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:11,431] {spark_submit.py:490} INFO - 23/05/28 03:30:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:11,433] {spark_submit.py:490} INFO - 23/05/28 03:30:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:12,293] {spark_submit.py:490} INFO - 23/05/28 03:30:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:12,300] {spark_submit.py:490} INFO - 23/05/28 03:30:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,076] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,077] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,233] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,239] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,247] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,928] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:14,993] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000007_218' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000007
[2023-05-28 03:30:14,994] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000007_218: Committed. Elapsed time: 3 ms.
[2023-05-28 03:30:14,996] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO Executor: Finished task 7.0 in stage 4.0 (TID 218). 6113 bytes result sent to driver
[2023-05-28 03:30:14,997] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 221) (c1224b457a2d, executor driver, partition 10, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:30:14,998] {spark_submit.py:490} INFO - 23/05/28 03:30:14 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 218) in 212840 ms on c1224b457a2d (executor driver) (7/28)
[2023-05-28 03:30:15,005] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO Executor: Running task 10.0 in stage 4.0 (TID 221)
[2023-05-28 03:30:15,015] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ShuffleBlockFetcherIterator: Getting 11 (57.1 MiB) non-empty blocks including 11 (57.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:30:15,016] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-28 03:30:15,223] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO UnsafeExternalSorter: Thread 155 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:30:15,526] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:15,619] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO UnsafeExternalSorter: Thread 155 spilling sort data of 100.0 MiB to disk (1  time so far)
[2023-05-28 03:30:15,655] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:15,960] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:30:15,961] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:30:15,961] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:30:15,962] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:30:15,962] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:30:15,963] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:30:15,964] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:30:15,965] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:30:15,965] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:30:15,966] {spark_submit.py:490} INFO - 23/05/28 03:30:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:30:15,967] {spark_submit.py:490} INFO - {
[2023-05-28 03:30:15,967] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:30:15,968] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:30:15,968] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:30:15,969] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,969] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,970] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,970] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,972] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:30:15,973] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,973] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,974] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,974] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,974] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:30:15,975] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,978] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,978] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,978] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,979] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:30:15,979] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,980] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,980] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,980] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,981] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:30:15,981] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,981] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,982] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,982] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,983] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:30:15,983] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,984] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,984] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,985] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,985] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:30:15,985] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,986] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,986] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,987] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,987] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:30:15,987] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,988] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,988] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,989] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,989] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:30:15,990] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:15,990] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,991] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,991] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,991] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:30:15,992] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:30:15,992] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,993] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,993] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:15,993] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:30:15,994] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:30:15,994] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:15,995] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:15,995] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:30:15,995] {spark_submit.py:490} INFO - }
[2023-05-28 03:30:15,996] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:30:15,996] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:30:15,997] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:30:15,997] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:30:15,997] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:30:15,998] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:30:15,998] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:30:15,999] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:30:15,999] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:30:15,999] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:30:16,000] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:30:16,001] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:30:16,001] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:30:16,001] {spark_submit.py:490} INFO - }
[2023-05-28 03:30:16,002] {spark_submit.py:490} INFO - 
[2023-05-28 03:30:16,002] {spark_submit.py:490} INFO - 
[2023-05-28 03:30:16,469] {spark_submit.py:490} INFO - 23/05/28 03:30:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:16,520] {spark_submit.py:490} INFO - 23/05/28 03:30:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:16,524] {spark_submit.py:490} INFO - 23/05/28 03:30:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:16,529] {spark_submit.py:490} INFO - 23/05/28 03:30:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:16,723] {spark_submit.py:490} INFO - 23/05/28 03:30:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,166] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,168] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,333] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,336] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,371] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:18,860] {spark_submit.py:490} INFO - 23/05/28 03:30:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:19,756] {spark_submit.py:490} INFO - 23/05/28 03:30:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:20,114] {spark_submit.py:490} INFO - 23/05/28 03:30:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:20,118] {spark_submit.py:490} INFO - 23/05/28 03:30:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:20,302] {spark_submit.py:490} INFO - 23/05/28 03:30:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:20,316] {spark_submit.py:490} INFO - 23/05/28 03:30:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:21,479] {spark_submit.py:490} INFO - 23/05/28 03:30:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:21,528] {spark_submit.py:490} INFO - 23/05/28 03:30:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:21,531] {spark_submit.py:490} INFO - 23/05/28 03:30:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:22,230] {spark_submit.py:490} INFO - 23/05/28 03:30:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:22,233] {spark_submit.py:490} INFO - 23/05/28 03:30:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:22,727] {spark_submit.py:490} INFO - 23/05/28 03:30:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:22,729] {spark_submit.py:490} INFO - 23/05/28 03:30:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:23,284] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO FileOutputCommitter: Saved output of task 'attempt_202305280323043085947774046998375_0004_m_000006_217' to file:/usr/local/spark/staging/20230528/feature_engineering/stocks.parquet/_temporary/0/task_202305280323043085947774046998375_0004_m_000006
[2023-05-28 03:30:23,285] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO SparkHadoopMapRedUtil: attempt_202305280323043085947774046998375_0004_m_000006_217: Committed. Elapsed time: 2 ms.
[2023-05-28 03:30:23,288] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO Executor: Finished task 6.0 in stage 4.0 (TID 217). 6070 bytes result sent to driver
[2023-05-28 03:30:23,289] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 222) (c1224b457a2d, executor driver, partition 11, NODE_LOCAL, 7363 bytes)
[2023-05-28 03:30:23,291] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 217) in 222163 ms on c1224b457a2d (executor driver) (8/28)
[2023-05-28 03:30:23,292] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO Executor: Running task 11.0 in stage 4.0 (TID 222)
[2023-05-28 03:30:23,299] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO ShuffleBlockFetcherIterator: Getting 11 (55.7 MiB) non-empty blocks including 11 (55.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-28 03:30:23,300] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-28 03:30:23,401] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:23,439] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 96.0 MiB to disk (0  time so far)
[2023-05-28 03:30:23,840] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:23,948] {spark_submit.py:490} INFO - 23/05/28 03:30:23 INFO UnsafeExternalSorter: Thread 65 spilling sort data of 104.0 MiB to disk (1  time so far)
[2023-05-28 03:30:24,265] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:24,266] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:30:24,267] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:30:24,267] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:30:24,267] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-28 03:30:24,268] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-28 03:30:24,268] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-28 03:30:24,268] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:24,269] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:24,269] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:30:24,270] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO CodecConfig: Compression: LZ4
[2023-05-28 03:30:24,270] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-28 03:30:24,271] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-28 03:30:24,272] {spark_submit.py:490} INFO - {
[2023-05-28 03:30:24,272] {spark_submit.py:490} INFO - "type" : "struct",
[2023-05-28 03:30:24,273] {spark_submit.py:490} INFO - "fields" : [ {
[2023-05-28 03:30:24,275] {spark_submit.py:490} INFO - "name" : "Symbol",
[2023-05-28 03:30:24,277] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,278] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,280] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,283] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,289] {spark_submit.py:490} INFO - "name" : "Security Name",
[2023-05-28 03:30:24,290] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,290] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,291] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,291] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,292] {spark_submit.py:490} INFO - "name" : "Date",
[2023-05-28 03:30:24,292] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,293] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,293] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,294] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,294] {spark_submit.py:490} INFO - "name" : "Open",
[2023-05-28 03:30:24,294] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,295] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,295] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,296] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,296] {spark_submit.py:490} INFO - "name" : "High",
[2023-05-28 03:30:24,296] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,297] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,298] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,298] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,298] {spark_submit.py:490} INFO - "name" : "Low",
[2023-05-28 03:30:24,299] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,299] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,300] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,300] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,300] {spark_submit.py:490} INFO - "name" : "Close",
[2023-05-28 03:30:24,301] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,301] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,301] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,301] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,302] {spark_submit.py:490} INFO - "name" : "Adj Close",
[2023-05-28 03:30:24,302] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,302] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,303] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,303] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,303] {spark_submit.py:490} INFO - "name" : "Volume",
[2023-05-28 03:30:24,304] {spark_submit.py:490} INFO - "type" : "string",
[2023-05-28 03:30:24,304] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,305] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,305] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,305] {spark_submit.py:490} INFO - "name" : "vol_moving_avg",
[2023-05-28 03:30:24,306] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:30:24,306] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,306] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,307] {spark_submit.py:490} INFO - }, {
[2023-05-28 03:30:24,307] {spark_submit.py:490} INFO - "name" : "adj_close_rolling_med",
[2023-05-28 03:30:24,307] {spark_submit.py:490} INFO - "type" : "double",
[2023-05-28 03:30:24,308] {spark_submit.py:490} INFO - "nullable" : true,
[2023-05-28 03:30:24,308] {spark_submit.py:490} INFO - "metadata" : { }
[2023-05-28 03:30:24,308] {spark_submit.py:490} INFO - } ]
[2023-05-28 03:30:24,309] {spark_submit.py:490} INFO - }
[2023-05-28 03:30:24,309] {spark_submit.py:490} INFO - and corresponding Parquet message type:
[2023-05-28 03:30:24,310] {spark_submit.py:490} INFO - message spark_schema {
[2023-05-28 03:30:24,310] {spark_submit.py:490} INFO - optional binary Symbol (STRING);
[2023-05-28 03:30:24,311] {spark_submit.py:490} INFO - optional binary Security Name (STRING);
[2023-05-28 03:30:24,311] {spark_submit.py:490} INFO - optional binary Date (STRING);
[2023-05-28 03:30:24,312] {spark_submit.py:490} INFO - optional binary Open (STRING);
[2023-05-28 03:30:24,312] {spark_submit.py:490} INFO - optional binary High (STRING);
[2023-05-28 03:30:24,313] {spark_submit.py:490} INFO - optional binary Low (STRING);
[2023-05-28 03:30:24,313] {spark_submit.py:490} INFO - optional binary Close (STRING);
[2023-05-28 03:30:24,314] {spark_submit.py:490} INFO - optional binary Adj Close (STRING);
[2023-05-28 03:30:24,314] {spark_submit.py:490} INFO - optional binary Volume (STRING);
[2023-05-28 03:30:24,315] {spark_submit.py:490} INFO - optional double vol_moving_avg;
[2023-05-28 03:30:24,315] {spark_submit.py:490} INFO - optional double adj_close_rolling_med;
[2023-05-28 03:30:24,316] {spark_submit.py:490} INFO - }
[2023-05-28 03:30:24,316] {spark_submit.py:490} INFO - 
[2023-05-28 03:30:24,317] {spark_submit.py:490} INFO - 
[2023-05-28 03:30:24,801] {spark_submit.py:490} INFO - 23/05/28 03:30:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,026] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,082] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,326] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,541] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,757] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,761] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:25,989] {spark_submit.py:490} INFO - 23/05/28 03:30:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:26,614] {spark_submit.py:490} INFO - 23/05/28 03:30:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:26,742] {spark_submit.py:490} INFO - 23/05/28 03:30:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:26,754] {spark_submit.py:490} INFO - 23/05/28 03:30:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:26,761] {spark_submit.py:490} INFO - 23/05/28 03:30:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:26,898] {spark_submit.py:490} INFO - 23/05/28 03:30:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:27,083] {spark_submit.py:490} INFO - 23/05/28 03:30:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:27,109] {spark_submit.py:490} INFO - 23/05/28 03:30:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:27,777] {spark_submit.py:490} INFO - 23/05/28 03:30:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:28,741] {spark_submit.py:490} INFO - 23/05/28 03:30:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:28,947] {spark_submit.py:490} INFO - 23/05/28 03:30:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,110] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,291] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,504] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,521] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,542] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,719] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,721] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:30,787] {spark_submit.py:490} INFO - 23/05/28 03:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:31,397] {spark_submit.py:490} INFO - 23/05/28 03:30:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:31,631] {spark_submit.py:490} INFO - 23/05/28 03:30:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:31,651] {spark_submit.py:490} INFO - 23/05/28 03:30:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:31,657] {spark_submit.py:490} INFO - 23/05/28 03:30:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:31,727] {spark_submit.py:490} INFO - 23/05/28 03:30:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:32,222] {spark_submit.py:490} INFO - 23/05/28 03:30:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:32,228] {spark_submit.py:490} INFO - 23/05/28 03:30:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:33,058] {spark_submit.py:490} INFO - 23/05/28 03:30:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:33,318] {spark_submit.py:490} INFO - 23/05/28 03:30:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:33,614] {spark_submit.py:490} INFO - 23/05/28 03:30:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:33,719] {spark_submit.py:490} INFO - 23/05/28 03:30:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:33,722] {spark_submit.py:490} INFO - 23/05/28 03:30:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:34,816] {spark_submit.py:490} INFO - 23/05/28 03:30:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:34,835] {spark_submit.py:490} INFO - 23/05/28 03:30:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:34,882] {spark_submit.py:490} INFO - 23/05/28 03:30:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:34,884] {spark_submit.py:490} INFO - 23/05/28 03:30:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:35,092] {spark_submit.py:490} INFO - 23/05/28 03:30:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:35,393] {spark_submit.py:490} INFO - 23/05/28 03:30:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:35,556] {spark_submit.py:490} INFO - 23/05/28 03:30:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:35,563] {spark_submit.py:490} INFO - 23/05/28 03:30:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,009] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,014] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,020] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,371] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,503] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,629] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:36,632] {spark_submit.py:490} INFO - 23/05/28 03:30:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:37,190] {spark_submit.py:490} INFO - 23/05/28 03:30:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:37,200] {spark_submit.py:490} INFO - 23/05/28 03:30:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:38,092] {spark_submit.py:490} INFO - 23/05/28 03:30:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:38,373] {spark_submit.py:490} INFO - 23/05/28 03:30:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:38,873] {spark_submit.py:490} INFO - 23/05/28 03:30:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:38,876] {spark_submit.py:490} INFO - 23/05/28 03:30:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:39,161] {spark_submit.py:490} INFO - 23/05/28 03:30:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:39,181] {spark_submit.py:490} INFO - 23/05/28 03:30:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:39,186] {spark_submit.py:490} INFO - 23/05/28 03:30:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:39,262] {spark_submit.py:490} INFO - 23/05/28 03:30:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:39,266] {spark_submit.py:490} INFO - 23/05/28 03:30:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:40,142] {spark_submit.py:490} INFO - 23/05/28 03:30:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:40,461] {spark_submit.py:490} INFO - 23/05/28 03:30:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,103] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,182] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,190] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,245] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,334] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,337] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,444] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:41,974] {spark_submit.py:490} INFO - 23/05/28 03:30:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:42,108] {spark_submit.py:490} INFO - 23/05/28 03:30:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:42,453] {spark_submit.py:490} INFO - 23/05/28 03:30:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:42,456] {spark_submit.py:490} INFO - 23/05/28 03:30:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:42,671] {spark_submit.py:490} INFO - 23/05/28 03:30:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:42,679] {spark_submit.py:490} INFO - 23/05/28 03:30:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:43,481] {spark_submit.py:490} INFO - 23/05/28 03:30:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:43,483] {spark_submit.py:490} INFO - 23/05/28 03:30:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,190] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,193] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,407] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,433] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,436] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,438] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:44,870] {spark_submit.py:490} INFO - 23/05/28 03:30:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:45,214] {spark_submit.py:490} INFO - 23/05/28 03:30:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:45,581] {spark_submit.py:490} INFO - 23/05/28 03:30:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:45,982] {spark_submit.py:490} INFO - 23/05/28 03:30:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:45,984] {spark_submit.py:490} INFO - 23/05/28 03:30:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:46,182] {spark_submit.py:490} INFO - 23/05/28 03:30:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:46,187] {spark_submit.py:490} INFO - 23/05/28 03:30:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:46,189] {spark_submit.py:490} INFO - 23/05/28 03:30:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:47,066] {spark_submit.py:490} INFO - 23/05/28 03:30:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:47,145] {spark_submit.py:490} INFO - 23/05/28 03:30:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:47,156] {spark_submit.py:490} INFO - 23/05/28 03:30:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:47,953] {spark_submit.py:490} INFO - 23/05/28 03:30:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:47,957] {spark_submit.py:490} INFO - 23/05/28 03:30:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:48,425] {spark_submit.py:490} INFO - 23/05/28 03:30:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:48,525] {spark_submit.py:490} INFO - 23/05/28 03:30:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:48,542] {spark_submit.py:490} INFO - 23/05/28 03:30:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:48,888] {spark_submit.py:490} INFO - 23/05/28 03:30:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:48,899] {spark_submit.py:490} INFO - 23/05/28 03:30:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:49,642] {spark_submit.py:490} INFO - 23/05/28 03:30:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:49,819] {spark_submit.py:490} INFO - 23/05/28 03:30:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:49,853] {spark_submit.py:490} INFO - 23/05/28 03:30:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:49,865] {spark_submit.py:490} INFO - 23/05/28 03:30:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:50,727] {spark_submit.py:490} INFO - 23/05/28 03:30:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:50,731] {spark_submit.py:490} INFO - 23/05/28 03:30:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:51,011] {spark_submit.py:490} INFO - 23/05/28 03:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:51,018] {spark_submit.py:490} INFO - 23/05/28 03:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:51,462] {spark_submit.py:490} INFO - 23/05/28 03:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:51,773] {spark_submit.py:490} INFO - 23/05/28 03:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:51,782] {spark_submit.py:490} INFO - 23/05/28 03:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:52,745] {spark_submit.py:490} INFO - 23/05/28 03:30:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:52,749] {spark_submit.py:490} INFO - 23/05/28 03:30:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:52,852] {spark_submit.py:490} INFO - 23/05/28 03:30:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:53,108] {spark_submit.py:490} INFO - 23/05/28 03:30:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:53,114] {spark_submit.py:490} INFO - 23/05/28 03:30:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:53,559] {spark_submit.py:490} INFO - 23/05/28 03:30:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:53,975] {spark_submit.py:490} INFO - 23/05/28 03:30:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:54,010] {spark_submit.py:490} INFO - 23/05/28 03:30:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:54,013] {spark_submit.py:490} INFO - 23/05/28 03:30:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:54,031] {spark_submit.py:490} INFO - 23/05/28 03:30:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:54,863] {spark_submit.py:490} INFO - 23/05/28 03:30:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:55,068] {spark_submit.py:490} INFO - 23/05/28 03:30:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:55,318] {spark_submit.py:490} INFO - 23/05/28 03:30:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:56,515] {spark_submit.py:490} INFO - 23/05/28 03:30:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:56,562] {spark_submit.py:490} INFO - 23/05/28 03:30:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:56,937] {spark_submit.py:490} INFO - 23/05/28 03:30:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:56,970] {spark_submit.py:490} INFO - 23/05/28 03:30:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:57,559] {spark_submit.py:490} INFO - 23/05/28 03:30:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:57,610] {spark_submit.py:490} INFO - 23/05/28 03:30:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:57,620] {spark_submit.py:490} INFO - 23/05/28 03:30:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:58,008] {spark_submit.py:490} INFO - 23/05/28 03:30:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:58,013] {spark_submit.py:490} INFO - 23/05/28 03:30:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:58,176] {spark_submit.py:490} INFO - 23/05/28 03:30:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:58,219] {spark_submit.py:490} INFO - 23/05/28 03:30:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:59,097] {spark_submit.py:490} INFO - 23/05/28 03:30:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:59,243] {spark_submit.py:490} INFO - 23/05/28 03:30:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:30:59,914] {spark_submit.py:490} INFO - 23/05/28 03:30:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:00,059] {spark_submit.py:490} INFO - 23/05/28 03:31:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:01,129] {spark_submit.py:490} INFO - 23/05/28 03:31:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:01,134] {spark_submit.py:490} INFO - 23/05/28 03:31:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:01,491] {spark_submit.py:490} INFO - 23/05/28 03:31:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:01,749] {spark_submit.py:490} INFO - 23/05/28 03:31:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:01,757] {spark_submit.py:490} INFO - 23/05/28 03:31:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,440] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,552] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,605] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,621] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,622] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,699] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:02,702] {spark_submit.py:490} INFO - 23/05/28 03:31:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,262] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,274] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,550] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,553] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,966] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:03,978] {spark_submit.py:490} INFO - 23/05/28 03:31:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,091] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,507] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,517] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,556] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,675] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,677] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,859] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:04,862] {spark_submit.py:490} INFO - 23/05/28 03:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:05,397] {spark_submit.py:490} INFO - 23/05/28 03:31:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:05,529] {spark_submit.py:490} INFO - 23/05/28 03:31:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:05,648] {spark_submit.py:490} INFO - 23/05/28 03:31:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:05,812] {spark_submit.py:490} INFO - 23/05/28 03:31:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:06,851] {spark_submit.py:490} INFO - 23/05/28 03:31:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:06,868] {spark_submit.py:490} INFO - 23/05/28 03:31:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,446] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,451] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,456] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,727] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,749] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:07,750] {spark_submit.py:490} INFO - 23/05/28 03:31:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:08,994] {spark_submit.py:490} INFO - 23/05/28 03:31:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:08,997] {spark_submit.py:490} INFO - 23/05/28 03:31:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:09,002] {spark_submit.py:490} INFO - 23/05/28 03:31:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:09,571] {spark_submit.py:490} INFO - 23/05/28 03:31:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:09,759] {spark_submit.py:490} INFO - 23/05/28 03:31:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:09,761] {spark_submit.py:490} INFO - 23/05/28 03:31:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,007] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,229] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,394] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,464] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,820] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:10,835] {spark_submit.py:490} INFO - 23/05/28 03:31:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:11,547] {spark_submit.py:490} INFO - 23/05/28 03:31:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:11,642] {spark_submit.py:490} INFO - 23/05/28 03:31:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:11,646] {spark_submit.py:490} INFO - 23/05/28 03:31:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:11,649] {spark_submit.py:490} INFO - 23/05/28 03:31:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:12,875] {spark_submit.py:490} INFO - 23/05/28 03:31:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:12,878] {spark_submit.py:490} INFO - 23/05/28 03:31:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:13,852] {spark_submit.py:490} INFO - 23/05/28 03:31:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:13,874] {spark_submit.py:490} INFO - 23/05/28 03:31:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:13,881] {spark_submit.py:490} INFO - 23/05/28 03:31:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:13,994] {spark_submit.py:490} INFO - 23/05/28 03:31:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:14,000] {spark_submit.py:490} INFO - 23/05/28 03:31:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:14,096] {spark_submit.py:490} INFO - 23/05/28 03:31:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:14,547] {spark_submit.py:490} INFO - 23/05/28 03:31:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:14,586] {spark_submit.py:490} INFO - 23/05/28 03:31:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:15,849] {spark_submit.py:490} INFO - 23/05/28 03:31:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:15,916] {spark_submit.py:490} INFO - 23/05/28 03:31:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:15,951] {spark_submit.py:490} INFO - 23/05/28 03:31:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:16,270] {spark_submit.py:490} INFO - 23/05/28 03:31:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:16,944] {spark_submit.py:490} INFO - 23/05/28 03:31:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:16,945] {spark_submit.py:490} INFO - 23/05/28 03:31:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:17,799] {spark_submit.py:490} INFO - 23/05/28 03:31:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:18,091] {spark_submit.py:490} INFO - 23/05/28 03:31:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:18,103] {spark_submit.py:490} INFO - 23/05/28 03:31:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:18,647] {spark_submit.py:490} INFO - 23/05/28 03:31:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:19,843] {spark_submit.py:490} INFO - 23/05/28 03:31:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:20,056] {spark_submit.py:490} INFO - 23/05/28 03:31:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:20,063] {spark_submit.py:490} INFO - 23/05/28 03:31:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:20,291] {spark_submit.py:490} INFO - 23/05/28 03:31:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:20,405] {spark_submit.py:490} INFO - 23/05/28 03:31:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:21,117] {spark_submit.py:490} INFO - 23/05/28 03:31:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:21,120] {spark_submit.py:490} INFO - 23/05/28 03:31:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:21,604] {spark_submit.py:490} INFO - 23/05/28 03:31:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:21,633] {spark_submit.py:490} INFO - 23/05/28 03:31:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:21,651] {spark_submit.py:490} INFO - 23/05/28 03:31:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:22,336] {spark_submit.py:490} INFO - 23/05/28 03:31:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:23,280] {spark_submit.py:490} INFO - 23/05/28 03:31:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:23,358] {spark_submit.py:490} INFO - 23/05/28 03:31:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:23,791] {spark_submit.py:490} INFO - 23/05/28 03:31:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,273] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,581] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,595] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,598] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,704] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:24,997] {spark_submit.py:490} INFO - 23/05/28 03:31:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:25,023] {spark_submit.py:490} INFO - 23/05/28 03:31:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:25,953] {spark_submit.py:490} INFO - 23/05/28 03:31:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:25,957] {spark_submit.py:490} INFO - 23/05/28 03:31:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,054] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,092] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,095] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,409] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,849] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:26,948] {spark_submit.py:490} INFO - 23/05/28 03:31:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:27,230] {spark_submit.py:490} INFO - 23/05/28 03:31:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:27,235] {spark_submit.py:490} INFO - 23/05/28 03:31:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:27,265] {spark_submit.py:490} INFO - 23/05/28 03:31:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:28,742] {spark_submit.py:490} INFO - 23/05/28 03:31:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,633] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,696] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,706] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,811] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,824] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,834] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:29,840] {spark_submit.py:490} INFO - 23/05/28 03:31:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:30,054] {spark_submit.py:490} INFO - 23/05/28 03:31:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:30,406] {spark_submit.py:490} INFO - 23/05/28 03:31:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:30,778] {spark_submit.py:490} INFO - 23/05/28 03:31:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,065] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,308] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,457] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,628] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,633] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,942] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,950] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:32,985] {spark_submit.py:490} INFO - 23/05/28 03:31:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:33,245] {spark_submit.py:490} INFO - 23/05/28 03:31:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:33,487] {spark_submit.py:490} INFO - 23/05/28 03:31:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:33,537] {spark_submit.py:490} INFO - 23/05/28 03:31:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,399] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,634] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,637] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,875] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,887] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,892] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:34,895] {spark_submit.py:490} INFO - 23/05/28 03:31:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,307] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,379] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,412] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,817] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,826] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:35,852] {spark_submit.py:490} INFO - 23/05/28 03:31:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:36,375] {spark_submit.py:490} INFO - 23/05/28 03:31:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:36,474] {spark_submit.py:490} INFO - 23/05/28 03:31:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:36,479] {spark_submit.py:490} INFO - 23/05/28 03:31:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:36,931] {spark_submit.py:490} INFO - 23/05/28 03:31:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:37,371] {spark_submit.py:490} INFO - 23/05/28 03:31:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:38,821] {spark_submit.py:490} INFO - 23/05/28 03:31:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:38,914] {spark_submit.py:490} INFO - 23/05/28 03:31:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:39,390] {spark_submit.py:490} INFO - 23/05/28 03:31:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:39,459] {spark_submit.py:490} INFO - 23/05/28 03:31:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:39,479] {spark_submit.py:490} INFO - 23/05/28 03:31:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:40,302] {spark_submit.py:490} INFO - 23/05/28 03:31:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:40,565] {spark_submit.py:490} INFO - 23/05/28 03:31:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:42,311] {spark_submit.py:490} INFO - 23/05/28 03:31:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:42,433] {spark_submit.py:490} INFO - 23/05/28 03:31:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:42,441] {spark_submit.py:490} INFO - 23/05/28 03:31:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:42,691] {spark_submit.py:490} INFO - 23/05/28 03:31:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:42,705] {spark_submit.py:490} INFO - 23/05/28 03:31:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:43,434] {spark_submit.py:490} INFO - 23/05/28 03:31:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:43,894] {spark_submit.py:490} INFO - 23/05/28 03:31:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:31:44,106] {spark_submit.py:490} INFO - 23/05/28 03:31:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:13,246] {spark_submit.py:490} INFO - 23/05/28 03:39:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:13,351] {spark_submit.py:490} INFO - 23/05/28 03:39:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:13,492] {spark_submit.py:490} INFO - 23/05/28 03:39:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:13,538] {spark_submit.py:490} INFO - 23/05/28 03:39:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:14,482] {spark_submit.py:490} INFO - 23/05/28 03:39:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:14,486] {spark_submit.py:490} INFO - 23/05/28 03:39:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:14,488] {spark_submit.py:490} INFO - 23/05/28 03:39:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:16,257] {spark_submit.py:490} INFO - 23/05/28 03:39:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:16,271] {spark_submit.py:490} INFO - 23/05/28 03:39:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:16,934] {spark_submit.py:490} INFO - 23/05/28 03:39:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:17,313] {spark_submit.py:490} INFO - 23/05/28 03:39:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:17,324] {spark_submit.py:490} INFO - 23/05/28 03:39:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:18,720] {spark_submit.py:490} INFO - 23/05/28 03:39:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:18,753] {spark_submit.py:490} INFO - 23/05/28 03:39:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:18,769] {spark_submit.py:490} INFO - 23/05/28 03:39:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:18,838] {spark_submit.py:490} INFO - 23/05/28 03:39:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:18,840] {spark_submit.py:490} INFO - 23/05/28 03:39:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:19,255] {spark_submit.py:490} INFO - 23/05/28 03:39:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:19,278] {spark_submit.py:490} INFO - 23/05/28 03:39:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:19,288] {spark_submit.py:490} INFO - 23/05/28 03:39:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:19,933] {spark_submit.py:490} INFO - 23/05/28 03:39:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:19,936] {spark_submit.py:490} INFO - 23/05/28 03:39:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:20,182] {spark_submit.py:490} INFO - 23/05/28 03:39:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:20,908] {spark_submit.py:490} INFO - 23/05/28 03:39:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:20,912] {spark_submit.py:490} INFO - 23/05/28 03:39:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:21,369] {spark_submit.py:490} INFO - 23/05/28 03:39:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:21,563] {spark_submit.py:490} INFO - 23/05/28 03:39:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:21,565] {spark_submit.py:490} INFO - 23/05/28 03:39:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:22,023] {spark_submit.py:490} INFO - 23/05/28 03:39:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:22,077] {spark_submit.py:490} INFO - 23/05/28 03:39:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-28 03:39:22,122] {local_task_job.py:221} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2023-05-28 03:39:22,128] {process_utils.py:129} INFO - Sending Signals.SIGTERM to group 13504. PIDs of all processes in the group: [13505, 13552, 13504]
[2023-05-28 03:39:22,129] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 13504
[2023-05-28 03:39:22,130] {taskinstance.py:1541} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-05-28 03:39:22,131] {spark_submit.py:615} INFO - Sending kill signal to spark-submit
[2023-05-28 03:39:22,808] {process_utils.py:75} INFO - Process psutil.Process(pid=13504, status='terminated', exitcode=0, started='03:22:36') (13504) terminated with exit code 0
[2023-05-28 03:39:22,824] {process_utils.py:75} INFO - Process psutil.Process(pid=13505, status='terminated', started='03:22:37') (13505) terminated with exit code None
[2023-05-28 03:39:22,826] {process_utils.py:75} INFO - Process psutil.Process(pid=13552, status='terminated', started='03:22:38') (13552) terminated with exit code None
